apiVersion: v1
kind: ConfigMap
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"v1","kind":"ConfigMap","metadata":{"annotations":{},"labels":{"app.kubernetes.io/name":"argocd-cm","app.kubernetes.io/part-of":"argocd"},"name":"argocd-cm","namespace":"argocd"}}
  labels:
    app.kubernetes.io/name: argocd-cm
    app.kubernetes.io/part-of: argocd
  name: argocd-cm
---
apiVersion: v1
kind: ConfigMap
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"v1","kind":"ConfigMap","metadata":{"annotations":{},"labels":{"app.kubernetes.io/name":"argocd-rbac-cm","app.kubernetes.io/part-of":"argocd"},"name":"argocd-rbac-cm","namespace":"argocd"}}
  labels:
    app.kubernetes.io/name: argocd-rbac-cm
    app.kubernetes.io/part-of: argocd
  name: argocd-rbac-cm
---
apiVersion: v1
data:
  ssh_known_hosts: |-
    bitbucket.org ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAubiN81eDcafrgMeLzaFPsw2kNvEcqTKl/VqLat/MaB33pZy0y3rJZtnqwR2qOOvbwKZYKiEO1O6VqNEBxKvJJelCq0dTXWT5pbO2gDXC6h6QDXCaHo6pOHGPUy+YBaGQRGuSusMEASYiWunYN0vCAI8QaXnWMXNMdFP3jHAJH0eDsoiGnLPBlBp4TNm6rYI74nMzgz3B9IikW4WVK+dc8KZJZWYjAuORU3jc1c/NPskD2ASinf8v3xnfXeukU0sJ5N6m5E8VLjObPEO+mN2t/FZTMZLiFqPWc/ALSqnMnnhwrNi2rbfg/rd/IpL8Le3pSBne8+seeFVBoGqzHM9yXw==
    github.com ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAq2A7hRGmdnm9tUDbO9IDSwBK6TbQa+PXYPCPy6rbTrTtw7PHkccKrpp0yVhp5HdEIcKr6pLlVDBfOLX9QUsyCOV0wzfjIJNlGEYsdlLJizHhbn2mUjvSAHQqZETYP81eFzLQNnPHt4EVVUh7VfDESU84KezmD5QlWpXLmvU31/yMf+Se8xhHTvKSCZIFImWwoG6mbUoWf9nzpIoaSjB+weqqUUmpaaasXVal72J+UX2B+2RPW3RcT0eOzQgqlJL3RKrTJvdsjE3JEAvGq3lGHSZXy28G3skua2SmVi/w4yCE6gbODqnTWlg7+wC604ydGXA8VJiS5ap43JXiUFFAaQ==
    gitlab.com ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBFSMqzJeV9rUzU4kWitGjeR4PWSa29SPqJ1fVkhtj3Hw9xjLVXVYrU9QlYWrOLXBpQ6KWjbjTDTdDkoohFzgbEY=
    gitlab.com ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIAfuCHKVTjquxvt6CM6tdG4SLp1Btn/nOeHHE5UOzRdf
    gitlab.com ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCsj2bNKTBSpIYDEGk9KxsGh3mySTRgMtXL583qmBpzeQ+jqCMRgBqB98u3z++J1sKlXHWfM9dyhSevkMwSbhoR8XIq/U0tCNyokEi/ueaBMCvbcTHhO7FcwzY92WK4Yt0aGROY5qX2UKSeOvuP4D6TPqKF1onrSzH9bx9XUf2lEdWT/ia1NEKjunUqu1xOB/StKDHMoX4/OKyIzuS0q/T1zOATthvasJFoPrAjkohTyaDUz2LN5JoH839hViyEG82yB+MjcFV5MU3N1l1QL3cVUCh93xSaua1N85qivl+siMkPGbO5xR/En4iEY6K2XPASUEMaieWVNTRCtJ4S8H+9
    ssh.dev.azure.com ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC7Hr1oTWqNqOlzGJOfGJ4NakVyIzf1rXYd4d7wo6jBlkLvCA4odBlL0mDUyZ0/QUfTTqeu+tm22gOsv+VrVTMk6vwRU75gY/y9ut5Mb3bR5BV58dKXyq9A9UeB5Cakehn5Zgm6x1mKoVyf+FFn26iYqXJRgzIZZcZ5V6hrE0Qg39kZm4az48o0AUbf6Sp4SLdvnuMa2sVNwHBboS7EJkm57XQPVU3/QpyNLHbWDdzwtrlS+ez30S3AdYhLKEOxAG8weOnyrtLJAUen9mTkol8oII1edf7mWWbWVf0nBmly21+nZcmCTISQBtdcyPaEno7fFQMDD26/s0lfKob4Kw8H
    vs-ssh.visualstudio.com ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC7Hr1oTWqNqOlzGJOfGJ4NakVyIzf1rXYd4d7wo6jBlkLvCA4odBlL0mDUyZ0/QUfTTqeu+tm22gOsv+VrVTMk6vwRU75gY/y9ut5Mb3bR5BV58dKXyq9A9UeB5Cakehn5Zgm6x1mKoVyf+FFn26iYqXJRgzIZZcZ5V6hrE0Qg39kZm4az48o0AUbf6Sp4SLdvnuMa2sVNwHBboS7EJkm57XQPVU3/QpyNLHbWDdzwtrlS+ez30S3AdYhLKEOxAG8weOnyrtLJAUen9mTkol8oII1edf7mWWbWVf0nBmly21+nZcmCTISQBtdcyPaEno7fFQMDD26/s0lfKob4Kw8H
    github.com ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBEmKSENjQEezOmxkZMy7opKgwFB9nkt5YRrYMjNuG5N87uRgg6CLrbo5wAdT/y6v0mKV0U2w0WZ2YB/++Tpockg=
    github.com ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIOMqqnkVzrm0SdG6UOoqKLsabgH5C9okWi0dh2l9GKJl
kind: ConfigMap
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"v1","data":{"ssh_known_hosts":"bitbucket.org ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAubiN81eDcafrgMeLzaFPsw2kNvEcqTKl/VqLat/MaB33pZy0y3rJZtnqwR2qOOvbwKZYKiEO1O6VqNEBxKvJJelCq0dTXWT5pbO2gDXC6h6QDXCaHo6pOHGPUy+YBaGQRGuSusMEASYiWunYN0vCAI8QaXnWMXNMdFP3jHAJH0eDsoiGnLPBlBp4TNm6rYI74nMzgz3B9IikW4WVK+dc8KZJZWYjAuORU3jc1c/NPskD2ASinf8v3xnfXeukU0sJ5N6m5E8VLjObPEO+mN2t/FZTMZLiFqPWc/ALSqnMnnhwrNi2rbfg/rd/IpL8Le3pSBne8+seeFVBoGqzHM9yXw==\ngithub.com ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAq2A7hRGmdnm9tUDbO9IDSwBK6TbQa+PXYPCPy6rbTrTtw7PHkccKrpp0yVhp5HdEIcKr6pLlVDBfOLX9QUsyCOV0wzfjIJNlGEYsdlLJizHhbn2mUjvSAHQqZETYP81eFzLQNnPHt4EVVUh7VfDESU84KezmD5QlWpXLmvU31/yMf+Se8xhHTvKSCZIFImWwoG6mbUoWf9nzpIoaSjB+weqqUUmpaaasXVal72J+UX2B+2RPW3RcT0eOzQgqlJL3RKrTJvdsjE3JEAvGq3lGHSZXy28G3skua2SmVi/w4yCE6gbODqnTWlg7+wC604ydGXA8VJiS5ap43JXiUFFAaQ==\ngitlab.com ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBFSMqzJeV9rUzU4kWitGjeR4PWSa29SPqJ1fVkhtj3Hw9xjLVXVYrU9QlYWrOLXBpQ6KWjbjTDTdDkoohFzgbEY=\ngitlab.com ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIAfuCHKVTjquxvt6CM6tdG4SLp1Btn/nOeHHE5UOzRdf\ngitlab.com ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCsj2bNKTBSpIYDEGk9KxsGh3mySTRgMtXL583qmBpzeQ+jqCMRgBqB98u3z++J1sKlXHWfM9dyhSevkMwSbhoR8XIq/U0tCNyokEi/ueaBMCvbcTHhO7FcwzY92WK4Yt0aGROY5qX2UKSeOvuP4D6TPqKF1onrSzH9bx9XUf2lEdWT/ia1NEKjunUqu1xOB/StKDHMoX4/OKyIzuS0q/T1zOATthvasJFoPrAjkohTyaDUz2LN5JoH839hViyEG82yB+MjcFV5MU3N1l1QL3cVUCh93xSaua1N85qivl+siMkPGbO5xR/En4iEY6K2XPASUEMaieWVNTRCtJ4S8H+9\nssh.dev.azure.com ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC7Hr1oTWqNqOlzGJOfGJ4NakVyIzf1rXYd4d7wo6jBlkLvCA4odBlL0mDUyZ0/QUfTTqeu+tm22gOsv+VrVTMk6vwRU75gY/y9ut5Mb3bR5BV58dKXyq9A9UeB5Cakehn5Zgm6x1mKoVyf+FFn26iYqXJRgzIZZcZ5V6hrE0Qg39kZm4az48o0AUbf6Sp4SLdvnuMa2sVNwHBboS7EJkm57XQPVU3/QpyNLHbWDdzwtrlS+ez30S3AdYhLKEOxAG8weOnyrtLJAUen9mTkol8oII1edf7mWWbWVf0nBmly21+nZcmCTISQBtdcyPaEno7fFQMDD26/s0lfKob4Kw8H\nvs-ssh.visualstudio.com ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC7Hr1oTWqNqOlzGJOfGJ4NakVyIzf1rXYd4d7wo6jBlkLvCA4odBlL0mDUyZ0/QUfTTqeu+tm22gOsv+VrVTMk6vwRU75gY/y9ut5Mb3bR5BV58dKXyq9A9UeB5Cakehn5Zgm6x1mKoVyf+FFn26iYqXJRgzIZZcZ5V6hrE0Qg39kZm4az48o0AUbf6Sp4SLdvnuMa2sVNwHBboS7EJkm57XQPVU3/QpyNLHbWDdzwtrlS+ez30S3AdYhLKEOxAG8weOnyrtLJAUen9mTkol8oII1edf7mWWbWVf0nBmly21+nZcmCTISQBtdcyPaEno7fFQMDD26/s0lfKob4Kw8H\ngithub.com ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBEmKSENjQEezOmxkZMy7opKgwFB9nkt5YRrYMjNuG5N87uRgg6CLrbo5wAdT/y6v0mKV0U2w0WZ2YB/++Tpockg=\ngithub.com ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIOMqqnkVzrm0SdG6UOoqKLsabgH5C9okWi0dh2l9GKJl"},"kind":"ConfigMap","metadata":{"annotations":{},"labels":{"app.kubernetes.io/name":"argocd-ssh-known-hosts-cm","app.kubernetes.io/part-of":"argocd"},"name":"argocd-ssh-known-hosts-cm","namespace":"argocd"}}
  labels:
    app.kubernetes.io/name: argocd-ssh-known-hosts-cm
    app.kubernetes.io/part-of: argocd
  name: argocd-ssh-known-hosts-cm
---
apiVersion: v1
kind: ConfigMap
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"v1","kind":"ConfigMap","metadata":{"annotations":{},"labels":{"app.kubernetes.io/name":"argocd-tls-certs-cm","app.kubernetes.io/part-of":"argocd"},"name":"argocd-tls-certs-cm","namespace":"argocd"}}
  labels:
    app.kubernetes.io/name: argocd-tls-certs-cm
    app.kubernetes.io/part-of: argocd
  name: argocd-tls-certs-cm
---
apiVersion: v1
data:
  admin.password: JDJhJDEwJGk5ZzBxeUpWdjBzTTY2UGNWeDhvemVqb2JIL3o5SWxPODEySE5ZaDdzN0w4djVqcW9IcVZH
  admin.passwordMtime: MjAyMi0wNy0wM1QxMToxNDoyNVo=
  server.secretkey: bGp6dUk5WnA0bFlTVVFGcUxrcFA3UGRkSy9ONDFQekFtZERPbm5LTTlCZz0=
  tls.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURZakNDQWtxZ0F3SUJBZ0lRRENEZXh1Vlh6Ym1sakQycSsyTUVLREFOQmdrcWhraUc5dzBCQVFzRkFEQVMKTVJBd0RnWURWUVFLRXdkQmNtZHZJRU5FTUI0WERUSXlNRGN3TXpBNU5EVXlOVm9YRFRJek1EY3dNekE1TkRVeQpOVm93RWpFUU1BNEdBMVVFQ2hNSFFYSm5ieUJEUkRDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDCkFRb0NnZ0VCQU9oUjhUMGtjbUE3QjhFdG9lT2R4U2lQK1ROZXJ6YkJsR0VNQzlLMjdHeWNudFU3dHBjem1Ia0wKdjFkTlA1OFoyWENlQXFrMmg2Vkl2TkJ6NXlxNkpNMEE5cDRVZXB3d1d3VW5ZUnVPYzVSVUhaQ01UWGtPeVhuVQpXUCtILzgyMG1PWGd4dWQ4aU5KaUI1bjRHNVpwQ1RNZmtMU1hyeis3UHhDNjVsanhOci9rSDBqK2pBRUpmSnhXCnZ2SXNpdnd5UFhreVNkcGxYUW5Cb2dyWm85bysvRjM2WVBqcW12Y1pjWWw2b2ZxZEx5MitXRi9kcVJjOHJnbXIKOWVsd0cvditzZXZwemQ1TFBydmN2Q3BJWDJ5U2RPV1pFWjdkUzc0S2diMlFXWnk2OFdpSGVuVEtYdW5ZOEJ3ZgpqMWx2TjBGeEk0ZlBBSk5QNjV2aGZWYmRLakRxSFhVQ0F3RUFBYU9Cc3pDQnNEQU9CZ05WSFE4QkFmOEVCQU1DCkJhQXdFd1lEVlIwbEJBd3dDZ1lJS3dZQkJRVUhBd0V3REFZRFZSMFRBUUgvQkFJd0FEQjdCZ05WSFJFRWREQnkKZ2dsc2IyTmhiR2h2YzNTQ0RXRnlaMjlqWkMxelpYSjJaWEtDRkdGeVoyOWpaQzF6WlhKMlpYSXVZWEpuYjJOawpnaGhoY21kdlkyUXRjMlZ5ZG1WeUxtRnlaMjlqWkM1emRtT0NKbUZ5WjI5alpDMXpaWEoyWlhJdVlYSm5iMk5rCkxuTjJZeTVqYkhWemRHVnlMbXh2WTJGc01BMEdDU3FHU0liM0RRRUJDd1VBQTRJQkFRQlBTbzdQUE10bGVZZ2QKUGlwbGE3eHR6Wi9kb2FoMnJSRTRpWHdXNitRdi9IbmhSUkNrS1lTYzF1RlZnR0laTUJBRXhNRWt6OVM2UVlQRAo1YWVDeW40RDM4bnc4RGtBN3Vsd2JIRm9QM2V2dkVtWi9sWitHSkRidFRVYnJBVWFEdnM2RE9PalZ5VjZkbGl0CnVLYVQwWkFQQnVBUVBRcm1aWGdGdnU1MENNZE1OQ2pXK2F4SmZuSDJoV0JWTEwweDNxVlFlZ01JSWVGSGJ4bnUKNk0wOXRBTmJwNzBIMktHTDRuTDhwMFhiNmtoY3ZPbjdlMHVpKzZNUVFZQUFOMEVuYmh0UXZXOVVDNEcwRGtISQo0Tmpta1RnM2YzYWpMMUpITDZJVlAwQkpXaVNlU0M2bnR3eVhXYWprQWRFWmtpYy9lWVB6QUFENkFZUGxCU3RTCkdERkd3ZnVQCi0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
  tls.key: REDACTED=
kind: Secret
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"v1","kind":"Secret","metadata":{"annotations":{},"labels":{"app.kubernetes.io/name":"argocd-secret","app.kubernetes.io/part-of":"argocd"},"name":"argocd-secret","namespace":"argocd"},"type":"Opaque"}
  labels:
    app.kubernetes.io/name: argocd-secret
    app.kubernetes.io/part-of: argocd
  name: argocd-secret
type: Opaque
---
apiVersion: argoproj.io/v1alpha1
kind: AppProject
metadata:
  name: default
spec:
  clusterResourceWhitelist:
  - group: '*'
    kind: '*'
  destinations:
  - namespace: '*'
    server: '*'
  sourceRepos:
  - '*'
status: {}
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: elasticsearch
spec:
  destination:
    namespace: monitoring
    server: https://kubernetes.default.svc
  project: default
  source:
    chart: elasticsearch
    helm:
      valueFiles:
      - values.yaml
      values: |-
        global:
          kibanaEnabled: true
        coordinating:
          heapSize: 512m
          resources:
            requests:
              memory: "512Mi"
        service:
          annotations:
            cloud.google.com/backend-config: '{"default": "admin-whitelist"}'
    repoURL: https://charts.bitnami.com/bitnami
    targetRevision: 19.1.9
status:
  health:
    status: Healthy
  history:
  - deployStartedAt: "2022-08-14T14:35:34Z"
    deployedAt: "2022-08-14T14:35:35Z"
    id: 0
    revision: 19.1.9
    source:
      chart: elasticsearch
      helm:
        parameters:
        - name: global.kibanaEnabled
          value: "true"
      repoURL: https://charts.bitnami.com/bitnami
      targetRevision: 19.1.9
  - deployStartedAt: "2022-08-14T15:38:24Z"
    deployedAt: "2022-08-14T15:38:25Z"
    id: 1
    revision: 19.1.9
    source:
      chart: elasticsearch
      helm:
        parameters:
        - name: global.kibanaEnabled
          value: "true"
        valueFiles:
        - values.yaml
        values: |-
          service:
            annotations:
              kubernetes.io/ingress.class: "gce"
              cloud.google.com/backend-config: '{"default": "admin-whitelist"}'
              cloud.google.com/neg: '{"ingress": true}'
      repoURL: https://charts.bitnami.com/bitnami
      targetRevision: 19.1.9
  - deployStartedAt: "2022-08-24T00:32:15Z"
    deployedAt: "2022-08-24T00:32:16Z"
    id: 2
    revision: 19.1.9
    source:
      chart: elasticsearch
      helm:
        parameters:
        - name: global.kibanaEnabled
          value: "true"
        valueFiles:
        - values.yaml
        values: |-
          service:
            annotations:
              cloud.google.com/backend-config: '{"default": "admin-whitelist"}'
      repoURL: https://charts.bitnami.com/bitnami
      targetRevision: 19.1.9
  - deployStartedAt: "2022-08-24T04:14:01Z"
    deployedAt: "2022-08-24T04:14:02Z"
    id: 3
    revision: 19.1.9
    source:
      chart: elasticsearch
      helm:
        parameters:
        - name: global.kibanaEnabled
          value: "true"
        valueFiles:
        - values.yaml
        values: |-
          coordinating:
            heapSize: 256m
          service:
            annotations:
              cloud.google.com/backend-config: '{"default": "admin-whitelist"}'
      repoURL: https://charts.bitnami.com/bitnami
      targetRevision: 19.1.9
  - deployStartedAt: "2022-08-26T06:20:55Z"
    deployedAt: "2022-08-26T06:20:56Z"
    id: 4
    revision: 19.1.9
    source:
      chart: elasticsearch
      helm:
        parameters:
        - name: global.kibanaEnabled
          value: "true"
        valueFiles:
        - values.yaml
        values: |-
          coordinating:
            heapSize: 512m
            resources:
              requests:
                memory: "512Mi"
          service:
            annotations:
              cloud.google.com/backend-config: '{"default": "admin-whitelist"}'
      repoURL: https://charts.bitnami.com/bitnami
      targetRevision: 19.1.9
  - deployStartedAt: "2022-08-26T06:22:03Z"
    deployedAt: "2022-08-26T06:22:03Z"
    id: 5
    revision: 19.1.9
    source:
      chart: elasticsearch
      helm:
        valueFiles:
        - values.yaml
        values: |-
          global:
            kibanaEnabled: true
          coordinating:
            heapSize: 512m
            resources:
              requests:
                memory: "512Mi"
          service:
            annotations:
              cloud.google.com/backend-config: '{"default": "admin-whitelist"}'
      repoURL: https://charts.bitnami.com/bitnami
      targetRevision: 19.1.9
  operationState:
    finishedAt: "2022-08-26T06:22:03Z"
    message: successfully synced (all tasks run)
    operation:
      initiatedBy:
        username: admin
      retry: {}
      sync:
        revision: 19.1.9
        syncStrategy:
          hook: {}
    phase: Succeeded
    startedAt: "2022-08-26T06:22:03Z"
    syncResult:
      resources:
      - group: cilium.io
        hookPhase: Succeeded
        kind: CiliumIdentity
        message: ignored (requires pruning)
        name: "10850"
        namespace: ""
        status: PruneSkipped
        syncPhase: Sync
        version: v2
      - group: cilium.io
        hookPhase: Succeeded
        kind: CiliumIdentity
        message: ignored (requires pruning)
        name: "40724"
        namespace: ""
        status: PruneSkipped
        syncPhase: Sync
        version: v2
      - group: cilium.io
        hookPhase: Succeeded
        kind: CiliumIdentity
        message: ignored (requires pruning)
        name: "14026"
        namespace: ""
        status: PruneSkipped
        syncPhase: Sync
        version: v2
      - group: cilium.io
        hookPhase: Succeeded
        kind: CiliumIdentity
        message: ignored (requires pruning)
        name: "42141"
        namespace: ""
        status: PruneSkipped
        syncPhase: Sync
        version: v2
      - group: cilium.io
        hookPhase: Succeeded
        kind: CiliumIdentity
        message: ignored (requires pruning)
        name: "55893"
        namespace: ""
        status: PruneSkipped
        syncPhase: Sync
        version: v2
      - group: cilium.io
        hookPhase: Succeeded
        kind: CiliumIdentity
        message: ignored (requires pruning)
        name: "6210"
        namespace: ""
        status: PruneSkipped
        syncPhase: Sync
        version: v2
      - group: cilium.io
        hookPhase: Succeeded
        kind: CiliumIdentity
        message: ignored (requires pruning)
        name: "31221"
        namespace: ""
        status: PruneSkipped
        syncPhase: Sync
        version: v2
      - group: cilium.io
        hookPhase: Succeeded
        kind: CiliumIdentity
        message: ignored (requires pruning)
        name: "21468"
        namespace: ""
        status: PruneSkipped
        syncPhase: Sync
        version: v2
      - group: cilium.io
        hookPhase: Succeeded
        kind: CiliumIdentity
        message: ignored (requires pruning)
        name: "48466"
        namespace: ""
        status: PruneSkipped
        syncPhase: Sync
        version: v2
      - group: ""
        hookPhase: Running
        kind: ServiceAccount
        message: serviceaccount/elasticsearch-kibana unchanged
        name: elasticsearch-kibana
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: ConfigMap
        message: configmap/elasticsearch-kibana-conf unchanged
        name: elasticsearch-kibana-conf
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: PersistentVolumeClaim
        message: persistentvolumeclaim/elasticsearch-kibana unchanged
        name: elasticsearch-kibana
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/elasticsearch-ingest-hl unchanged
        name: elasticsearch-ingest-hl
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/elasticsearch-data-hl unchanged
        name: elasticsearch-data-hl
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/elasticsearch-master-hl unchanged
        name: elasticsearch-master-hl
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/elasticsearch-coordinating-hl unchanged
        name: elasticsearch-coordinating-hl
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/elasticsearch configured
        name: elasticsearch
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/elasticsearch-kibana configured
        name: elasticsearch-kibana
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Running
        kind: Deployment
        message: deployment.apps/elasticsearch-kibana configured
        name: elasticsearch-kibana
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Running
        kind: StatefulSet
        message: statefulset.apps/elasticsearch-master configured
        name: elasticsearch-master
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Running
        kind: StatefulSet
        message: statefulset.apps/elasticsearch-coordinating configured
        name: elasticsearch-coordinating
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Running
        kind: StatefulSet
        message: statefulset.apps/elasticsearch-data configured
        name: elasticsearch-data
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Running
        kind: StatefulSet
        message: statefulset.apps/elasticsearch-ingest configured
        name: elasticsearch-ingest
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      revision: 19.1.9
      source:
        chart: elasticsearch
        helm:
          valueFiles:
          - values.yaml
          values: |-
            global:
              kibanaEnabled: true
            coordinating:
              heapSize: 512m
              resources:
                requests:
                  memory: "512Mi"
            service:
              annotations:
                cloud.google.com/backend-config: '{"default": "admin-whitelist"}'
        repoURL: https://charts.bitnami.com/bitnami
        targetRevision: 19.1.9
  reconciledAt: "2022-08-29T06:10:47Z"
  resources:
  - kind: ConfigMap
    name: elasticsearch-kibana-conf
    namespace: monitoring
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: PersistentVolumeClaim
    name: elasticsearch-kibana
    namespace: monitoring
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: elasticsearch
    namespace: monitoring
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: elasticsearch-coordinating-hl
    namespace: monitoring
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: elasticsearch-data-hl
    namespace: monitoring
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: elasticsearch-ingest-hl
    namespace: monitoring
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: elasticsearch-kibana
    namespace: monitoring
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: elasticsearch-master-hl
    namespace: monitoring
    status: Synced
    version: v1
  - kind: ServiceAccount
    name: elasticsearch-kibana
    namespace: monitoring
    status: Synced
    version: v1
  - group: apps
    health:
      status: Healthy
    kind: Deployment
    name: elasticsearch-kibana
    namespace: monitoring
    status: Synced
    version: v1
  - group: apps
    health:
      message: statefulset rolling update complete 2 pods at revision elasticsearch-coordinating-5df45df787...
      status: Healthy
    kind: StatefulSet
    name: elasticsearch-coordinating
    namespace: monitoring
    status: Synced
    version: v1
  - group: apps
    health:
      message: statefulset rolling update complete 2 pods at revision elasticsearch-data-7ddd447d58...
      status: Healthy
    kind: StatefulSet
    name: elasticsearch-data
    namespace: monitoring
    status: Synced
    version: v1
  - group: apps
    health:
      message: statefulset rolling update complete 2 pods at revision elasticsearch-ingest-64f4db9ff7...
      status: Healthy
    kind: StatefulSet
    name: elasticsearch-ingest
    namespace: monitoring
    status: Synced
    version: v1
  - group: apps
    health:
      message: statefulset rolling update complete 2 pods at revision elasticsearch-master-b88f69f57...
      status: Healthy
    kind: StatefulSet
    name: elasticsearch-master
    namespace: monitoring
    status: Synced
    version: v1
  - group: cilium.io
    kind: CiliumIdentity
    name: "10850"
    requiresPruning: true
    status: OutOfSync
    version: v2
  - group: cilium.io
    kind: CiliumIdentity
    name: "14026"
    requiresPruning: true
    status: OutOfSync
    version: v2
  - group: cilium.io
    kind: CiliumIdentity
    name: "21468"
    requiresPruning: true
    status: OutOfSync
    version: v2
  - group: cilium.io
    kind: CiliumIdentity
    name: "31221"
    requiresPruning: true
    status: OutOfSync
    version: v2
  - group: cilium.io
    kind: CiliumIdentity
    name: "40724"
    requiresPruning: true
    status: OutOfSync
    version: v2
  - group: cilium.io
    kind: CiliumIdentity
    name: "42141"
    requiresPruning: true
    status: OutOfSync
    version: v2
  - group: cilium.io
    kind: CiliumIdentity
    name: "48466"
    requiresPruning: true
    status: OutOfSync
    version: v2
  - group: cilium.io
    kind: CiliumIdentity
    name: "55893"
    requiresPruning: true
    status: OutOfSync
    version: v2
  - group: cilium.io
    kind: CiliumIdentity
    name: "6210"
    requiresPruning: true
    status: OutOfSync
    version: v2
  sourceType: Helm
  summary:
    images:
    - docker.io/bitnami/bitnami-shell:11-debian-11-r23
    - docker.io/bitnami/elasticsearch:8.3.3-debian-11-r5
    - docker.io/bitnami/kibana:8.3.3-debian-11-r3
  sync:
    comparedTo:
      destination:
        namespace: monitoring
        server: https://kubernetes.default.svc
      source:
        chart: elasticsearch
        helm:
          valueFiles:
          - values.yaml
          values: |-
            global:
              kibanaEnabled: true
            coordinating:
              heapSize: 512m
              resources:
                requests:
                  memory: "512Mi"
            service:
              annotations:
                cloud.google.com/backend-config: '{"default": "admin-whitelist"}'
        repoURL: https://charts.bitnami.com/bitnami
        targetRevision: 19.1.9
    revision: 19.1.9
    status: OutOfSync
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: fluentd
spec:
  destination:
    namespace: monitoring
    server: https://kubernetes.default.svc
  project: default
  source:
    chart: fluentd
    helm:
      parameters:
      - name: image.repository
        value: bensonyanger/fluentd
      - name: image.tag
        value: latest
      valueFiles:
      - values.yaml
      values: |-
        aggregator:
          configMap: elasticsearch-output
          extraEnv:
          - name: ELASTICSEARCH_HOST
            value: elasticsearch-coordinating-hl.monitoring.svc.cluster.local
          - name: ELASTICSEARCH_PORT
            value: 9200
        forwarder:
          configMap: fluentd-config
          extraEnv:
          - name: FLUENTD_DAEMON_USER
            value: root
          - name: FLUENTD_DAEMON_GROUP
            value: root
          tolerations:
          - key: "ctfd-node-pool"
            operator: "Equal"
            value: "true"
            effect: "NoSchedule"
    repoURL: https://charts.bitnami.com/bitnami
    targetRevision: 5.3.4
status:
  health:
    status: Healthy
  history:
  - deployStartedAt: "2022-08-24T15:16:52Z"
    deployedAt: "2022-08-24T15:16:52Z"
    id: 0
    revision: 5.3.4
    source:
      chart: fluentd
      helm:
        valueFiles:
        - values.yaml
        values: |-
          aggregator:
            configMap: elasticsearch-output
            extraEnv:
            - name: ELASTICSEARCH_HOST
              value: elasticsearch-coordinating-hl.monitoring.svc.cluster.local
            - name: ELASTICSEARCH_PORT
              value: 9200
          forwarder:
            configMap: fluentd-config
            extraEnv:
            - name: FLUENTD_DAEMON_USER
              value: root
            - name: FLUENTD_DAEMON_GROUP
              value: root
            tolerations:
            - key: "ctfd-node-pool"
              operator: "Equal"
              value: "true"
              effect: "NoSchedule"
      repoURL: https://charts.bitnami.com/bitnami
      targetRevision: 5.3.4
  - deployStartedAt: "2022-08-24T16:11:05Z"
    deployedAt: "2022-08-24T16:11:05Z"
    id: 1
    revision: 5.3.4
    source:
      chart: fluentd
      helm:
        parameters:
        - name: image.repository
          value: bensonyanger/fluentd
        - name: image.tag
          value: latest
        valueFiles:
        - values.yaml
        values: |-
          aggregator:
            configMap: elasticsearch-output
            extraEnv:
            - name: ELASTICSEARCH_HOST
              value: elasticsearch-coordinating-hl.monitoring.svc.cluster.local
            - name: ELASTICSEARCH_PORT
              value: 9200
          forwarder:
            configMap: fluentd-config
            extraEnv:
            - name: FLUENTD_DAEMON_USER
              value: root
            - name: FLUENTD_DAEMON_GROUP
              value: root
            tolerations:
            - key: "ctfd-node-pool"
              operator: "Equal"
              value: "true"
              effect: "NoSchedule"
      repoURL: https://charts.bitnami.com/bitnami
      targetRevision: 5.3.4
  operationState:
    finishedAt: "2022-08-24T16:11:05Z"
    message: successfully synced (all tasks run)
    operation:
      initiatedBy:
        username: admin
      retry: {}
      sync:
        revision: 5.3.4
        syncStrategy:
          hook: {}
    phase: Succeeded
    startedAt: "2022-08-24T16:11:05Z"
    syncResult:
      resources:
      - group: cilium.io
        hookPhase: Succeeded
        kind: CiliumIdentity
        message: ignored (requires pruning)
        name: "63115"
        namespace: ""
        status: PruneSkipped
        syncPhase: Sync
        version: v2
      - group: cilium.io
        hookPhase: Succeeded
        kind: CiliumIdentity
        message: ignored (requires pruning)
        name: "10498"
        namespace: ""
        status: PruneSkipped
        syncPhase: Sync
        version: v2
      - group: ""
        hookPhase: Running
        kind: ServiceAccount
        message: serviceaccount/fluentd-forwarder unchanged
        name: fluentd-forwarder
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: ClusterRole
        message: clusterrole.rbac.authorization.k8s.io/fluentd-monitoring reconciled.
          clusterrole.rbac.authorization.k8s.io/fluentd-monitoring unchanged
        name: fluentd-monitoring
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: ClusterRoleBinding
        message: clusterrolebinding.rbac.authorization.k8s.io/fluentd-monitoring reconciled.
          clusterrolebinding.rbac.authorization.k8s.io/fluentd-monitoring unchanged
        name: fluentd-monitoring
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/fluentd-aggregator unchanged
        name: fluentd-aggregator
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/fluentd-forwarder unchanged
        name: fluentd-forwarder
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/fluentd-headless unchanged
        name: fluentd-headless
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Running
        kind: DaemonSet
        message: daemonset.apps/fluentd configured
        name: fluentd
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Running
        kind: StatefulSet
        message: statefulset.apps/fluentd configured
        name: fluentd
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      revision: 5.3.4
      source:
        chart: fluentd
        helm:
          parameters:
          - name: image.repository
            value: bensonyanger/fluentd
          - name: image.tag
            value: latest
          valueFiles:
          - values.yaml
          values: |-
            aggregator:
              configMap: elasticsearch-output
              extraEnv:
              - name: ELASTICSEARCH_HOST
                value: elasticsearch-coordinating-hl.monitoring.svc.cluster.local
              - name: ELASTICSEARCH_PORT
                value: 9200
            forwarder:
              configMap: fluentd-config
              extraEnv:
              - name: FLUENTD_DAEMON_USER
                value: root
              - name: FLUENTD_DAEMON_GROUP
                value: root
              tolerations:
              - key: "ctfd-node-pool"
                operator: "Equal"
                value: "true"
                effect: "NoSchedule"
        repoURL: https://charts.bitnami.com/bitnami
        targetRevision: 5.3.4
  reconciledAt: "2022-08-29T06:10:47Z"
  resources:
  - health:
      status: Healthy
    kind: Service
    name: fluentd-aggregator
    namespace: monitoring
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: fluentd-forwarder
    namespace: monitoring
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: fluentd-headless
    namespace: monitoring
    status: Synced
    version: v1
  - kind: ServiceAccount
    name: fluentd-forwarder
    namespace: monitoring
    status: Synced
    version: v1
  - group: apps
    health:
      status: Healthy
    kind: DaemonSet
    name: fluentd
    namespace: monitoring
    status: Synced
    version: v1
  - group: apps
    health:
      message: statefulset rolling update complete 1 pods at revision fluentd-85dfd445f9...
      status: Healthy
    kind: StatefulSet
    name: fluentd
    namespace: monitoring
    status: Synced
    version: v1
  - group: cilium.io
    kind: CiliumIdentity
    name: "10498"
    requiresPruning: true
    status: OutOfSync
    version: v2
  - group: cilium.io
    kind: CiliumIdentity
    name: "63115"
    requiresPruning: true
    status: OutOfSync
    version: v2
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: fluentd-monitoring
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
    name: fluentd-monitoring
    status: Synced
    version: v1
  sourceType: Helm
  summary:
    images:
    - docker.io/bensonyanger/fluentd:latest
  sync:
    comparedTo:
      destination:
        namespace: monitoring
        server: https://kubernetes.default.svc
      source:
        chart: fluentd
        helm:
          parameters:
          - name: image.repository
            value: bensonyanger/fluentd
          - name: image.tag
            value: latest
          valueFiles:
          - values.yaml
          values: |-
            aggregator:
              configMap: elasticsearch-output
              extraEnv:
              - name: ELASTICSEARCH_HOST
                value: elasticsearch-coordinating-hl.monitoring.svc.cluster.local
              - name: ELASTICSEARCH_PORT
                value: 9200
            forwarder:
              configMap: fluentd-config
              extraEnv:
              - name: FLUENTD_DAEMON_USER
                value: root
              - name: FLUENTD_DAEMON_GROUP
                value: root
              tolerations:
              - key: "ctfd-node-pool"
                operator: "Equal"
                value: "true"
                effect: "NoSchedule"
        repoURL: https://charts.bitnami.com/bitnami
        targetRevision: 5.3.4
    revision: 5.3.4
    status: OutOfSync
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: grafana
spec:
  destination:
    namespace: monitoring
    server: https://kubernetes.default.svc
  project: default
  source:
    chart: grafana
    helm:
      valueFiles:
      - values.yaml
      values: |-
        service:
          annotations:
            cloud.google.com/backend-config: '{"default": "admin-whitelist"}'
    repoURL: https://charts.bitnami.com/bitnami
    targetRevision: 8.2.2
status:
  health:
    status: Healthy
  history:
  - deployStartedAt: "2022-08-26T07:16:51Z"
    deployedAt: "2022-08-26T07:16:51Z"
    id: 0
    revision: 8.2.2
    source:
      chart: grafana
      repoURL: https://charts.bitnami.com/bitnami
      targetRevision: 8.2.2
  - deployStartedAt: "2022-08-26T07:21:17Z"
    deployedAt: "2022-08-26T07:21:18Z"
    id: 1
    revision: 8.2.2
    source:
      chart: grafana
      helm:
        valueFiles:
        - values.yaml
        values: |-
          service:
            annotations:
              cloud.google.com/backend-config: '{"default": "admin-whitelist"}'
      repoURL: https://charts.bitnami.com/bitnami
      targetRevision: 8.2.2
  - deployStartedAt: "2022-08-26T18:09:36Z"
    deployedAt: "2022-08-26T18:09:37Z"
    id: 2
    revision: 8.2.2
    source:
      chart: grafana
      helm:
        valueFiles:
        - values.yaml
        values: |-
          service:
            annotations:
              cloud.google.com/backend-config: '{"default": "admin-whitelist"}'
      repoURL: https://charts.bitnami.com/bitnami
      targetRevision: 8.2.2
  - deployStartedAt: "2022-08-26T18:32:54Z"
    deployedAt: "2022-08-26T18:32:55Z"
    id: 3
    revision: 8.2.2
    source:
      chart: grafana
      helm:
        valueFiles:
        - values.yaml
        values: |-
          service:
            annotations:
              cloud.google.com/backend-config: '{"default": "admin-whitelist"}'
      repoURL: https://charts.bitnami.com/bitnami
      targetRevision: 8.2.2
  operationState:
    finishedAt: "2022-08-26T18:32:55Z"
    message: successfully synced (all tasks run)
    operation:
      initiatedBy:
        username: admin
      retry: {}
      sync:
        revision: 8.2.2
        syncStrategy:
          hook: {}
    phase: Succeeded
    startedAt: "2022-08-26T18:32:54Z"
    syncResult:
      resources:
      - group: cilium.io
        hookPhase: Succeeded
        kind: CiliumIdentity
        message: ignored (requires pruning)
        name: "44623"
        namespace: ""
        status: PruneSkipped
        syncPhase: Sync
        version: v2
      - group: ""
        hookPhase: Running
        kind: ServiceAccount
        message: serviceaccount/grafana unchanged
        name: grafana
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Secret
        message: secret/grafana-admin unchanged
        name: grafana-admin
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: ConfigMap
        message: configmap/grafana-envvars configured
        name: grafana-envvars
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: PersistentVolumeClaim
        message: persistentvolumeclaim/grafana unchanged
        name: grafana
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/grafana configured
        name: grafana
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Running
        kind: Deployment
        message: deployment.apps/grafana configured
        name: grafana
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      revision: 8.2.2
      source:
        chart: grafana
        helm:
          valueFiles:
          - values.yaml
          values: |-
            service:
              annotations:
                cloud.google.com/backend-config: '{"default": "admin-whitelist"}'
        repoURL: https://charts.bitnami.com/bitnami
        targetRevision: 8.2.2
  reconciledAt: "2022-08-29T06:10:47Z"
  resources:
  - kind: ConfigMap
    name: grafana-envvars
    namespace: monitoring
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: PersistentVolumeClaim
    name: grafana
    namespace: monitoring
    status: Synced
    version: v1
  - kind: Secret
    name: grafana-admin
    namespace: monitoring
    status: OutOfSync
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: grafana
    namespace: monitoring
    status: Synced
    version: v1
  - kind: ServiceAccount
    name: grafana
    namespace: monitoring
    status: Synced
    version: v1
  - group: apps
    health:
      status: Healthy
    kind: Deployment
    name: grafana
    namespace: monitoring
    status: OutOfSync
    version: v1
  - group: cilium.io
    kind: CiliumIdentity
    name: "44623"
    requiresPruning: true
    status: OutOfSync
    version: v2
  sourceType: Helm
  summary:
    images:
    - docker.io/bitnami/grafana:9.1.1-debian-11-r0
  sync:
    comparedTo:
      destination:
        namespace: monitoring
        server: https://kubernetes.default.svc
      source:
        chart: grafana
        helm:
          valueFiles:
          - values.yaml
          values: |-
            service:
              annotations:
                cloud.google.com/backend-config: '{"default": "admin-whitelist"}'
        repoURL: https://charts.bitnami.com/bitnami
        targetRevision: 8.2.2
    revision: 8.2.2
    status: OutOfSync
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: jenkins
spec:
  destination:
    namespace: jenkins
    server: https://kubernetes.default.svc
  project: default
  source:
    chart: jenkins
    helm:
      parameters:
      - name: serviceAccount.create
        value: "false"
      - name: serviceAccount.name
        value: jenkins
      - name: persistence.size
        value: 10Gi
      - name: agent.alwaysPullImage
        value: "true"
      - name: agent.tag
        value: latest
      - name: agent.image
        value: bensonyanger/jenkins-agent
      valueFiles:
      - values.yaml
      values: |
        agent:
          enabled: true
          defaultsProviderTemplate: ""
          # URL for connecting to the Jenkins contoller
          jenkinsUrl:
          # connect to the specified host and port, instead of connecting directly to the Jenkins controller
          jenkinsTunnel:
          kubernetesConnectTimeout: 5
          kubernetesReadTimeout: 15
          maxRequestsPerHostStr: "32"
          namespace:
          image: "jenkins/inbound-agent"
          tag: "4.11.2-4"
          workingDir: "/home/jenkins/agent"
          nodeUsageMode: "NORMAL"
          customJenkinsLabels: []
          # name of the secret to be used for image pulling
          imagePullSecretName:
          componentName: "jenkins-agent"
          websocket: false
          privileged: false
          runAsUser:
          runAsGroup:
          resources:
            requests:
              cpu: "512m"
              memory: "512Mi"
            limits:
              cpu: "512m"
              memory: "512Mi"
          # You may want to change this to true while testing a new image
          alwaysPullImage: false
          # Controls how agent pods are retained after the Jenkins build completes
          # Possible values: Always, Never, OnFailure
          podRetention: "Never"
          # Disable if you do not want the Yaml the agent pod template to show up
          # in the job Console Output. This can be helpful for either security reasons
          # or simply to clean up the output to make it easier to read.
          showRawYaml: true
          # You can define the volumes that you want to mount for this container
          # Allowed types are: ConfigMap, EmptyDir, HostPath, Nfs, PVC, Secret
          # Configure the attributes as they appear in the corresponding Java class for that type
          # https://github.com/jenkinsci/kubernetes-plugin/tree/master/src/main/java/org/csanchez/jenkins/plugins/kubernetes/volumes
          volumes: []
          # - type: ConfigMap
          #   configMapName: myconfigmap
          #   mountPath: /var/myapp/myconfigmap
          # - type: EmptyDir
          #   mountPath: /var/myapp/myemptydir
          #   memory: false
          # - type: HostPath
          #   hostPath: /var/lib/containers
          #   mountPath: /var/myapp/myhostpath
          # - type: Nfs
          #   mountPath: /var/myapp/mynfs
          #   readOnly: false
          #   serverAddress: "192.0.2.0"
          #   serverPath: /var/lib/containers
          # - type: PVC
          #   claimName: mypvc
          #   mountPath: /var/myapp/mypvc
          #   readOnly: false
          # - type: Secret
          #   defaultMode: "600"
          #   mountPath: /var/myapp/mysecret
          #   secretName: mysecret
          # Pod-wide environment, these vars are visible to any container in the agent pod

          # You can define the workspaceVolume that you want to mount for this container
          # Allowed types are: DynamicPVC, EmptyDir, HostPath, Nfs, PVC
          # Configure the attributes as they appear in the corresponding Java class for that type
          # https://github.com/jenkinsci/kubernetes-plugin/tree/master/src/main/java/org/csanchez/jenkins/plugins/kubernetes/volumes/workspace
          workspaceVolume: {}
          ## DynamicPVC example
          # type: DynamicPVC
          # configMapName: myconfigmap
          ## EmptyDir example
          # type: EmptyDir
          # memory: false
          ## HostPath example
          # type: HostPath
          # hostPath: /var/lib/containers
          ## NFS example
          # type: Nfs
          # readOnly: false
          # serverAddress: "192.0.2.0"
          # serverPath: /var/lib/containers
          ## PVC example
          # type: PVC
          # claimName: mypvc
          # readOnly: false
          #
          # Pod-wide environment, these vars are visible to any container in the agent pod
          envVars: []
          # - name: PATH
          #   value: /usr/local/bin
          nodeSelector: {}
          # Key Value selectors. Ex:
          # jenkins-agent: v1

          # Executed command when side container gets started
          command:
          args: "${computer.jnlpmac} ${computer.name}"
          # Side container name
          sideContainerName: "jnlp"
          # Doesn't allocate pseudo TTY by default
          TTYEnabled: false
          # Max number of spawned agent
          containerCap: 10
          # Pod name
          podName: "jenkins-agent"
          # Allows the Pod to remain active for reuse until the configured number of
          # minutes has passed since the last step was executed on it.
          idleMinutes: 5
          # Raw yaml template for the Pod. For example this allows usage of toleration for agent pods.
          # https://github.com/jenkinsci/kubernetes-plugin#using-yaml-to-define-pod-templates
          # https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
          yamlTemplate: ""
          # yamlTemplate: |-
          #   apiVersion: v1
          #   kind: Pod
          #   annotations:
          #     container.apparmor.security.beta.kubernetes.io/jenkins-agent: unconfined
          # Defines how the raw yaml field gets merged with yaml definitions from inherited pod templates: merge or override
          yamlMergeStrategy: "override"
          # Timeout in seconds for an agent to be online
          connectTimeout: 100
          # Annotations to apply to the pod.
          annotations: {
            container.apparmor.security.beta.kubernetes.io/jnlp: unconfined
          }

          # Disable the default Jenkins Agent configuration.
          # Useful when configuring agents only with the podTemplates value, since the default podTemplate populated by values mentioned above will be excluded in the rendered template.
          disableDefaultAgent: false

          # Below is the implementation of custom pod templates for the default configured kubernetes cloud.
          # Add a key under podTemplates for each pod template. Each key (prior to | character) is just a label, and can be any value.
          # Keys are only used to give the pod template a meaningful name.  The only restriction is they may only contain RFC 1123 \ DNS label
          # characters: lowercase letters, numbers, and hyphens. Each pod template can contain multiple containers.
          # For this pod templates configuration to be loaded the following values must be set:
          # controller.JCasC.defaultConfig: true
          # Best reference is https://<jenkins_url>/configuration-as-code/reference#Cloud-kubernetes. The example below creates a python pod template.
          podTemplates: {}
          #  python: |
          #    - name: python
          #      label: jenkins-python
          #      serviceAccount: jenkins
          #      containers:
          #        - name: python
          #          image: python:3
          #          command: "/bin/sh -c"
          #          args: "cat"
          #          ttyEnabled: true
          #          privileged: true
          #          resourceRequestCpu: "400m"
          #          resourceRequestMemory: "512Mi"
          #          resourceLimitCpu: "1"
          #          resourceLimitMemory: "1024Mi"

        # Here you can add additional agents
        # They inherit all values from `agent` so you only need to specify values which differ
        additionalAgents: {}
        #  maven:
        #    podName: maven
        #    customJenkinsLabels: maven
        #    # An example of overriding the jnlp container
        #    # sideContainerName: jnlp
        #    image: jenkins/jnlp-agent-maven
        #    tag: latest
        #  python:
        #    podName: python
        #    customJenkinsLabels: python
        #    sideContainerName: python
        #    image: python
        #    tag: "3"
        #    command: "/bin/sh -c"
        #    args: "cat"
        #    TTYEnabled: true

        persistence:
          enabled: true
          ## A manually managed Persistent Volume and Claim
          ## Requires persistence.enabled: true
          ## If defined, PVC must be created manually before volume will be bound
          existingClaim:
          ## jenkins data Persistent Volume Storage Class
          ## If defined, storageClassName: <storageClass>
          ## If set to "-", storageClassName: "", which disables dynamic provisioning
          ## If undefined (the default) or set to null, no storageClassName spec is
          ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
          ##   GKE, AWS & OpenStack)
          ##
          storageClass:
          annotations: {}
          labels: {}
          accessMode: "ReadWriteOnce"
          size: "10Gi"
          volumes:
          #  - name: nothing
          #    emptyDir: {}
          mounts:
          #  - mountPath: /var/nothing
          #    name: nothing
          #    readOnly: true

        serviceAccount:
          create: false
          # The name of the service account is autogenerated by default
          name: jenkins
          annotations: {}
          imagePullSecretName:
    repoURL: https://charts.jenkins.io
    targetRevision: 4.1.12
  syncPolicy:
    automated: {}
status:
  health:
    status: Healthy
  history:
  - deployStartedAt: "2022-07-17T23:31:17Z"
    deployedAt: "2022-07-17T23:31:19Z"
    id: 20
    revision: 4.1.12
    source:
      chart: jenkins
      helm:
        parameters:
        - name: serviceAccount.create
          value: "false"
        - name: serviceAccount.name
          value: jenkins
        - name: persistence.size
          value: 10Gi
        - name: agent.image
          value: bensonyanger/jenkins-agent
        - name: agent.tag
          value: latest
        - name: agent.privileged
          value: "true"
        - name: agent.alwaysPullImage
          value: "true"
        valueFiles:
        - values.yaml
        values: |
          agent:
            enabled: true
            defaultsProviderTemplate: ""
            # URL for connecting to the Jenkins contoller
            jenkinsUrl:
            # connect to the specified host and port, instead of connecting directly to the Jenkins controller
            jenkinsTunnel:
            kubernetesConnectTimeout: 5
            kubernetesReadTimeout: 15
            maxRequestsPerHostStr: "32"
            namespace:
            image: "jenkins/inbound-agent"
            tag: "4.11.2-4"
            workingDir: "/home/jenkins/agent"
            nodeUsageMode: "NORMAL"
            customJenkinsLabels: []
            # name of the secret to be used for image pulling
            imagePullSecretName:
            componentName: "jenkins-agent"
            websocket: false
            privileged: false
            runAsUser:
            runAsGroup:
            resources:
              requests:
                cpu: "512m"
                memory: "512Mi"
              limits:
                cpu: "512m"
                memory: "512Mi"
            # You may want to change this to true while testing a new image
            alwaysPullImage: false
            # Controls how agent pods are retained after the Jenkins build completes
            # Possible values: Always, Never, OnFailure
            podRetention: "Never"
            # Disable if you do not want the Yaml the agent pod template to show up
            # in the job Console Output. This can be helpful for either security reasons
            # or simply to clean up the output to make it easier to read.
            showRawYaml: true
            # You can define the volumes that you want to mount for this container
            # Allowed types are: ConfigMap, EmptyDir, HostPath, Nfs, PVC, Secret
            # Configure the attributes as they appear in the corresponding Java class for that type
            # https://github.com/jenkinsci/kubernetes-plugin/tree/master/src/main/java/org/csanchez/jenkins/plugins/kubernetes/volumes
            volumes: []
            # - type: ConfigMap
            #   configMapName: myconfigmap
            #   mountPath: /var/myapp/myconfigmap
            # - type: EmptyDir
            #   mountPath: /var/myapp/myemptydir
            #   memory: false
            # - type: HostPath
            #   hostPath: /var/lib/containers
            #   mountPath: /var/myapp/myhostpath
            # - type: Nfs
            #   mountPath: /var/myapp/mynfs
            #   readOnly: false
            #   serverAddress: "192.0.2.0"
            #   serverPath: /var/lib/containers
            # - type: PVC
            #   claimName: mypvc
            #   mountPath: /var/myapp/mypvc
            #   readOnly: false
            # - type: Secret
            #   defaultMode: "600"
            #   mountPath: /var/myapp/mysecret
            #   secretName: mysecret
            # Pod-wide environment, these vars are visible to any container in the agent pod

            # You can define the workspaceVolume that you want to mount for this container
            # Allowed types are: DynamicPVC, EmptyDir, HostPath, Nfs, PVC
            # Configure the attributes as they appear in the corresponding Java class for that type
            # https://github.com/jenkinsci/kubernetes-plugin/tree/master/src/main/java/org/csanchez/jenkins/plugins/kubernetes/volumes/workspace
            workspaceVolume: {}
            ## DynamicPVC example
            # type: DynamicPVC
            # configMapName: myconfigmap
            ## EmptyDir example
            # type: EmptyDir
            # memory: false
            ## HostPath example
            # type: HostPath
            # hostPath: /var/lib/containers
            ## NFS example
            # type: Nfs
            # readOnly: false
            # serverAddress: "192.0.2.0"
            # serverPath: /var/lib/containers
            ## PVC example
            # type: PVC
            # claimName: mypvc
            # readOnly: false
            #
            # Pod-wide environment, these vars are visible to any container in the agent pod
            envVars: []
            # - name: PATH
            #   value: /usr/local/bin
            nodeSelector: {}
            # Key Value selectors. Ex:
            # jenkins-agent: v1

            # Executed command when side container gets started
            command:
            args: "${computer.jnlpmac} ${computer.name}"
            # Side container name
            sideContainerName: "jnlp"
            # Doesn't allocate pseudo TTY by default
            TTYEnabled: false
            # Max number of spawned agent
            containerCap: 10
            # Pod name
            podName: "jenkins-agent"
            # Allows the Pod to remain active for reuse until the configured number of
            # minutes has passed since the last step was executed on it.
            idleMinutes: 10
            # Raw yaml template for the Pod. For example this allows usage of toleration for agent pods.
            # https://github.com/jenkinsci/kubernetes-plugin#using-yaml-to-define-pod-templates
            # https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
            yamlTemplate: ""
            # yamlTemplate: |-
            #   apiVersion: v1
            #   kind: Pod
            #   annotations:
            #     container.apparmor.security.beta.kubernetes.io/jenkins-agent: unconfined
            # Defines how the raw yaml field gets merged with yaml definitions from inherited pod templates: merge or override
            yamlMergeStrategy: "override"
            # Timeout in seconds for an agent to be online
            connectTimeout: 100
            # Annotations to apply to the pod.
            annotations: {
              container.apparmor.security.beta.kubernetes.io/jnlp: unconfined
            }

            # Disable the default Jenkins Agent configuration.
            # Useful when configuring agents only with the podTemplates value, since the default podTemplate populated by values mentioned above will be excluded in the rendered template.
            disableDefaultAgent: false

            # Below is the implementation of custom pod templates for the default configured kubernetes cloud.
            # Add a key under podTemplates for each pod template. Each key (prior to | character) is just a label, and can be any value.
            # Keys are only used to give the pod template a meaningful name.  The only restriction is they may only contain RFC 1123 \ DNS label
            # characters: lowercase letters, numbers, and hyphens. Each pod template can contain multiple containers.
            # For this pod templates configuration to be loaded the following values must be set:
            # controller.JCasC.defaultConfig: true
            # Best reference is https://<jenkins_url>/configuration-as-code/reference#Cloud-kubernetes. The example below creates a python pod template.
            podTemplates: {}
            #  python: |
            #    - name: python
            #      label: jenkins-python
            #      serviceAccount: jenkins
            #      containers:
            #        - name: python
            #          image: python:3
            #          command: "/bin/sh -c"
            #          args: "cat"
            #          ttyEnabled: true
            #          privileged: true
            #          resourceRequestCpu: "400m"
            #          resourceRequestMemory: "512Mi"
            #          resourceLimitCpu: "1"
            #          resourceLimitMemory: "1024Mi"

          # Here you can add additional agents
          # They inherit all values from `agent` so you only need to specify values which differ
          additionalAgents: {}
          #  maven:
          #    podName: maven
          #    customJenkinsLabels: maven
          #    # An example of overriding the jnlp container
          #    # sideContainerName: jnlp
          #    image: jenkins/jnlp-agent-maven
          #    tag: latest
          #  python:
          #    podName: python
          #    customJenkinsLabels: python
          #    sideContainerName: python
          #    image: python
          #    tag: "3"
          #    command: "/bin/sh -c"
          #    args: "cat"
          #    TTYEnabled: true

          persistence:
            enabled: true
            ## A manually managed Persistent Volume and Claim
            ## Requires persistence.enabled: true
            ## If defined, PVC must be created manually before volume will be bound
            existingClaim:
            ## jenkins data Persistent Volume Storage Class
            ## If defined, storageClassName: <storageClass>
            ## If set to "-", storageClassName: "", which disables dynamic provisioning
            ## If undefined (the default) or set to null, no storageClassName spec is
            ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
            ##   GKE, AWS & OpenStack)
            ##
            storageClass:
            annotations: {}
            labels: {}
            accessMode: "ReadWriteOnce"
            size: "10Gi"
            volumes:
            #  - name: nothing
            #    emptyDir: {}
            mounts:
            #  - mountPath: /var/nothing
            #    name: nothing
            #    readOnly: true

          serviceAccount:
            create: false
            # The name of the service account is autogenerated by default
            name: jenkins
            annotations: {}
            imagePullSecretName:
      repoURL: https://charts.jenkins.io
      targetRevision: 4.1.12
  - deployStartedAt: "2022-07-17T23:37:17Z"
    deployedAt: "2022-07-17T23:37:19Z"
    id: 21
    revision: 4.1.12
    source:
      chart: jenkins
      helm:
        parameters:
        - name: serviceAccount.create
          value: "false"
        - name: serviceAccount.name
          value: jenkins
        - name: persistence.size
          value: 10Gi
        - name: agent.image
          value: bensonyanger/jenkins-agent
        - name: agent.tag
          value: latest
        - name: agent.privileged
          value: "true"
        - name: agent.alwaysPullImage
          value: "false"
        valueFiles:
        - values.yaml
        values: |
          agent:
            enabled: true
            defaultsProviderTemplate: ""
            # URL for connecting to the Jenkins contoller
            jenkinsUrl:
            # connect to the specified host and port, instead of connecting directly to the Jenkins controller
            jenkinsTunnel:
            kubernetesConnectTimeout: 5
            kubernetesReadTimeout: 15
            maxRequestsPerHostStr: "32"
            namespace:
            image: "jenkins/inbound-agent"
            tag: "4.11.2-4"
            workingDir: "/home/jenkins/agent"
            nodeUsageMode: "NORMAL"
            customJenkinsLabels: []
            # name of the secret to be used for image pulling
            imagePullSecretName:
            componentName: "jenkins-agent"
            websocket: false
            privileged: false
            runAsUser:
            runAsGroup:
            resources:
              requests:
                cpu: "512m"
                memory: "512Mi"
              limits:
                cpu: "512m"
                memory: "512Mi"
            # You may want to change this to true while testing a new image
            alwaysPullImage: false
            # Controls how agent pods are retained after the Jenkins build completes
            # Possible values: Always, Never, OnFailure
            podRetention: "Never"
            # Disable if you do not want the Yaml the agent pod template to show up
            # in the job Console Output. This can be helpful for either security reasons
            # or simply to clean up the output to make it easier to read.
            showRawYaml: true
            # You can define the volumes that you want to mount for this container
            # Allowed types are: ConfigMap, EmptyDir, HostPath, Nfs, PVC, Secret
            # Configure the attributes as they appear in the corresponding Java class for that type
            # https://github.com/jenkinsci/kubernetes-plugin/tree/master/src/main/java/org/csanchez/jenkins/plugins/kubernetes/volumes
            volumes: []
            # - type: ConfigMap
            #   configMapName: myconfigmap
            #   mountPath: /var/myapp/myconfigmap
            # - type: EmptyDir
            #   mountPath: /var/myapp/myemptydir
            #   memory: false
            # - type: HostPath
            #   hostPath: /var/lib/containers
            #   mountPath: /var/myapp/myhostpath
            # - type: Nfs
            #   mountPath: /var/myapp/mynfs
            #   readOnly: false
            #   serverAddress: "192.0.2.0"
            #   serverPath: /var/lib/containers
            # - type: PVC
            #   claimName: mypvc
            #   mountPath: /var/myapp/mypvc
            #   readOnly: false
            # - type: Secret
            #   defaultMode: "600"
            #   mountPath: /var/myapp/mysecret
            #   secretName: mysecret
            # Pod-wide environment, these vars are visible to any container in the agent pod

            # You can define the workspaceVolume that you want to mount for this container
            # Allowed types are: DynamicPVC, EmptyDir, HostPath, Nfs, PVC
            # Configure the attributes as they appear in the corresponding Java class for that type
            # https://github.com/jenkinsci/kubernetes-plugin/tree/master/src/main/java/org/csanchez/jenkins/plugins/kubernetes/volumes/workspace
            workspaceVolume: {}
            ## DynamicPVC example
            # type: DynamicPVC
            # configMapName: myconfigmap
            ## EmptyDir example
            # type: EmptyDir
            # memory: false
            ## HostPath example
            # type: HostPath
            # hostPath: /var/lib/containers
            ## NFS example
            # type: Nfs
            # readOnly: false
            # serverAddress: "192.0.2.0"
            # serverPath: /var/lib/containers
            ## PVC example
            # type: PVC
            # claimName: mypvc
            # readOnly: false
            #
            # Pod-wide environment, these vars are visible to any container in the agent pod
            envVars: []
            # - name: PATH
            #   value: /usr/local/bin
            nodeSelector: {}
            # Key Value selectors. Ex:
            # jenkins-agent: v1

            # Executed command when side container gets started
            command:
            args: "${computer.jnlpmac} ${computer.name}"
            # Side container name
            sideContainerName: "jnlp"
            # Doesn't allocate pseudo TTY by default
            TTYEnabled: false
            # Max number of spawned agent
            containerCap: 10
            # Pod name
            podName: "jenkins-agent"
            # Allows the Pod to remain active for reuse until the configured number of
            # minutes has passed since the last step was executed on it.
            idleMinutes: 10
            # Raw yaml template for the Pod. For example this allows usage of toleration for agent pods.
            # https://github.com/jenkinsci/kubernetes-plugin#using-yaml-to-define-pod-templates
            # https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
            yamlTemplate: ""
            # yamlTemplate: |-
            #   apiVersion: v1
            #   kind: Pod
            #   annotations:
            #     container.apparmor.security.beta.kubernetes.io/jenkins-agent: unconfined
            # Defines how the raw yaml field gets merged with yaml definitions from inherited pod templates: merge or override
            yamlMergeStrategy: "override"
            # Timeout in seconds for an agent to be online
            connectTimeout: 100
            # Annotations to apply to the pod.
            annotations: {
              container.apparmor.security.beta.kubernetes.io/jnlp: unconfined
            }

            # Disable the default Jenkins Agent configuration.
            # Useful when configuring agents only with the podTemplates value, since the default podTemplate populated by values mentioned above will be excluded in the rendered template.
            disableDefaultAgent: false

            # Below is the implementation of custom pod templates for the default configured kubernetes cloud.
            # Add a key under podTemplates for each pod template. Each key (prior to | character) is just a label, and can be any value.
            # Keys are only used to give the pod template a meaningful name.  The only restriction is they may only contain RFC 1123 \ DNS label
            # characters: lowercase letters, numbers, and hyphens. Each pod template can contain multiple containers.
            # For this pod templates configuration to be loaded the following values must be set:
            # controller.JCasC.defaultConfig: true
            # Best reference is https://<jenkins_url>/configuration-as-code/reference#Cloud-kubernetes. The example below creates a python pod template.
            podTemplates: {}
            #  python: |
            #    - name: python
            #      label: jenkins-python
            #      serviceAccount: jenkins
            #      containers:
            #        - name: python
            #          image: python:3
            #          command: "/bin/sh -c"
            #          args: "cat"
            #          ttyEnabled: true
            #          privileged: true
            #          resourceRequestCpu: "400m"
            #          resourceRequestMemory: "512Mi"
            #          resourceLimitCpu: "1"
            #          resourceLimitMemory: "1024Mi"

          # Here you can add additional agents
          # They inherit all values from `agent` so you only need to specify values which differ
          additionalAgents: {}
          #  maven:
          #    podName: maven
          #    customJenkinsLabels: maven
          #    # An example of overriding the jnlp container
          #    # sideContainerName: jnlp
          #    image: jenkins/jnlp-agent-maven
          #    tag: latest
          #  python:
          #    podName: python
          #    customJenkinsLabels: python
          #    sideContainerName: python
          #    image: python
          #    tag: "3"
          #    command: "/bin/sh -c"
          #    args: "cat"
          #    TTYEnabled: true

          persistence:
            enabled: true
            ## A manually managed Persistent Volume and Claim
            ## Requires persistence.enabled: true
            ## If defined, PVC must be created manually before volume will be bound
            existingClaim:
            ## jenkins data Persistent Volume Storage Class
            ## If defined, storageClassName: <storageClass>
            ## If set to "-", storageClassName: "", which disables dynamic provisioning
            ## If undefined (the default) or set to null, no storageClassName spec is
            ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
            ##   GKE, AWS & OpenStack)
            ##
            storageClass:
            annotations: {}
            labels: {}
            accessMode: "ReadWriteOnce"
            size: "10Gi"
            volumes:
            #  - name: nothing
            #    emptyDir: {}
            mounts:
            #  - mountPath: /var/nothing
            #    name: nothing
            #    readOnly: true

          serviceAccount:
            create: false
            # The name of the service account is autogenerated by default
            name: jenkins
            annotations: {}
            imagePullSecretName:
      repoURL: https://charts.jenkins.io
      targetRevision: 4.1.12
  - deployStartedAt: "2022-07-17T23:37:37Z"
    deployedAt: "2022-07-17T23:37:38Z"
    id: 22
    revision: 4.1.12
    source:
      chart: jenkins
      helm:
        parameters:
        - name: serviceAccount.create
          value: "false"
        - name: serviceAccount.name
          value: jenkins
        - name: persistence.size
          value: 10Gi
        - name: agent.image
          value: bensonyanger/jenkins-agent
        - name: agent.tag
          value: latest
        - name: agent.privileged
          value: "true"
        - name: agent.alwaysPullImage
          value: "true"
        valueFiles:
        - values.yaml
        values: |
          agent:
            enabled: true
            defaultsProviderTemplate: ""
            # URL for connecting to the Jenkins contoller
            jenkinsUrl:
            # connect to the specified host and port, instead of connecting directly to the Jenkins controller
            jenkinsTunnel:
            kubernetesConnectTimeout: 5
            kubernetesReadTimeout: 15
            maxRequestsPerHostStr: "32"
            namespace:
            image: "jenkins/inbound-agent"
            tag: "4.11.2-4"
            workingDir: "/home/jenkins/agent"
            nodeUsageMode: "NORMAL"
            customJenkinsLabels: []
            # name of the secret to be used for image pulling
            imagePullSecretName:
            componentName: "jenkins-agent"
            websocket: false
            privileged: false
            runAsUser:
            runAsGroup:
            resources:
              requests:
                cpu: "512m"
                memory: "512Mi"
              limits:
                cpu: "512m"
                memory: "512Mi"
            # You may want to change this to true while testing a new image
            alwaysPullImage: false
            # Controls how agent pods are retained after the Jenkins build completes
            # Possible values: Always, Never, OnFailure
            podRetention: "Never"
            # Disable if you do not want the Yaml the agent pod template to show up
            # in the job Console Output. This can be helpful for either security reasons
            # or simply to clean up the output to make it easier to read.
            showRawYaml: true
            # You can define the volumes that you want to mount for this container
            # Allowed types are: ConfigMap, EmptyDir, HostPath, Nfs, PVC, Secret
            # Configure the attributes as they appear in the corresponding Java class for that type
            # https://github.com/jenkinsci/kubernetes-plugin/tree/master/src/main/java/org/csanchez/jenkins/plugins/kubernetes/volumes
            volumes: []
            # - type: ConfigMap
            #   configMapName: myconfigmap
            #   mountPath: /var/myapp/myconfigmap
            # - type: EmptyDir
            #   mountPath: /var/myapp/myemptydir
            #   memory: false
            # - type: HostPath
            #   hostPath: /var/lib/containers
            #   mountPath: /var/myapp/myhostpath
            # - type: Nfs
            #   mountPath: /var/myapp/mynfs
            #   readOnly: false
            #   serverAddress: "192.0.2.0"
            #   serverPath: /var/lib/containers
            # - type: PVC
            #   claimName: mypvc
            #   mountPath: /var/myapp/mypvc
            #   readOnly: false
            # - type: Secret
            #   defaultMode: "600"
            #   mountPath: /var/myapp/mysecret
            #   secretName: mysecret
            # Pod-wide environment, these vars are visible to any container in the agent pod

            # You can define the workspaceVolume that you want to mount for this container
            # Allowed types are: DynamicPVC, EmptyDir, HostPath, Nfs, PVC
            # Configure the attributes as they appear in the corresponding Java class for that type
            # https://github.com/jenkinsci/kubernetes-plugin/tree/master/src/main/java/org/csanchez/jenkins/plugins/kubernetes/volumes/workspace
            workspaceVolume: {}
            ## DynamicPVC example
            # type: DynamicPVC
            # configMapName: myconfigmap
            ## EmptyDir example
            # type: EmptyDir
            # memory: false
            ## HostPath example
            # type: HostPath
            # hostPath: /var/lib/containers
            ## NFS example
            # type: Nfs
            # readOnly: false
            # serverAddress: "192.0.2.0"
            # serverPath: /var/lib/containers
            ## PVC example
            # type: PVC
            # claimName: mypvc
            # readOnly: false
            #
            # Pod-wide environment, these vars are visible to any container in the agent pod
            envVars: []
            # - name: PATH
            #   value: /usr/local/bin
            nodeSelector: {}
            # Key Value selectors. Ex:
            # jenkins-agent: v1

            # Executed command when side container gets started
            command:
            args: "${computer.jnlpmac} ${computer.name}"
            # Side container name
            sideContainerName: "jnlp"
            # Doesn't allocate pseudo TTY by default
            TTYEnabled: false
            # Max number of spawned agent
            containerCap: 10
            # Pod name
            podName: "jenkins-agent"
            # Allows the Pod to remain active for reuse until the configured number of
            # minutes has passed since the last step was executed on it.
            idleMinutes: 10
            # Raw yaml template for the Pod. For example this allows usage of toleration for agent pods.
            # https://github.com/jenkinsci/kubernetes-plugin#using-yaml-to-define-pod-templates
            # https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
            yamlTemplate: ""
            # yamlTemplate: |-
            #   apiVersion: v1
            #   kind: Pod
            #   annotations:
            #     container.apparmor.security.beta.kubernetes.io/jenkins-agent: unconfined
            # Defines how the raw yaml field gets merged with yaml definitions from inherited pod templates: merge or override
            yamlMergeStrategy: "override"
            # Timeout in seconds for an agent to be online
            connectTimeout: 100
            # Annotations to apply to the pod.
            annotations: {
              container.apparmor.security.beta.kubernetes.io/jnlp: unconfined
            }

            # Disable the default Jenkins Agent configuration.
            # Useful when configuring agents only with the podTemplates value, since the default podTemplate populated by values mentioned above will be excluded in the rendered template.
            disableDefaultAgent: false

            # Below is the implementation of custom pod templates for the default configured kubernetes cloud.
            # Add a key under podTemplates for each pod template. Each key (prior to | character) is just a label, and can be any value.
            # Keys are only used to give the pod template a meaningful name.  The only restriction is they may only contain RFC 1123 \ DNS label
            # characters: lowercase letters, numbers, and hyphens. Each pod template can contain multiple containers.
            # For this pod templates configuration to be loaded the following values must be set:
            # controller.JCasC.defaultConfig: true
            # Best reference is https://<jenkins_url>/configuration-as-code/reference#Cloud-kubernetes. The example below creates a python pod template.
            podTemplates: {}
            #  python: |
            #    - name: python
            #      label: jenkins-python
            #      serviceAccount: jenkins
            #      containers:
            #        - name: python
            #          image: python:3
            #          command: "/bin/sh -c"
            #          args: "cat"
            #          ttyEnabled: true
            #          privileged: true
            #          resourceRequestCpu: "400m"
            #          resourceRequestMemory: "512Mi"
            #          resourceLimitCpu: "1"
            #          resourceLimitMemory: "1024Mi"

          # Here you can add additional agents
          # They inherit all values from `agent` so you only need to specify values which differ
          additionalAgents: {}
          #  maven:
          #    podName: maven
          #    customJenkinsLabels: maven
          #    # An example of overriding the jnlp container
          #    # sideContainerName: jnlp
          #    image: jenkins/jnlp-agent-maven
          #    tag: latest
          #  python:
          #    podName: python
          #    customJenkinsLabels: python
          #    sideContainerName: python
          #    image: python
          #    tag: "3"
          #    command: "/bin/sh -c"
          #    args: "cat"
          #    TTYEnabled: true

          persistence:
            enabled: true
            ## A manually managed Persistent Volume and Claim
            ## Requires persistence.enabled: true
            ## If defined, PVC must be created manually before volume will be bound
            existingClaim:
            ## jenkins data Persistent Volume Storage Class
            ## If defined, storageClassName: <storageClass>
            ## If set to "-", storageClassName: "", which disables dynamic provisioning
            ## If undefined (the default) or set to null, no storageClassName spec is
            ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
            ##   GKE, AWS & OpenStack)
            ##
            storageClass:
            annotations: {}
            labels: {}
            accessMode: "ReadWriteOnce"
            size: "10Gi"
            volumes:
            #  - name: nothing
            #    emptyDir: {}
            mounts:
            #  - mountPath: /var/nothing
            #    name: nothing
            #    readOnly: true

          serviceAccount:
            create: false
            # The name of the service account is autogenerated by default
            name: jenkins
            annotations: {}
            imagePullSecretName:
      repoURL: https://charts.jenkins.io
      targetRevision: 4.1.12
  - deployStartedAt: "2022-07-17T23:42:57Z"
    deployedAt: "2022-07-17T23:42:58Z"
    id: 23
    revision: 4.1.12
    source:
      chart: jenkins
      helm:
        parameters:
        - name: serviceAccount.create
          value: "false"
        - name: serviceAccount.name
          value: jenkins
        - name: persistence.size
          value: 10Gi
        - name: agent.image
          value: bensonyanger/jenkins-agent
        - name: agent.tag
          value: latest
        - name: agent.privileged
          value: "true"
        - name: agent.alwaysPullImage
          value: "true"
        valueFiles:
        - values.yaml
        values: |
          agent:
            enabled: true
            defaultsProviderTemplate: ""
            # URL for connecting to the Jenkins contoller
            jenkinsUrl:
            # connect to the specified host and port, instead of connecting directly to the Jenkins controller
            jenkinsTunnel:
            kubernetesConnectTimeout: 5
            kubernetesReadTimeout: 15
            maxRequestsPerHostStr: "32"
            namespace:
            image: "jenkins/inbound-agent"
            tag: "4.11.2-4"
            workingDir: "/home/jenkins/agent"
            nodeUsageMode: "NORMAL"
            customJenkinsLabels: []
            # name of the secret to be used for image pulling
            imagePullSecretName:
            componentName: "jenkins-agent"
            websocket: false
            privileged: false
            runAsUser:
            runAsGroup:
            resources:
              requests:
                cpu: "512m"
                memory: "512Mi"
              limits:
                cpu: "512m"
                memory: "512Mi"
            # You may want to change this to true while testing a new image
            alwaysPullImage: false
            # Controls how agent pods are retained after the Jenkins build completes
            # Possible values: Always, Never, OnFailure
            podRetention: "Never"
            # Disable if you do not want the Yaml the agent pod template to show up
            # in the job Console Output. This can be helpful for either security reasons
            # or simply to clean up the output to make it easier to read.
            showRawYaml: true
            # You can define the volumes that you want to mount for this container
            # Allowed types are: ConfigMap, EmptyDir, HostPath, Nfs, PVC, Secret
            # Configure the attributes as they appear in the corresponding Java class for that type
            # https://github.com/jenkinsci/kubernetes-plugin/tree/master/src/main/java/org/csanchez/jenkins/plugins/kubernetes/volumes
            volumes:
              - type: EmptyDir
                mountpath: /var/lib/docker
                memory: false
            # - type: ConfigMap
            #   configMapName: myconfigmap
            #   mountPath: /var/myapp/myconfigmap
            # - type: EmptyDir
            #   mountPath: /var/myapp/myemptydir
            #   memory: false
            # - type: HostPath
            #   hostPath: /var/lib/containers
            #   mountPath: /var/myapp/myhostpath
            # - type: Nfs
            #   mountPath: /var/myapp/mynfs
            #   readOnly: false
            #   serverAddress: "192.0.2.0"
            #   serverPath: /var/lib/containers
            # - type: PVC
            #   claimName: mypvc
            #   mountPath: /var/myapp/mypvc
            #   readOnly: false
            # - type: Secret
            #   defaultMode: "600"
            #   mountPath: /var/myapp/mysecret
            #   secretName: mysecret
            # Pod-wide environment, these vars are visible to any container in the agent pod

            # You can define the workspaceVolume that you want to mount for this container
            # Allowed types are: DynamicPVC, EmptyDir, HostPath, Nfs, PVC
            # Configure the attributes as they appear in the corresponding Java class for that type
            # https://github.com/jenkinsci/kubernetes-plugin/tree/master/src/main/java/org/csanchez/jenkins/plugins/kubernetes/volumes/workspace
            workspaceVolume: {}
            ## DynamicPVC example
            # type: DynamicPVC
            # configMapName: myconfigmap
            ## EmptyDir example
            # type: EmptyDir
            # memory: false
            ## HostPath example
            # type: HostPath
            # hostPath: /var/lib/containers
            ## NFS example
            # type: Nfs
            # readOnly: false
            # serverAddress: "192.0.2.0"
            # serverPath: /var/lib/containers
            ## PVC example
            # type: PVC
            # claimName: mypvc
            # readOnly: false
            #
            # Pod-wide environment, these vars are visible to any container in the agent pod
            envVars: []
            # - name: PATH
            #   value: /usr/local/bin
            nodeSelector: {}
            # Key Value selectors. Ex:
            # jenkins-agent: v1

            # Executed command when side container gets started
            command:
            args: "${computer.jnlpmac} ${computer.name}"
            # Side container name
            sideContainerName: "jnlp"
            # Doesn't allocate pseudo TTY by default
            TTYEnabled: false
            # Max number of spawned agent
            containerCap: 10
            # Pod name
            podName: "jenkins-agent"
            # Allows the Pod to remain active for reuse until the configured number of
            # minutes has passed since the last step was executed on it.
            idleMinutes: 10
            # Raw yaml template for the Pod. For example this allows usage of toleration for agent pods.
            # https://github.com/jenkinsci/kubernetes-plugin#using-yaml-to-define-pod-templates
            # https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
            yamlTemplate: ""
            # yamlTemplate: |-
            #   apiVersion: v1
            #   kind: Pod
            #   annotations:
            #     container.apparmor.security.beta.kubernetes.io/jenkins-agent: unconfined
            # Defines how the raw yaml field gets merged with yaml definitions from inherited pod templates: merge or override
            yamlMergeStrategy: "override"
            # Timeout in seconds for an agent to be online
            connectTimeout: 100
            # Annotations to apply to the pod.
            annotations: {
              container.apparmor.security.beta.kubernetes.io/jnlp: unconfined
            }

            # Disable the default Jenkins Agent configuration.
            # Useful when configuring agents only with the podTemplates value, since the default podTemplate populated by values mentioned above will be excluded in the rendered template.
            disableDefaultAgent: false

            # Below is the implementation of custom pod templates for the default configured kubernetes cloud.
            # Add a key under podTemplates for each pod template. Each key (prior to | character) is just a label, and can be any value.
            # Keys are only used to give the pod template a meaningful name.  The only restriction is they may only contain RFC 1123 \ DNS label
            # characters: lowercase letters, numbers, and hyphens. Each pod template can contain multiple containers.
            # For this pod templates configuration to be loaded the following values must be set:
            # controller.JCasC.defaultConfig: true
            # Best reference is https://<jenkins_url>/configuration-as-code/reference#Cloud-kubernetes. The example below creates a python pod template.
            podTemplates: {}
            #  python: |
            #    - name: python
            #      label: jenkins-python
            #      serviceAccount: jenkins
            #      containers:
            #        - name: python
            #          image: python:3
            #          command: "/bin/sh -c"
            #          args: "cat"
            #          ttyEnabled: true
            #          privileged: true
            #          resourceRequestCpu: "400m"
            #          resourceRequestMemory: "512Mi"
            #          resourceLimitCpu: "1"
            #          resourceLimitMemory: "1024Mi"

          # Here you can add additional agents
          # They inherit all values from `agent` so you only need to specify values which differ
          additionalAgents: {}
          #  maven:
          #    podName: maven
          #    customJenkinsLabels: maven
          #    # An example of overriding the jnlp container
          #    # sideContainerName: jnlp
          #    image: jenkins/jnlp-agent-maven
          #    tag: latest
          #  python:
          #    podName: python
          #    customJenkinsLabels: python
          #    sideContainerName: python
          #    image: python
          #    tag: "3"
          #    command: "/bin/sh -c"
          #    args: "cat"
          #    TTYEnabled: true

          persistence:
            enabled: true
            ## A manually managed Persistent Volume and Claim
            ## Requires persistence.enabled: true
            ## If defined, PVC must be created manually before volume will be bound
            existingClaim:
            ## jenkins data Persistent Volume Storage Class
            ## If defined, storageClassName: <storageClass>
            ## If set to "-", storageClassName: "", which disables dynamic provisioning
            ## If undefined (the default) or set to null, no storageClassName spec is
            ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
            ##   GKE, AWS & OpenStack)
            ##
            storageClass:
            annotations: {}
            labels: {}
            accessMode: "ReadWriteOnce"
            size: "10Gi"
            volumes:
            #  - name: nothing
            #    emptyDir: {}
            mounts:
            #  - mountPath: /var/nothing
            #    name: nothing
            #    readOnly: true

          serviceAccount:
            create: false
            # The name of the service account is autogenerated by default
            name: jenkins
            annotations: {}
            imagePullSecretName:
      repoURL: https://charts.jenkins.io
      targetRevision: 4.1.12
  - deployStartedAt: "2022-07-17T23:43:25Z"
    deployedAt: "2022-07-17T23:43:26Z"
    id: 24
    revision: 4.1.12
    source:
      chart: jenkins
      helm:
        parameters:
        - name: serviceAccount.create
          value: "false"
        - name: serviceAccount.name
          value: jenkins
        - name: persistence.size
          value: 10Gi
        - name: agent.image
          value: bensonyanger/jenkins-agent
        - name: agent.tag
          value: latest
        - name: agent.privileged
          value: "true"
        - name: agent.alwaysPullImage
          value: "true"
        valueFiles:
        - values.yaml
        values: |
          agent:
            enabled: true
            defaultsProviderTemplate: ""
            # URL for connecting to the Jenkins contoller
            jenkinsUrl:
            # connect to the specified host and port, instead of connecting directly to the Jenkins controller
            jenkinsTunnel:
            kubernetesConnectTimeout: 5
            kubernetesReadTimeout: 15
            maxRequestsPerHostStr: "32"
            namespace:
            image: "jenkins/inbound-agent"
            tag: "4.11.2-4"
            workingDir: "/home/jenkins/agent"
            nodeUsageMode: "NORMAL"
            customJenkinsLabels: []
            # name of the secret to be used for image pulling
            imagePullSecretName:
            componentName: "jenkins-agent"
            websocket: false
            privileged: false
            runAsUser:
            runAsGroup:
            resources:
              requests:
                cpu: "512m"
                memory: "512Mi"
              limits:
                cpu: "512m"
                memory: "512Mi"
            # You may want to change this to true while testing a new image
            alwaysPullImage: false
            # Controls how agent pods are retained after the Jenkins build completes
            # Possible values: Always, Never, OnFailure
            podRetention: "Never"
            # Disable if you do not want the Yaml the agent pod template to show up
            # in the job Console Output. This can be helpful for either security reasons
            # or simply to clean up the output to make it easier to read.
            showRawYaml: true
            # You can define the volumes that you want to mount for this container
            # Allowed types are: ConfigMap, EmptyDir, HostPath, Nfs, PVC, Secret
            # Configure the attributes as they appear in the corresponding Java class for that type
            # https://github.com/jenkinsci/kubernetes-plugin/tree/master/src/main/java/org/csanchez/jenkins/plugins/kubernetes/volumes
            volumes:
              - type: EmptyDir
                mountpath: /var/lib/docker
                memory: false
            # - type: ConfigMap
            #   configMapName: myconfigmap
            #   mountPath: /var/myapp/myconfigmap
            # - type: EmptyDir
            #   mountPath: /var/myapp/myemptydir
            #   memory: false
            # - type: HostPath
            #   hostPath: /var/lib/containers
            #   mountPath: /var/myapp/myhostpath
            # - type: Nfs
            #   mountPath: /var/myapp/mynfs
            #   readOnly: false
            #   serverAddress: "192.0.2.0"
            #   serverPath: /var/lib/containers
            # - type: PVC
            #   claimName: mypvc
            #   mountPath: /var/myapp/mypvc
            #   readOnly: false
            # - type: Secret
            #   defaultMode: "600"
            #   mountPath: /var/myapp/mysecret
            #   secretName: mysecret
            # Pod-wide environment, these vars are visible to any container in the agent pod

            # You can define the workspaceVolume that you want to mount for this container
            # Allowed types are: DynamicPVC, EmptyDir, HostPath, Nfs, PVC
            # Configure the attributes as they appear in the corresponding Java class for that type
            # https://github.com/jenkinsci/kubernetes-plugin/tree/master/src/main/java/org/csanchez/jenkins/plugins/kubernetes/volumes/workspace
            workspaceVolume: {}
            ## DynamicPVC example
            # type: DynamicPVC
            # configMapName: myconfigmap
            ## EmptyDir example
            # type: EmptyDir
            # memory: false
            ## HostPath example
            # type: HostPath
            # hostPath: /var/lib/containers
            ## NFS example
            # type: Nfs
            # readOnly: false
            # serverAddress: "192.0.2.0"
            # serverPath: /var/lib/containers
            ## PVC example
            # type: PVC
            # claimName: mypvc
            # readOnly: false
            #
            # Pod-wide environment, these vars are visible to any container in the agent pod
            envVars: []
            # - name: PATH
            #   value: /usr/local/bin
            nodeSelector: {}
            # Key Value selectors. Ex:
            # jenkins-agent: v1

            # Executed command when side container gets started
            command:
            args: "${computer.jnlpmac} ${computer.name}"
            # Side container name
            sideContainerName: "jnlp"
            # Doesn't allocate pseudo TTY by default
            TTYEnabled: false
            # Max number of spawned agent
            containerCap: 10
            # Pod name
            podName: "jenkins-agent"
            # Allows the Pod to remain active for reuse until the configured number of
            # minutes has passed since the last step was executed on it.
            idleMinutes: 5
            # Raw yaml template for the Pod. For example this allows usage of toleration for agent pods.
            # https://github.com/jenkinsci/kubernetes-plugin#using-yaml-to-define-pod-templates
            # https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
            yamlTemplate: ""
            # yamlTemplate: |-
            #   apiVersion: v1
            #   kind: Pod
            #   annotations:
            #     container.apparmor.security.beta.kubernetes.io/jenkins-agent: unconfined
            # Defines how the raw yaml field gets merged with yaml definitions from inherited pod templates: merge or override
            yamlMergeStrategy: "override"
            # Timeout in seconds for an agent to be online
            connectTimeout: 100
            # Annotations to apply to the pod.
            annotations: {
              container.apparmor.security.beta.kubernetes.io/jnlp: unconfined
            }

            # Disable the default Jenkins Agent configuration.
            # Useful when configuring agents only with the podTemplates value, since the default podTemplate populated by values mentioned above will be excluded in the rendered template.
            disableDefaultAgent: false

            # Below is the implementation of custom pod templates for the default configured kubernetes cloud.
            # Add a key under podTemplates for each pod template. Each key (prior to | character) is just a label, and can be any value.
            # Keys are only used to give the pod template a meaningful name.  The only restriction is they may only contain RFC 1123 \ DNS label
            # characters: lowercase letters, numbers, and hyphens. Each pod template can contain multiple containers.
            # For this pod templates configuration to be loaded the following values must be set:
            # controller.JCasC.defaultConfig: true
            # Best reference is https://<jenkins_url>/configuration-as-code/reference#Cloud-kubernetes. The example below creates a python pod template.
            podTemplates: {}
            #  python: |
            #    - name: python
            #      label: jenkins-python
            #      serviceAccount: jenkins
            #      containers:
            #        - name: python
            #          image: python:3
            #          command: "/bin/sh -c"
            #          args: "cat"
            #          ttyEnabled: true
            #          privileged: true
            #          resourceRequestCpu: "400m"
            #          resourceRequestMemory: "512Mi"
            #          resourceLimitCpu: "1"
            #          resourceLimitMemory: "1024Mi"

          # Here you can add additional agents
          # They inherit all values from `agent` so you only need to specify values which differ
          additionalAgents: {}
          #  maven:
          #    podName: maven
          #    customJenkinsLabels: maven
          #    # An example of overriding the jnlp container
          #    # sideContainerName: jnlp
          #    image: jenkins/jnlp-agent-maven
          #    tag: latest
          #  python:
          #    podName: python
          #    customJenkinsLabels: python
          #    sideContainerName: python
          #    image: python
          #    tag: "3"
          #    command: "/bin/sh -c"
          #    args: "cat"
          #    TTYEnabled: true

          persistence:
            enabled: true
            ## A manually managed Persistent Volume and Claim
            ## Requires persistence.enabled: true
            ## If defined, PVC must be created manually before volume will be bound
            existingClaim:
            ## jenkins data Persistent Volume Storage Class
            ## If defined, storageClassName: <storageClass>
            ## If set to "-", storageClassName: "", which disables dynamic provisioning
            ## If undefined (the default) or set to null, no storageClassName spec is
            ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
            ##   GKE, AWS & OpenStack)
            ##
            storageClass:
            annotations: {}
            labels: {}
            accessMode: "ReadWriteOnce"
            size: "10Gi"
            volumes:
            #  - name: nothing
            #    emptyDir: {}
            mounts:
            #  - mountPath: /var/nothing
            #    name: nothing
            #    readOnly: true

          serviceAccount:
            create: false
            # The name of the service account is autogenerated by default
            name: jenkins
            annotations: {}
            imagePullSecretName:
      repoURL: https://charts.jenkins.io
      targetRevision: 4.1.12
  - deployStartedAt: "2022-07-18T00:33:10Z"
    deployedAt: "2022-07-18T00:33:11Z"
    id: 25
    revision: 4.1.12
    source:
      chart: jenkins
      helm:
        parameters:
        - name: serviceAccount.create
          value: "false"
        - name: serviceAccount.name
          value: jenkins
        - name: persistence.size
          value: 10Gi
        - name: agent.privileged
          value: "true"
        - name: agent.alwaysPullImage
          value: "true"
        valueFiles:
        - values.yaml
        values: |
          agent:
            enabled: true
            defaultsProviderTemplate: ""
            # URL for connecting to the Jenkins contoller
            jenkinsUrl:
            # connect to the specified host and port, instead of connecting directly to the Jenkins controller
            jenkinsTunnel:
            kubernetesConnectTimeout: 5
            kubernetesReadTimeout: 15
            maxRequestsPerHostStr: "32"
            namespace:
            image: "jenkins/inbound-agent"
            tag: "4.11.2-4"
            workingDir: "/home/jenkins/agent"
            nodeUsageMode: "NORMAL"
            customJenkinsLabels: []
            # name of the secret to be used for image pulling
            imagePullSecretName:
            componentName: "jenkins-agent"
            websocket: false
            privileged: false
            runAsUser:
            runAsGroup:
            resources:
              requests:
                cpu: "512m"
                memory: "512Mi"
              limits:
                cpu: "512m"
                memory: "512Mi"
            # You may want to change this to true while testing a new image
            alwaysPullImage: false
            # Controls how agent pods are retained after the Jenkins build completes
            # Possible values: Always, Never, OnFailure
            podRetention: "Never"
            # Disable if you do not want the Yaml the agent pod template to show up
            # in the job Console Output. This can be helpful for either security reasons
            # or simply to clean up the output to make it easier to read.
            showRawYaml: true
            # You can define the volumes that you want to mount for this container
            # Allowed types are: ConfigMap, EmptyDir, HostPath, Nfs, PVC, Secret
            # Configure the attributes as they appear in the corresponding Java class for that type
            # https://github.com/jenkinsci/kubernetes-plugin/tree/master/src/main/java/org/csanchez/jenkins/plugins/kubernetes/volumes
            volumes:
              - type: EmptyDir
                mountpath: /var/lib/docker
                memory: false
            # - type: ConfigMap
            #   configMapName: myconfigmap
            #   mountPath: /var/myapp/myconfigmap
            # - type: EmptyDir
            #   mountPath: /var/myapp/myemptydir
            #   memory: false
            # - type: HostPath
            #   hostPath: /var/lib/containers
            #   mountPath: /var/myapp/myhostpath
            # - type: Nfs
            #   mountPath: /var/myapp/mynfs
            #   readOnly: false
            #   serverAddress: "192.0.2.0"
            #   serverPath: /var/lib/containers
            # - type: PVC
            #   claimName: mypvc
            #   mountPath: /var/myapp/mypvc
            #   readOnly: false
            # - type: Secret
            #   defaultMode: "600"
            #   mountPath: /var/myapp/mysecret
            #   secretName: mysecret
            # Pod-wide environment, these vars are visible to any container in the agent pod

            # You can define the workspaceVolume that you want to mount for this container
            # Allowed types are: DynamicPVC, EmptyDir, HostPath, Nfs, PVC
            # Configure the attributes as they appear in the corresponding Java class for that type
            # https://github.com/jenkinsci/kubernetes-plugin/tree/master/src/main/java/org/csanchez/jenkins/plugins/kubernetes/volumes/workspace
            workspaceVolume: {}
            ## DynamicPVC example
            # type: DynamicPVC
            # configMapName: myconfigmap
            ## EmptyDir example
            # type: EmptyDir
            # memory: false
            ## HostPath example
            # type: HostPath
            # hostPath: /var/lib/containers
            ## NFS example
            # type: Nfs
            # readOnly: false
            # serverAddress: "192.0.2.0"
            # serverPath: /var/lib/containers
            ## PVC example
            # type: PVC
            # claimName: mypvc
            # readOnly: false
            #
            # Pod-wide environment, these vars are visible to any container in the agent pod
            envVars: []
            # - name: PATH
            #   value: /usr/local/bin
            nodeSelector: {}
            # Key Value selectors. Ex:
            # jenkins-agent: v1

            # Executed command when side container gets started
            command:
            args: "${computer.jnlpmac} ${computer.name}"
            # Side container name
            sideContainerName: "jnlp"
            # Doesn't allocate pseudo TTY by default
            TTYEnabled: false
            # Max number of spawned agent
            containerCap: 10
            # Pod name
            podName: "jenkins-agent"
            # Allows the Pod to remain active for reuse until the configured number of
            # minutes has passed since the last step was executed on it.
            idleMinutes: 5
            # Raw yaml template for the Pod. For example this allows usage of toleration for agent pods.
            # https://github.com/jenkinsci/kubernetes-plugin#using-yaml-to-define-pod-templates
            # https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
            yamlTemplate: ""
            # yamlTemplate: |-
            #   apiVersion: v1
            #   kind: Pod
            #   annotations:
            #     container.apparmor.security.beta.kubernetes.io/jenkins-agent: unconfined
            # Defines how the raw yaml field gets merged with yaml definitions from inherited pod templates: merge or override
            yamlMergeStrategy: "override"
            # Timeout in seconds for an agent to be online
            connectTimeout: 100
            # Annotations to apply to the pod.
            annotations: {
              container.apparmor.security.beta.kubernetes.io/jnlp: unconfined
            }

            # Disable the default Jenkins Agent configuration.
            # Useful when configuring agents only with the podTemplates value, since the default podTemplate populated by values mentioned above will be excluded in the rendered template.
            disableDefaultAgent: false

            # Below is the implementation of custom pod templates for the default configured kubernetes cloud.
            # Add a key under podTemplates for each pod template. Each key (prior to | character) is just a label, and can be any value.
            # Keys are only used to give the pod template a meaningful name.  The only restriction is they may only contain RFC 1123 \ DNS label
            # characters: lowercase letters, numbers, and hyphens. Each pod template can contain multiple containers.
            # For this pod templates configuration to be loaded the following values must be set:
            # controller.JCasC.defaultConfig: true
            # Best reference is https://<jenkins_url>/configuration-as-code/reference#Cloud-kubernetes. The example below creates a python pod template.
            podTemplates: {}
            #  python: |
            #    - name: python
            #      label: jenkins-python
            #      serviceAccount: jenkins
            #      containers:
            #        - name: python
            #          image: python:3
            #          command: "/bin/sh -c"
            #          args: "cat"
            #          ttyEnabled: true
            #          privileged: true
            #          resourceRequestCpu: "400m"
            #          resourceRequestMemory: "512Mi"
            #          resourceLimitCpu: "1"
            #          resourceLimitMemory: "1024Mi"

          # Here you can add additional agents
          # They inherit all values from `agent` so you only need to specify values which differ
          additionalAgents: {}
          #  maven:
          #    podName: maven
          #    customJenkinsLabels: maven
          #    # An example of overriding the jnlp container
          #    # sideContainerName: jnlp
          #    image: jenkins/jnlp-agent-maven
          #    tag: latest
          #  python:
          #    podName: python
          #    customJenkinsLabels: python
          #    sideContainerName: python
          #    image: python
          #    tag: "3"
          #    command: "/bin/sh -c"
          #    args: "cat"
          #    TTYEnabled: true

          persistence:
            enabled: true
            ## A manually managed Persistent Volume and Claim
            ## Requires persistence.enabled: true
            ## If defined, PVC must be created manually before volume will be bound
            existingClaim:
            ## jenkins data Persistent Volume Storage Class
            ## If defined, storageClassName: <storageClass>
            ## If set to "-", storageClassName: "", which disables dynamic provisioning
            ## If undefined (the default) or set to null, no storageClassName spec is
            ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
            ##   GKE, AWS & OpenStack)
            ##
            storageClass:
            annotations: {}
            labels: {}
            accessMode: "ReadWriteOnce"
            size: "10Gi"
            volumes:
            #  - name: nothing
            #    emptyDir: {}
            mounts:
            #  - mountPath: /var/nothing
            #    name: nothing
            #    readOnly: true

          serviceAccount:
            create: false
            # The name of the service account is autogenerated by default
            name: jenkins
            annotations: {}
            imagePullSecretName:
      repoURL: https://charts.jenkins.io
      targetRevision: 4.1.12
  - deployStartedAt: "2022-07-18T00:37:42Z"
    deployedAt: "2022-07-18T00:37:43Z"
    id: 26
    revision: 4.1.12
    source:
      chart: jenkins
      helm:
        parameters:
        - name: serviceAccount.create
          value: "false"
        - name: serviceAccount.name
          value: jenkins
        - name: persistence.size
          value: 10Gi
        - name: agent.privileged
          value: "true"
        - name: agent.alwaysPullImage
          value: "true"
        valueFiles:
        - values.yaml
        values: |
          agent:
            enabled: true
            defaultsProviderTemplate: ""
            # URL for connecting to the Jenkins contoller
            jenkinsUrl:
            # connect to the specified host and port, instead of connecting directly to the Jenkins controller
            jenkinsTunnel:
            kubernetesConnectTimeout: 5
            kubernetesReadTimeout: 15
            maxRequestsPerHostStr: "32"
            namespace:
            image: "jenkins/inbound-agent"
            tag: "4.11.2-4"
            workingDir: "/home/jenkins/agent"
            nodeUsageMode: "NORMAL"
            customJenkinsLabels: []
            # name of the secret to be used for image pulling
            imagePullSecretName:
            componentName: "jenkins-agent"
            websocket: false
            privileged: false
            runAsUser:
            runAsGroup:
            resources:
              requests:
                cpu: "512m"
                memory: "512Mi"
              limits:
                cpu: "512m"
                memory: "512Mi"
            # You may want to change this to true while testing a new image
            alwaysPullImage: false
            # Controls how agent pods are retained after the Jenkins build completes
            # Possible values: Always, Never, OnFailure
            podRetention: "Never"
            # Disable if you do not want the Yaml the agent pod template to show up
            # in the job Console Output. This can be helpful for either security reasons
            # or simply to clean up the output to make it easier to read.
            showRawYaml: true
            # You can define the volumes that you want to mount for this container
            # Allowed types are: ConfigMap, EmptyDir, HostPath, Nfs, PVC, Secret
            # Configure the attributes as they appear in the corresponding Java class for that type
            # https://github.com/jenkinsci/kubernetes-plugin/tree/master/src/main/java/org/csanchez/jenkins/plugins/kubernetes/volumes
            volumes:
              - type: EmptyDir
                mountpath: /var/lib/docker
                memory: false
            # - type: ConfigMap
            #   configMapName: myconfigmap
            #   mountPath: /var/myapp/myconfigmap
            # - type: EmptyDir
            #   mountPath: /var/myapp/myemptydir
            #   memory: false
            # - type: HostPath
            #   hostPath: /var/lib/containers
            #   mountPath: /var/myapp/myhostpath
            # - type: Nfs
            #   mountPath: /var/myapp/mynfs
            #   readOnly: false
            #   serverAddress: "192.0.2.0"
            #   serverPath: /var/lib/containers
            # - type: PVC
            #   claimName: mypvc
            #   mountPath: /var/myapp/mypvc
            #   readOnly: false
            # - type: Secret
            #   defaultMode: "600"
            #   mountPath: /var/myapp/mysecret
            #   secretName: mysecret
            # Pod-wide environment, these vars are visible to any container in the agent pod

            # You can define the workspaceVolume that you want to mount for this container
            # Allowed types are: DynamicPVC, EmptyDir, HostPath, Nfs, PVC
            # Configure the attributes as they appear in the corresponding Java class for that type
            # https://github.com/jenkinsci/kubernetes-plugin/tree/master/src/main/java/org/csanchez/jenkins/plugins/kubernetes/volumes/workspace
            workspaceVolume: {}
            ## DynamicPVC example
            # type: DynamicPVC
            # configMapName: myconfigmap
            ## EmptyDir example
            # type: EmptyDir
            # memory: false
            ## HostPath example
            # type: HostPath
            # hostPath: /var/lib/containers
            ## NFS example
            # type: Nfs
            # readOnly: false
            # serverAddress: "192.0.2.0"
            # serverPath: /var/lib/containers
            ## PVC example
            # type: PVC
            # claimName: mypvc
            # readOnly: false
            #
            # Pod-wide environment, these vars are visible to any container in the agent pod
            envVars: []
            # - name: PATH
            #   value: /usr/local/bin
            nodeSelector: {}
            # Key Value selectors. Ex:
            # jenkins-agent: v1

            # Executed command when side container gets started
            command:
            args: "${computer.jnlpmac} ${computer.name}"
            # Side container name
            sideContainerName: "jnlp"
            # Doesn't allocate pseudo TTY by default
            TTYEnabled: false
            # Max number of spawned agent
            containerCap: 10
            # Pod name
            podName: "jenkins-agent"
            # Allows the Pod to remain active for reuse until the configured number of
            # minutes has passed since the last step was executed on it.
            idleMinutes: 5
            # Raw yaml template for the Pod. For example this allows usage of toleration for agent pods.
            # https://github.com/jenkinsci/kubernetes-plugin#using-yaml-to-define-pod-templates
            # https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
            yamlTemplate: ""
            # yamlTemplate: |-
            #   apiVersion: v1
            #   kind: Pod
            #   annotations:
            #     container.apparmor.security.beta.kubernetes.io/jenkins-agent: unconfined
            # Defines how the raw yaml field gets merged with yaml definitions from inherited pod templates: merge or override
            yamlMergeStrategy: "override"
            # Timeout in seconds for an agent to be online
            connectTimeout: 100
            # Annotations to apply to the pod.
            annotations: {
              container.apparmor.security.beta.kubernetes.io/jnlp: unconfined
            }

            # Disable the default Jenkins Agent configuration.
            # Useful when configuring agents only with the podTemplates value, since the default podTemplate populated by values mentioned above will be excluded in the rendered template.
            disableDefaultAgent: false

            # Below is the implementation of custom pod templates for the default configured kubernetes cloud.
            # Add a key under podTemplates for each pod template. Each key (prior to | character) is just a label, and can be any value.
            # Keys are only used to give the pod template a meaningful name.  The only restriction is they may only contain RFC 1123 \ DNS label
            # characters: lowercase letters, numbers, and hyphens. Each pod template can contain multiple containers.
            # For this pod templates configuration to be loaded the following values must be set:
            # controller.JCasC.defaultConfig: true
            # Best reference is https://<jenkins_url>/configuration-as-code/reference#Cloud-kubernetes. The example below creates a python pod template.
            podTemplates: {}
            #  python: |
            #    - name: python
            #      label: jenkins-python
            #      serviceAccount: jenkins
            #      containers:
            #        - name: python
            #          image: python:3
            #          command: "/bin/sh -c"
            #          args: "cat"
            #          ttyEnabled: true
            #          privileged: true
            #          resourceRequestCpu: "400m"
            #          resourceRequestMemory: "512Mi"
            #          resourceLimitCpu: "1"
            #          resourceLimitMemory: "1024Mi"

          # Here you can add additional agents
          # They inherit all values from `agent` so you only need to specify values which differ
          additionalAgents: {}
          #  maven:
          #    podName: maven
          #    customJenkinsLabels: maven
          #    # An example of overriding the jnlp container
          #    # sideContainerName: jnlp
          #    image: jenkins/jnlp-agent-maven
          #    tag: latest
          #  python:
          #    podName: python
          #    customJenkinsLabels: python
          #    sideContainerName: python
          #    image: python
          #    tag: "3"
          #    command: "/bin/sh -c"
          #    args: "cat"
          #    TTYEnabled: true

          persistence:
            enabled: true
            ## A manually managed Persistent Volume and Claim
            ## Requires persistence.enabled: true
            ## If defined, PVC must be created manually before volume will be bound
            existingClaim:
            ## jenkins data Persistent Volume Storage Class
            ## If defined, storageClassName: <storageClass>
            ## If set to "-", storageClassName: "", which disables dynamic provisioning
            ## If undefined (the default) or set to null, no storageClassName spec is
            ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
            ##   GKE, AWS & OpenStack)
            ##
            storageClass:
            annotations: {}
            labels: {}
            accessMode: "ReadWriteOnce"
            size: "10Gi"
            volumes:
            #  - name: nothing
            #    emptyDir: {}
            mounts:
            #  - mountPath: /var/nothing
            #    name: nothing
            #    readOnly: true

          serviceAccount:
            create: false
            # The name of the service account is autogenerated by default
            name: jenkins
            annotations: {}
            imagePullSecretName:
      repoURL: https://charts.jenkins.io
      targetRevision: 4.1.12
  - deployStartedAt: "2022-07-18T02:30:50Z"
    deployedAt: "2022-07-18T02:30:51Z"
    id: 27
    revision: 4.1.12
    source:
      chart: jenkins
      helm:
        parameters:
        - name: serviceAccount.create
          value: "false"
        - name: serviceAccount.name
          value: jenkins
        - name: persistence.size
          value: 10Gi
        - name: agent.privileged
          value: "true"
        - name: agent.alwaysPullImage
          value: "true"
        valueFiles:
        - values.yaml
        values: |
          agent:
            enabled: true
            defaultsProviderTemplate: ""
            # URL for connecting to the Jenkins contoller
            jenkinsUrl:
            # connect to the specified host and port, instead of connecting directly to the Jenkins controller
            jenkinsTunnel:
            kubernetesConnectTimeout: 5
            kubernetesReadTimeout: 15
            maxRequestsPerHostStr: "32"
            namespace:
            image: "jenkins/inbound-agent"
            tag: "4.11.2-4"
            workingDir: "/home/jenkins/agent"
            nodeUsageMode: "NORMAL"
            customJenkinsLabels: []
            # name of the secret to be used for image pulling
            imagePullSecretName:
            componentName: "jenkins-agent"
            websocket: false
            privileged: false
            runAsUser:
            runAsGroup:
            resources:
              requests:
                cpu: "512m"
                memory: "512Mi"
              limits:
                cpu: "512m"
                memory: "512Mi"
            # You may want to change this to true while testing a new image
            alwaysPullImage: false
            # Controls how agent pods are retained after the Jenkins build completes
            # Possible values: Always, Never, OnFailure
            podRetention: "Never"
            # Disable if you do not want the Yaml the agent pod template to show up
            # in the job Console Output. This can be helpful for either security reasons
            # or simply to clean up the output to make it easier to read.
            showRawYaml: true
            # You can define the volumes that you want to mount for this container
            # Allowed types are: ConfigMap, EmptyDir, HostPath, Nfs, PVC, Secret
            # Configure the attributes as they appear in the corresponding Java class for that type
            # https://github.com/jenkinsci/kubernetes-plugin/tree/master/src/main/java/org/csanchez/jenkins/plugins/kubernetes/volumes
            volumes: []
            # - type: ConfigMap
            #   configMapName: myconfigmap
            #   mountPath: /var/myapp/myconfigmap
            # - type: EmptyDir
            #   mountPath: /var/myapp/myemptydir
            #   memory: false
            # - type: HostPath
            #   hostPath: /var/lib/containers
            #   mountPath: /var/myapp/myhostpath
            # - type: Nfs
            #   mountPath: /var/myapp/mynfs
            #   readOnly: false
            #   serverAddress: "192.0.2.0"
            #   serverPath: /var/lib/containers
            # - type: PVC
            #   claimName: mypvc
            #   mountPath: /var/myapp/mypvc
            #   readOnly: false
            # - type: Secret
            #   defaultMode: "600"
            #   mountPath: /var/myapp/mysecret
            #   secretName: mysecret
            # Pod-wide environment, these vars are visible to any container in the agent pod

            # You can define the workspaceVolume that you want to mount for this container
            # Allowed types are: DynamicPVC, EmptyDir, HostPath, Nfs, PVC
            # Configure the attributes as they appear in the corresponding Java class for that type
            # https://github.com/jenkinsci/kubernetes-plugin/tree/master/src/main/java/org/csanchez/jenkins/plugins/kubernetes/volumes/workspace
            workspaceVolume: {}
            ## DynamicPVC example
            # type: DynamicPVC
            # configMapName: myconfigmap
            ## EmptyDir example
            # type: EmptyDir
            # memory: false
            ## HostPath example
            # type: HostPath
            # hostPath: /var/lib/containers
            ## NFS example
            # type: Nfs
            # readOnly: false
            # serverAddress: "192.0.2.0"
            # serverPath: /var/lib/containers
            ## PVC example
            # type: PVC
            # claimName: mypvc
            # readOnly: false
            #
            # Pod-wide environment, these vars are visible to any container in the agent pod
            envVars: []
            # - name: PATH
            #   value: /usr/local/bin
            nodeSelector: {}
            # Key Value selectors. Ex:
            # jenkins-agent: v1

            # Executed command when side container gets started
            command:
            args: "${computer.jnlpmac} ${computer.name}"
            # Side container name
            sideContainerName: "jnlp"
            # Doesn't allocate pseudo TTY by default
            TTYEnabled: false
            # Max number of spawned agent
            containerCap: 10
            # Pod name
            podName: "jenkins-agent"
            # Allows the Pod to remain active for reuse until the configured number of
            # minutes has passed since the last step was executed on it.
            idleMinutes: 5
            # Raw yaml template for the Pod. For example this allows usage of toleration for agent pods.
            # https://github.com/jenkinsci/kubernetes-plugin#using-yaml-to-define-pod-templates
            # https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
            yamlTemplate: ""
            # yamlTemplate: |-
            #   apiVersion: v1
            #   kind: Pod
            #   annotations:
            #     container.apparmor.security.beta.kubernetes.io/jenkins-agent: unconfined
            # Defines how the raw yaml field gets merged with yaml definitions from inherited pod templates: merge or override
            yamlMergeStrategy: "override"
            # Timeout in seconds for an agent to be online
            connectTimeout: 100
            # Annotations to apply to the pod.
            annotations: {
              container.apparmor.security.beta.kubernetes.io/jnlp: unconfined
            }

            # Disable the default Jenkins Agent configuration.
            # Useful when configuring agents only with the podTemplates value, since the default podTemplate populated by values mentioned above will be excluded in the rendered template.
            disableDefaultAgent: false

            # Below is the implementation of custom pod templates for the default configured kubernetes cloud.
            # Add a key under podTemplates for each pod template. Each key (prior to | character) is just a label, and can be any value.
            # Keys are only used to give the pod template a meaningful name.  The only restriction is they may only contain RFC 1123 \ DNS label
            # characters: lowercase letters, numbers, and hyphens. Each pod template can contain multiple containers.
            # For this pod templates configuration to be loaded the following values must be set:
            # controller.JCasC.defaultConfig: true
            # Best reference is https://<jenkins_url>/configuration-as-code/reference#Cloud-kubernetes. The example below creates a python pod template.
            podTemplates: {}
            #  python: |
            #    - name: python
            #      label: jenkins-python
            #      serviceAccount: jenkins
            #      containers:
            #        - name: python
            #          image: python:3
            #          command: "/bin/sh -c"
            #          args: "cat"
            #          ttyEnabled: true
            #          privileged: true
            #          resourceRequestCpu: "400m"
            #          resourceRequestMemory: "512Mi"
            #          resourceLimitCpu: "1"
            #          resourceLimitMemory: "1024Mi"

          # Here you can add additional agents
          # They inherit all values from `agent` so you only need to specify values which differ
          additionalAgents: {}
          #  maven:
          #    podName: maven
          #    customJenkinsLabels: maven
          #    # An example of overriding the jnlp container
          #    # sideContainerName: jnlp
          #    image: jenkins/jnlp-agent-maven
          #    tag: latest
          #  python:
          #    podName: python
          #    customJenkinsLabels: python
          #    sideContainerName: python
          #    image: python
          #    tag: "3"
          #    command: "/bin/sh -c"
          #    args: "cat"
          #    TTYEnabled: true

          persistence:
            enabled: true
            ## A manually managed Persistent Volume and Claim
            ## Requires persistence.enabled: true
            ## If defined, PVC must be created manually before volume will be bound
            existingClaim:
            ## jenkins data Persistent Volume Storage Class
            ## If defined, storageClassName: <storageClass>
            ## If set to "-", storageClassName: "", which disables dynamic provisioning
            ## If undefined (the default) or set to null, no storageClassName spec is
            ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
            ##   GKE, AWS & OpenStack)
            ##
            storageClass:
            annotations: {}
            labels: {}
            accessMode: "ReadWriteOnce"
            size: "10Gi"
            volumes:
            #  - name: nothing
            #    emptyDir: {}
            mounts:
            #  - mountPath: /var/nothing
            #    name: nothing
            #    readOnly: true

          serviceAccount:
            create: false
            # The name of the service account is autogenerated by default
            name: jenkins
            annotations: {}
            imagePullSecretName:
      repoURL: https://charts.jenkins.io
      targetRevision: 4.1.12
  - deployStartedAt: "2022-07-18T04:16:10Z"
    deployedAt: "2022-07-18T04:16:12Z"
    id: 28
    revision: 4.1.12
    source:
      chart: jenkins
      helm:
        parameters:
        - name: serviceAccount.create
          value: "false"
        - name: serviceAccount.name
          value: jenkins
        - name: persistence.size
          value: 10Gi
        - name: agent.alwaysPullImage
          value: "true"
        - name: agent.tag
          value: latest
        - name: agent.image
          value: bensonyanger/jenkins-agent
        valueFiles:
        - values.yaml
        values: |
          agent:
            enabled: true
            defaultsProviderTemplate: ""
            # URL for connecting to the Jenkins contoller
            jenkinsUrl:
            # connect to the specified host and port, instead of connecting directly to the Jenkins controller
            jenkinsTunnel:
            kubernetesConnectTimeout: 5
            kubernetesReadTimeout: 15
            maxRequestsPerHostStr: "32"
            namespace:
            image: "jenkins/inbound-agent"
            tag: "4.11.2-4"
            workingDir: "/home/jenkins/agent"
            nodeUsageMode: "NORMAL"
            customJenkinsLabels: []
            # name of the secret to be used for image pulling
            imagePullSecretName:
            componentName: "jenkins-agent"
            websocket: false
            privileged: false
            runAsUser:
            runAsGroup:
            resources:
              requests:
                cpu: "512m"
                memory: "512Mi"
              limits:
                cpu: "512m"
                memory: "512Mi"
            # You may want to change this to true while testing a new image
            alwaysPullImage: false
            # Controls how agent pods are retained after the Jenkins build completes
            # Possible values: Always, Never, OnFailure
            podRetention: "Never"
            # Disable if you do not want the Yaml the agent pod template to show up
            # in the job Console Output. This can be helpful for either security reasons
            # or simply to clean up the output to make it easier to read.
            showRawYaml: true
            # You can define the volumes that you want to mount for this container
            # Allowed types are: ConfigMap, EmptyDir, HostPath, Nfs, PVC, Secret
            # Configure the attributes as they appear in the corresponding Java class for that type
            # https://github.com/jenkinsci/kubernetes-plugin/tree/master/src/main/java/org/csanchez/jenkins/plugins/kubernetes/volumes
            volumes: []
            # - type: ConfigMap
            #   configMapName: myconfigmap
            #   mountPath: /var/myapp/myconfigmap
            # - type: EmptyDir
            #   mountPath: /var/myapp/myemptydir
            #   memory: false
            # - type: HostPath
            #   hostPath: /var/lib/containers
            #   mountPath: /var/myapp/myhostpath
            # - type: Nfs
            #   mountPath: /var/myapp/mynfs
            #   readOnly: false
            #   serverAddress: "192.0.2.0"
            #   serverPath: /var/lib/containers
            # - type: PVC
            #   claimName: mypvc
            #   mountPath: /var/myapp/mypvc
            #   readOnly: false
            # - type: Secret
            #   defaultMode: "600"
            #   mountPath: /var/myapp/mysecret
            #   secretName: mysecret
            # Pod-wide environment, these vars are visible to any container in the agent pod

            # You can define the workspaceVolume that you want to mount for this container
            # Allowed types are: DynamicPVC, EmptyDir, HostPath, Nfs, PVC
            # Configure the attributes as they appear in the corresponding Java class for that type
            # https://github.com/jenkinsci/kubernetes-plugin/tree/master/src/main/java/org/csanchez/jenkins/plugins/kubernetes/volumes/workspace
            workspaceVolume: {}
            ## DynamicPVC example
            # type: DynamicPVC
            # configMapName: myconfigmap
            ## EmptyDir example
            # type: EmptyDir
            # memory: false
            ## HostPath example
            # type: HostPath
            # hostPath: /var/lib/containers
            ## NFS example
            # type: Nfs
            # readOnly: false
            # serverAddress: "192.0.2.0"
            # serverPath: /var/lib/containers
            ## PVC example
            # type: PVC
            # claimName: mypvc
            # readOnly: false
            #
            # Pod-wide environment, these vars are visible to any container in the agent pod
            envVars: []
            # - name: PATH
            #   value: /usr/local/bin
            nodeSelector: {}
            # Key Value selectors. Ex:
            # jenkins-agent: v1

            # Executed command when side container gets started
            command:
            args: "${computer.jnlpmac} ${computer.name}"
            # Side container name
            sideContainerName: "jnlp"
            # Doesn't allocate pseudo TTY by default
            TTYEnabled: false
            # Max number of spawned agent
            containerCap: 10
            # Pod name
            podName: "jenkins-agent"
            # Allows the Pod to remain active for reuse until the configured number of
            # minutes has passed since the last step was executed on it.
            idleMinutes: 5
            # Raw yaml template for the Pod. For example this allows usage of toleration for agent pods.
            # https://github.com/jenkinsci/kubernetes-plugin#using-yaml-to-define-pod-templates
            # https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
            yamlTemplate: ""
            # yamlTemplate: |-
            #   apiVersion: v1
            #   kind: Pod
            #   annotations:
            #     container.apparmor.security.beta.kubernetes.io/jenkins-agent: unconfined
            # Defines how the raw yaml field gets merged with yaml definitions from inherited pod templates: merge or override
            yamlMergeStrategy: "override"
            # Timeout in seconds for an agent to be online
            connectTimeout: 100
            # Annotations to apply to the pod.
            annotations: {
              container.apparmor.security.beta.kubernetes.io/jnlp: unconfined
            }

            # Disable the default Jenkins Agent configuration.
            # Useful when configuring agents only with the podTemplates value, since the default podTemplate populated by values mentioned above will be excluded in the rendered template.
            disableDefaultAgent: false

            # Below is the implementation of custom pod templates for the default configured kubernetes cloud.
            # Add a key under podTemplates for each pod template. Each key (prior to | character) is just a label, and can be any value.
            # Keys are only used to give the pod template a meaningful name.  The only restriction is they may only contain RFC 1123 \ DNS label
            # characters: lowercase letters, numbers, and hyphens. Each pod template can contain multiple containers.
            # For this pod templates configuration to be loaded the following values must be set:
            # controller.JCasC.defaultConfig: true
            # Best reference is https://<jenkins_url>/configuration-as-code/reference#Cloud-kubernetes. The example below creates a python pod template.
            podTemplates: {}
            #  python: |
            #    - name: python
            #      label: jenkins-python
            #      serviceAccount: jenkins
            #      containers:
            #        - name: python
            #          image: python:3
            #          command: "/bin/sh -c"
            #          args: "cat"
            #          ttyEnabled: true
            #          privileged: true
            #          resourceRequestCpu: "400m"
            #          resourceRequestMemory: "512Mi"
            #          resourceLimitCpu: "1"
            #          resourceLimitMemory: "1024Mi"

          # Here you can add additional agents
          # They inherit all values from `agent` so you only need to specify values which differ
          additionalAgents: {}
          #  maven:
          #    podName: maven
          #    customJenkinsLabels: maven
          #    # An example of overriding the jnlp container
          #    # sideContainerName: jnlp
          #    image: jenkins/jnlp-agent-maven
          #    tag: latest
          #  python:
          #    podName: python
          #    customJenkinsLabels: python
          #    sideContainerName: python
          #    image: python
          #    tag: "3"
          #    command: "/bin/sh -c"
          #    args: "cat"
          #    TTYEnabled: true

          persistence:
            enabled: true
            ## A manually managed Persistent Volume and Claim
            ## Requires persistence.enabled: true
            ## If defined, PVC must be created manually before volume will be bound
            existingClaim:
            ## jenkins data Persistent Volume Storage Class
            ## If defined, storageClassName: <storageClass>
            ## If set to "-", storageClassName: "", which disables dynamic provisioning
            ## If undefined (the default) or set to null, no storageClassName spec is
            ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
            ##   GKE, AWS & OpenStack)
            ##
            storageClass:
            annotations: {}
            labels: {}
            accessMode: "ReadWriteOnce"
            size: "10Gi"
            volumes:
            #  - name: nothing
            #    emptyDir: {}
            mounts:
            #  - mountPath: /var/nothing
            #    name: nothing
            #    readOnly: true

          serviceAccount:
            create: false
            # The name of the service account is autogenerated by default
            name: jenkins
            annotations: {}
            imagePullSecretName:
      repoURL: https://charts.jenkins.io
      targetRevision: 4.1.12
  - deployStartedAt: "2022-08-13T08:52:40Z"
    deployedAt: "2022-08-13T08:52:41Z"
    id: 29
    revision: 4.1.12
    source:
      chart: jenkins
      helm:
        parameters:
        - name: serviceAccount.create
          value: "false"
        - name: serviceAccount.name
          value: jenkins
        - name: persistence.size
          value: 10Gi
        - name: agent.alwaysPullImage
          value: "true"
        - name: agent.tag
          value: latest
        - name: agent.image
          value: bensonyanger/jenkins-agent
        valueFiles:
        - values.yaml
        values: |
          agent:
            enabled: true
            defaultsProviderTemplate: ""
            # URL for connecting to the Jenkins contoller
            jenkinsUrl:
            # connect to the specified host and port, instead of connecting directly to the Jenkins controller
            jenkinsTunnel:
            kubernetesConnectTimeout: 5
            kubernetesReadTimeout: 15
            maxRequestsPerHostStr: "32"
            namespace:
            image: "jenkins/inbound-agent"
            tag: "4.11.2-4"
            workingDir: "/home/jenkins/agent"
            nodeUsageMode: "NORMAL"
            customJenkinsLabels: []
            # name of the secret to be used for image pulling
            imagePullSecretName:
            componentName: "jenkins-agent"
            websocket: false
            privileged: false
            runAsUser:
            runAsGroup:
            resources:
              requests:
                cpu: "512m"
                memory: "512Mi"
              limits:
                cpu: "512m"
                memory: "512Mi"
            # You may want to change this to true while testing a new image
            alwaysPullImage: false
            # Controls how agent pods are retained after the Jenkins build completes
            # Possible values: Always, Never, OnFailure
            podRetention: "Never"
            # Disable if you do not want the Yaml the agent pod template to show up
            # in the job Console Output. This can be helpful for either security reasons
            # or simply to clean up the output to make it easier to read.
            showRawYaml: true
            # You can define the volumes that you want to mount for this container
            # Allowed types are: ConfigMap, EmptyDir, HostPath, Nfs, PVC, Secret
            # Configure the attributes as they appear in the corresponding Java class for that type
            # https://github.com/jenkinsci/kubernetes-plugin/tree/master/src/main/java/org/csanchez/jenkins/plugins/kubernetes/volumes
            volumes: []
            # - type: ConfigMap
            #   configMapName: myconfigmap
            #   mountPath: /var/myapp/myconfigmap
            # - type: EmptyDir
            #   mountPath: /var/myapp/myemptydir
            #   memory: false
            # - type: HostPath
            #   hostPath: /var/lib/containers
            #   mountPath: /var/myapp/myhostpath
            # - type: Nfs
            #   mountPath: /var/myapp/mynfs
            #   readOnly: false
            #   serverAddress: "192.0.2.0"
            #   serverPath: /var/lib/containers
            # - type: PVC
            #   claimName: mypvc
            #   mountPath: /var/myapp/mypvc
            #   readOnly: false
            # - type: Secret
            #   defaultMode: "600"
            #   mountPath: /var/myapp/mysecret
            #   secretName: mysecret
            # Pod-wide environment, these vars are visible to any container in the agent pod

            # You can define the workspaceVolume that you want to mount for this container
            # Allowed types are: DynamicPVC, EmptyDir, HostPath, Nfs, PVC
            # Configure the attributes as they appear in the corresponding Java class for that type
            # https://github.com/jenkinsci/kubernetes-plugin/tree/master/src/main/java/org/csanchez/jenkins/plugins/kubernetes/volumes/workspace
            workspaceVolume: {}
            ## DynamicPVC example
            # type: DynamicPVC
            # configMapName: myconfigmap
            ## EmptyDir example
            # type: EmptyDir
            # memory: false
            ## HostPath example
            # type: HostPath
            # hostPath: /var/lib/containers
            ## NFS example
            # type: Nfs
            # readOnly: false
            # serverAddress: "192.0.2.0"
            # serverPath: /var/lib/containers
            ## PVC example
            # type: PVC
            # claimName: mypvc
            # readOnly: false
            #
            # Pod-wide environment, these vars are visible to any container in the agent pod
            envVars: []
            # - name: PATH
            #   value: /usr/local/bin
            nodeSelector: {}
            # Key Value selectors. Ex:
            # jenkins-agent: v1

            # Executed command when side container gets started
            command:
            args: "${computer.jnlpmac} ${computer.name}"
            # Side container name
            sideContainerName: "jnlp"
            # Doesn't allocate pseudo TTY by default
            TTYEnabled: false
            # Max number of spawned agent
            containerCap: 10
            # Pod name
            podName: "jenkins-agent"
            # Allows the Pod to remain active for reuse until the configured number of
            # minutes has passed since the last step was executed on it.
            idleMinutes: 5
            # Raw yaml template for the Pod. For example this allows usage of toleration for agent pods.
            # https://github.com/jenkinsci/kubernetes-plugin#using-yaml-to-define-pod-templates
            # https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
            yamlTemplate: ""
            # yamlTemplate: |-
            #   apiVersion: v1
            #   kind: Pod
            #   annotations:
            #     container.apparmor.security.beta.kubernetes.io/jenkins-agent: unconfined
            # Defines how the raw yaml field gets merged with yaml definitions from inherited pod templates: merge or override
            yamlMergeStrategy: "override"
            # Timeout in seconds for an agent to be online
            connectTimeout: 100
            # Annotations to apply to the pod.
            annotations: {
              container.apparmor.security.beta.kubernetes.io/jnlp: unconfined
            }

            # Disable the default Jenkins Agent configuration.
            # Useful when configuring agents only with the podTemplates value, since the default podTemplate populated by values mentioned above will be excluded in the rendered template.
            disableDefaultAgent: false

            # Below is the implementation of custom pod templates for the default configured kubernetes cloud.
            # Add a key under podTemplates for each pod template. Each key (prior to | character) is just a label, and can be any value.
            # Keys are only used to give the pod template a meaningful name.  The only restriction is they may only contain RFC 1123 \ DNS label
            # characters: lowercase letters, numbers, and hyphens. Each pod template can contain multiple containers.
            # For this pod templates configuration to be loaded the following values must be set:
            # controller.JCasC.defaultConfig: true
            # Best reference is https://<jenkins_url>/configuration-as-code/reference#Cloud-kubernetes. The example below creates a python pod template.
            podTemplates: {}
            #  python: |
            #    - name: python
            #      label: jenkins-python
            #      serviceAccount: jenkins
            #      containers:
            #        - name: python
            #          image: python:3
            #          command: "/bin/sh -c"
            #          args: "cat"
            #          ttyEnabled: true
            #          privileged: true
            #          resourceRequestCpu: "400m"
            #          resourceRequestMemory: "512Mi"
            #          resourceLimitCpu: "1"
            #          resourceLimitMemory: "1024Mi"

          # Here you can add additional agents
          # They inherit all values from `agent` so you only need to specify values which differ
          additionalAgents: {}
          #  maven:
          #    podName: maven
          #    customJenkinsLabels: maven
          #    # An example of overriding the jnlp container
          #    # sideContainerName: jnlp
          #    image: jenkins/jnlp-agent-maven
          #    tag: latest
          #  python:
          #    podName: python
          #    customJenkinsLabels: python
          #    sideContainerName: python
          #    image: python
          #    tag: "3"
          #    command: "/bin/sh -c"
          #    args: "cat"
          #    TTYEnabled: true

          persistence:
            enabled: true
            ## A manually managed Persistent Volume and Claim
            ## Requires persistence.enabled: true
            ## If defined, PVC must be created manually before volume will be bound
            existingClaim:
            ## jenkins data Persistent Volume Storage Class
            ## If defined, storageClassName: <storageClass>
            ## If set to "-", storageClassName: "", which disables dynamic provisioning
            ## If undefined (the default) or set to null, no storageClassName spec is
            ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
            ##   GKE, AWS & OpenStack)
            ##
            storageClass:
            annotations: {}
            labels: {}
            accessMode: "ReadWriteOnce"
            size: "10Gi"
            volumes:
            #  - name: nothing
            #    emptyDir: {}
            mounts:
            #  - mountPath: /var/nothing
            #    name: nothing
            #    readOnly: true

          serviceAccount:
            create: false
            # The name of the service account is autogenerated by default
            name: jenkins
            annotations: {}
            imagePullSecretName:
      repoURL: https://charts.jenkins.io
      targetRevision: 4.1.12
  operationState:
    finishedAt: "2022-08-13T08:52:41Z"
    message: successfully synced (all tasks run)
    operation:
      initiatedBy:
        username: admin
      retry: {}
      sync:
        revision: 4.1.12
        syncStrategy:
          hook: {}
    phase: Succeeded
    startedAt: "2022-08-13T08:52:40Z"
    syncResult:
      resources:
      - group: cilium.io
        hookPhase: Succeeded
        kind: CiliumIdentity
        message: ignored (requires pruning)
        name: "55999"
        namespace: ""
        status: PruneSkipped
        syncPhase: Sync
        version: v2
      - group: ""
        hookPhase: Running
        kind: Secret
        message: secret/jenkins configured
        name: jenkins
        namespace: jenkins
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: ConfigMap
        message: configmap/jenkins unchanged
        name: jenkins
        namespace: jenkins
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: ConfigMap
        message: configmap/jenkins-jenkins-jcasc-config unchanged
        name: jenkins-jenkins-jcasc-config
        namespace: jenkins
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: PersistentVolumeClaim
        message: persistentvolumeclaim/jenkins unchanged
        name: jenkins
        namespace: jenkins
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: Role
        message: role.rbac.authorization.k8s.io/jenkins-schedule-agents reconciled.
          role.rbac.authorization.k8s.io/jenkins-schedule-agents unchanged
        name: jenkins-schedule-agents
        namespace: jenkins
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: Role
        message: role.rbac.authorization.k8s.io/jenkins-casc-reload reconciled. role.rbac.authorization.k8s.io/jenkins-casc-reload
          unchanged
        name: jenkins-casc-reload
        namespace: jenkins
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: RoleBinding
        message: rolebinding.rbac.authorization.k8s.io/jenkins-watch-configmaps reconciled.
          rolebinding.rbac.authorization.k8s.io/jenkins-watch-configmaps unchanged
        name: jenkins-watch-configmaps
        namespace: jenkins
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: RoleBinding
        message: rolebinding.rbac.authorization.k8s.io/jenkins-schedule-agents reconciled.
          rolebinding.rbac.authorization.k8s.io/jenkins-schedule-agents unchanged
        name: jenkins-schedule-agents
        namespace: jenkins
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/jenkins unchanged
        name: jenkins
        namespace: jenkins
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/jenkins-agent unchanged
        name: jenkins-agent
        namespace: jenkins
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Running
        kind: StatefulSet
        message: statefulset.apps/jenkins configured
        name: jenkins
        namespace: jenkins
        status: Synced
        syncPhase: Sync
        version: v1
      revision: 4.1.12
      source:
        chart: jenkins
        helm:
          parameters:
          - name: serviceAccount.create
            value: "false"
          - name: serviceAccount.name
            value: jenkins
          - name: persistence.size
            value: 10Gi
          - name: agent.alwaysPullImage
            value: "true"
          - name: agent.tag
            value: latest
          - name: agent.image
            value: bensonyanger/jenkins-agent
          valueFiles:
          - values.yaml
          values: |
            agent:
              enabled: true
              defaultsProviderTemplate: ""
              # URL for connecting to the Jenkins contoller
              jenkinsUrl:
              # connect to the specified host and port, instead of connecting directly to the Jenkins controller
              jenkinsTunnel:
              kubernetesConnectTimeout: 5
              kubernetesReadTimeout: 15
              maxRequestsPerHostStr: "32"
              namespace:
              image: "jenkins/inbound-agent"
              tag: "4.11.2-4"
              workingDir: "/home/jenkins/agent"
              nodeUsageMode: "NORMAL"
              customJenkinsLabels: []
              # name of the secret to be used for image pulling
              imagePullSecretName:
              componentName: "jenkins-agent"
              websocket: false
              privileged: false
              runAsUser:
              runAsGroup:
              resources:
                requests:
                  cpu: "512m"
                  memory: "512Mi"
                limits:
                  cpu: "512m"
                  memory: "512Mi"
              # You may want to change this to true while testing a new image
              alwaysPullImage: false
              # Controls how agent pods are retained after the Jenkins build completes
              # Possible values: Always, Never, OnFailure
              podRetention: "Never"
              # Disable if you do not want the Yaml the agent pod template to show up
              # in the job Console Output. This can be helpful for either security reasons
              # or simply to clean up the output to make it easier to read.
              showRawYaml: true
              # You can define the volumes that you want to mount for this container
              # Allowed types are: ConfigMap, EmptyDir, HostPath, Nfs, PVC, Secret
              # Configure the attributes as they appear in the corresponding Java class for that type
              # https://github.com/jenkinsci/kubernetes-plugin/tree/master/src/main/java/org/csanchez/jenkins/plugins/kubernetes/volumes
              volumes: []
              # - type: ConfigMap
              #   configMapName: myconfigmap
              #   mountPath: /var/myapp/myconfigmap
              # - type: EmptyDir
              #   mountPath: /var/myapp/myemptydir
              #   memory: false
              # - type: HostPath
              #   hostPath: /var/lib/containers
              #   mountPath: /var/myapp/myhostpath
              # - type: Nfs
              #   mountPath: /var/myapp/mynfs
              #   readOnly: false
              #   serverAddress: "192.0.2.0"
              #   serverPath: /var/lib/containers
              # - type: PVC
              #   claimName: mypvc
              #   mountPath: /var/myapp/mypvc
              #   readOnly: false
              # - type: Secret
              #   defaultMode: "600"
              #   mountPath: /var/myapp/mysecret
              #   secretName: mysecret
              # Pod-wide environment, these vars are visible to any container in the agent pod

              # You can define the workspaceVolume that you want to mount for this container
              # Allowed types are: DynamicPVC, EmptyDir, HostPath, Nfs, PVC
              # Configure the attributes as they appear in the corresponding Java class for that type
              # https://github.com/jenkinsci/kubernetes-plugin/tree/master/src/main/java/org/csanchez/jenkins/plugins/kubernetes/volumes/workspace
              workspaceVolume: {}
              ## DynamicPVC example
              # type: DynamicPVC
              # configMapName: myconfigmap
              ## EmptyDir example
              # type: EmptyDir
              # memory: false
              ## HostPath example
              # type: HostPath
              # hostPath: /var/lib/containers
              ## NFS example
              # type: Nfs
              # readOnly: false
              # serverAddress: "192.0.2.0"
              # serverPath: /var/lib/containers
              ## PVC example
              # type: PVC
              # claimName: mypvc
              # readOnly: false
              #
              # Pod-wide environment, these vars are visible to any container in the agent pod
              envVars: []
              # - name: PATH
              #   value: /usr/local/bin
              nodeSelector: {}
              # Key Value selectors. Ex:
              # jenkins-agent: v1

              # Executed command when side container gets started
              command:
              args: "${computer.jnlpmac} ${computer.name}"
              # Side container name
              sideContainerName: "jnlp"
              # Doesn't allocate pseudo TTY by default
              TTYEnabled: false
              # Max number of spawned agent
              containerCap: 10
              # Pod name
              podName: "jenkins-agent"
              # Allows the Pod to remain active for reuse until the configured number of
              # minutes has passed since the last step was executed on it.
              idleMinutes: 5
              # Raw yaml template for the Pod. For example this allows usage of toleration for agent pods.
              # https://github.com/jenkinsci/kubernetes-plugin#using-yaml-to-define-pod-templates
              # https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
              yamlTemplate: ""
              # yamlTemplate: |-
              #   apiVersion: v1
              #   kind: Pod
              #   annotations:
              #     container.apparmor.security.beta.kubernetes.io/jenkins-agent: unconfined
              # Defines how the raw yaml field gets merged with yaml definitions from inherited pod templates: merge or override
              yamlMergeStrategy: "override"
              # Timeout in seconds for an agent to be online
              connectTimeout: 100
              # Annotations to apply to the pod.
              annotations: {
                container.apparmor.security.beta.kubernetes.io/jnlp: unconfined
              }

              # Disable the default Jenkins Agent configuration.
              # Useful when configuring agents only with the podTemplates value, since the default podTemplate populated by values mentioned above will be excluded in the rendered template.
              disableDefaultAgent: false

              # Below is the implementation of custom pod templates for the default configured kubernetes cloud.
              # Add a key under podTemplates for each pod template. Each key (prior to | character) is just a label, and can be any value.
              # Keys are only used to give the pod template a meaningful name.  The only restriction is they may only contain RFC 1123 \ DNS label
              # characters: lowercase letters, numbers, and hyphens. Each pod template can contain multiple containers.
              # For this pod templates configuration to be loaded the following values must be set:
              # controller.JCasC.defaultConfig: true
              # Best reference is https://<jenkins_url>/configuration-as-code/reference#Cloud-kubernetes. The example below creates a python pod template.
              podTemplates: {}
              #  python: |
              #    - name: python
              #      label: jenkins-python
              #      serviceAccount: jenkins
              #      containers:
              #        - name: python
              #          image: python:3
              #          command: "/bin/sh -c"
              #          args: "cat"
              #          ttyEnabled: true
              #          privileged: true
              #          resourceRequestCpu: "400m"
              #          resourceRequestMemory: "512Mi"
              #          resourceLimitCpu: "1"
              #          resourceLimitMemory: "1024Mi"

            # Here you can add additional agents
            # They inherit all values from `agent` so you only need to specify values which differ
            additionalAgents: {}
            #  maven:
            #    podName: maven
            #    customJenkinsLabels: maven
            #    # An example of overriding the jnlp container
            #    # sideContainerName: jnlp
            #    image: jenkins/jnlp-agent-maven
            #    tag: latest
            #  python:
            #    podName: python
            #    customJenkinsLabels: python
            #    sideContainerName: python
            #    image: python
            #    tag: "3"
            #    command: "/bin/sh -c"
            #    args: "cat"
            #    TTYEnabled: true

            persistence:
              enabled: true
              ## A manually managed Persistent Volume and Claim
              ## Requires persistence.enabled: true
              ## If defined, PVC must be created manually before volume will be bound
              existingClaim:
              ## jenkins data Persistent Volume Storage Class
              ## If defined, storageClassName: <storageClass>
              ## If set to "-", storageClassName: "", which disables dynamic provisioning
              ## If undefined (the default) or set to null, no storageClassName spec is
              ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
              ##   GKE, AWS & OpenStack)
              ##
              storageClass:
              annotations: {}
              labels: {}
              accessMode: "ReadWriteOnce"
              size: "10Gi"
              volumes:
              #  - name: nothing
              #    emptyDir: {}
              mounts:
              #  - mountPath: /var/nothing
              #    name: nothing
              #    readOnly: true

            serviceAccount:
              create: false
              # The name of the service account is autogenerated by default
              name: jenkins
              annotations: {}
              imagePullSecretName:
        repoURL: https://charts.jenkins.io
        targetRevision: 4.1.12
  reconciledAt: "2022-08-29T06:10:47Z"
  resources:
  - kind: ConfigMap
    name: jenkins
    namespace: jenkins
    status: Synced
    version: v1
  - kind: ConfigMap
    name: jenkins-jenkins-jcasc-config
    namespace: jenkins
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: PersistentVolumeClaim
    name: jenkins
    namespace: jenkins
    status: Synced
    version: v1
  - kind: Secret
    name: jenkins
    namespace: jenkins
    status: OutOfSync
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: jenkins
    namespace: jenkins
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: jenkins-agent
    namespace: jenkins
    status: Synced
    version: v1
  - group: apps
    health:
      message: 'partitioned roll out complete: 1 new pods have been updated...'
      status: Healthy
    kind: StatefulSet
    name: jenkins
    namespace: jenkins
    status: Synced
    version: v1
  - group: cilium.io
    kind: CiliumIdentity
    name: "55999"
    requiresPruning: true
    status: OutOfSync
    version: v2
  - group: rbac.authorization.k8s.io
    kind: Role
    name: jenkins-casc-reload
    namespace: jenkins
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: Role
    name: jenkins-schedule-agents
    namespace: jenkins
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: RoleBinding
    name: jenkins-schedule-agents
    namespace: jenkins
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: RoleBinding
    name: jenkins-watch-configmaps
    namespace: jenkins
    status: Synced
    version: v1
  sourceType: Helm
  summary:
    images:
    - jenkins/jenkins:2.346.1-jdk11
    - kiwigrid/k8s-sidecar:1.15.0
  sync:
    comparedTo:
      destination:
        namespace: jenkins
        server: https://kubernetes.default.svc
      source:
        chart: jenkins
        helm:
          parameters:
          - name: serviceAccount.create
            value: "false"
          - name: serviceAccount.name
            value: jenkins
          - name: persistence.size
            value: 10Gi
          - name: agent.alwaysPullImage
            value: "true"
          - name: agent.tag
            value: latest
          - name: agent.image
            value: bensonyanger/jenkins-agent
          valueFiles:
          - values.yaml
          values: |
            agent:
              enabled: true
              defaultsProviderTemplate: ""
              # URL for connecting to the Jenkins contoller
              jenkinsUrl:
              # connect to the specified host and port, instead of connecting directly to the Jenkins controller
              jenkinsTunnel:
              kubernetesConnectTimeout: 5
              kubernetesReadTimeout: 15
              maxRequestsPerHostStr: "32"
              namespace:
              image: "jenkins/inbound-agent"
              tag: "4.11.2-4"
              workingDir: "/home/jenkins/agent"
              nodeUsageMode: "NORMAL"
              customJenkinsLabels: []
              # name of the secret to be used for image pulling
              imagePullSecretName:
              componentName: "jenkins-agent"
              websocket: false
              privileged: false
              runAsUser:
              runAsGroup:
              resources:
                requests:
                  cpu: "512m"
                  memory: "512Mi"
                limits:
                  cpu: "512m"
                  memory: "512Mi"
              # You may want to change this to true while testing a new image
              alwaysPullImage: false
              # Controls how agent pods are retained after the Jenkins build completes
              # Possible values: Always, Never, OnFailure
              podRetention: "Never"
              # Disable if you do not want the Yaml the agent pod template to show up
              # in the job Console Output. This can be helpful for either security reasons
              # or simply to clean up the output to make it easier to read.
              showRawYaml: true
              # You can define the volumes that you want to mount for this container
              # Allowed types are: ConfigMap, EmptyDir, HostPath, Nfs, PVC, Secret
              # Configure the attributes as they appear in the corresponding Java class for that type
              # https://github.com/jenkinsci/kubernetes-plugin/tree/master/src/main/java/org/csanchez/jenkins/plugins/kubernetes/volumes
              volumes: []
              # - type: ConfigMap
              #   configMapName: myconfigmap
              #   mountPath: /var/myapp/myconfigmap
              # - type: EmptyDir
              #   mountPath: /var/myapp/myemptydir
              #   memory: false
              # - type: HostPath
              #   hostPath: /var/lib/containers
              #   mountPath: /var/myapp/myhostpath
              # - type: Nfs
              #   mountPath: /var/myapp/mynfs
              #   readOnly: false
              #   serverAddress: "192.0.2.0"
              #   serverPath: /var/lib/containers
              # - type: PVC
              #   claimName: mypvc
              #   mountPath: /var/myapp/mypvc
              #   readOnly: false
              # - type: Secret
              #   defaultMode: "600"
              #   mountPath: /var/myapp/mysecret
              #   secretName: mysecret
              # Pod-wide environment, these vars are visible to any container in the agent pod

              # You can define the workspaceVolume that you want to mount for this container
              # Allowed types are: DynamicPVC, EmptyDir, HostPath, Nfs, PVC
              # Configure the attributes as they appear in the corresponding Java class for that type
              # https://github.com/jenkinsci/kubernetes-plugin/tree/master/src/main/java/org/csanchez/jenkins/plugins/kubernetes/volumes/workspace
              workspaceVolume: {}
              ## DynamicPVC example
              # type: DynamicPVC
              # configMapName: myconfigmap
              ## EmptyDir example
              # type: EmptyDir
              # memory: false
              ## HostPath example
              # type: HostPath
              # hostPath: /var/lib/containers
              ## NFS example
              # type: Nfs
              # readOnly: false
              # serverAddress: "192.0.2.0"
              # serverPath: /var/lib/containers
              ## PVC example
              # type: PVC
              # claimName: mypvc
              # readOnly: false
              #
              # Pod-wide environment, these vars are visible to any container in the agent pod
              envVars: []
              # - name: PATH
              #   value: /usr/local/bin
              nodeSelector: {}
              # Key Value selectors. Ex:
              # jenkins-agent: v1

              # Executed command when side container gets started
              command:
              args: "${computer.jnlpmac} ${computer.name}"
              # Side container name
              sideContainerName: "jnlp"
              # Doesn't allocate pseudo TTY by default
              TTYEnabled: false
              # Max number of spawned agent
              containerCap: 10
              # Pod name
              podName: "jenkins-agent"
              # Allows the Pod to remain active for reuse until the configured number of
              # minutes has passed since the last step was executed on it.
              idleMinutes: 5
              # Raw yaml template for the Pod. For example this allows usage of toleration for agent pods.
              # https://github.com/jenkinsci/kubernetes-plugin#using-yaml-to-define-pod-templates
              # https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
              yamlTemplate: ""
              # yamlTemplate: |-
              #   apiVersion: v1
              #   kind: Pod
              #   annotations:
              #     container.apparmor.security.beta.kubernetes.io/jenkins-agent: unconfined
              # Defines how the raw yaml field gets merged with yaml definitions from inherited pod templates: merge or override
              yamlMergeStrategy: "override"
              # Timeout in seconds for an agent to be online
              connectTimeout: 100
              # Annotations to apply to the pod.
              annotations: {
                container.apparmor.security.beta.kubernetes.io/jnlp: unconfined
              }

              # Disable the default Jenkins Agent configuration.
              # Useful when configuring agents only with the podTemplates value, since the default podTemplate populated by values mentioned above will be excluded in the rendered template.
              disableDefaultAgent: false

              # Below is the implementation of custom pod templates for the default configured kubernetes cloud.
              # Add a key under podTemplates for each pod template. Each key (prior to | character) is just a label, and can be any value.
              # Keys are only used to give the pod template a meaningful name.  The only restriction is they may only contain RFC 1123 \ DNS label
              # characters: lowercase letters, numbers, and hyphens. Each pod template can contain multiple containers.
              # For this pod templates configuration to be loaded the following values must be set:
              # controller.JCasC.defaultConfig: true
              # Best reference is https://<jenkins_url>/configuration-as-code/reference#Cloud-kubernetes. The example below creates a python pod template.
              podTemplates: {}
              #  python: |
              #    - name: python
              #      label: jenkins-python
              #      serviceAccount: jenkins
              #      containers:
              #        - name: python
              #          image: python:3
              #          command: "/bin/sh -c"
              #          args: "cat"
              #          ttyEnabled: true
              #          privileged: true
              #          resourceRequestCpu: "400m"
              #          resourceRequestMemory: "512Mi"
              #          resourceLimitCpu: "1"
              #          resourceLimitMemory: "1024Mi"

            # Here you can add additional agents
            # They inherit all values from `agent` so you only need to specify values which differ
            additionalAgents: {}
            #  maven:
            #    podName: maven
            #    customJenkinsLabels: maven
            #    # An example of overriding the jnlp container
            #    # sideContainerName: jnlp
            #    image: jenkins/jnlp-agent-maven
            #    tag: latest
            #  python:
            #    podName: python
            #    customJenkinsLabels: python
            #    sideContainerName: python
            #    image: python
            #    tag: "3"
            #    command: "/bin/sh -c"
            #    args: "cat"
            #    TTYEnabled: true

            persistence:
              enabled: true
              ## A manually managed Persistent Volume and Claim
              ## Requires persistence.enabled: true
              ## If defined, PVC must be created manually before volume will be bound
              existingClaim:
              ## jenkins data Persistent Volume Storage Class
              ## If defined, storageClassName: <storageClass>
              ## If set to "-", storageClassName: "", which disables dynamic provisioning
              ## If undefined (the default) or set to null, no storageClassName spec is
              ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
              ##   GKE, AWS & OpenStack)
              ##
              storageClass:
              annotations: {}
              labels: {}
              accessMode: "ReadWriteOnce"
              size: "10Gi"
              volumes:
              #  - name: nothing
              #    emptyDir: {}
              mounts:
              #  - mountPath: /var/nothing
              #    name: nothing
              #    readOnly: true

            serviceAccount:
              create: false
              # The name of the service account is autogenerated by default
              name: jenkins
              annotations: {}
              imagePullSecretName:
        repoURL: https://charts.jenkins.io
        targetRevision: 4.1.12
    revision: 4.1.12
    status: OutOfSync
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: jwt-mysql
spec:
  destination:
    namespace: challenges
    server: https://kubernetes.default.svc
  project: default
  source:
    chart: mysql
    repoURL: https://charts.bitnami.com/bitnami
    targetRevision: 9.3.1
status:
  health:
    status: Missing
  history:
  - deployStartedAt: "2022-08-25T07:07:45Z"
    deployedAt: "2022-08-25T07:07:46Z"
    id: 0
    revision: 9.3.1
    source:
      chart: mysql
      repoURL: https://charts.bitnami.com/bitnami
      targetRevision: 9.3.1
  - deployStartedAt: "2022-08-25T07:14:00Z"
    deployedAt: "2022-08-25T07:14:01Z"
    id: 1
    revision: 9.3.1
    source:
      chart: mysql
      repoURL: https://charts.bitnami.com/bitnami
      targetRevision: 9.3.1
  operationState:
    finishedAt: "2022-08-25T07:14:01Z"
    message: successfully synced (all tasks run)
    operation:
      initiatedBy:
        username: admin
      retry: {}
      sync:
        revision: 9.3.1
        syncStrategy:
          hook: {}
    phase: Succeeded
    startedAt: "2022-08-25T07:14:00Z"
    syncResult:
      resources:
      - group: cilium.io
        hookPhase: Succeeded
        kind: CiliumIdentity
        message: ignored (requires pruning)
        name: "50637"
        namespace: ""
        status: PruneSkipped
        syncPhase: Sync
        version: v2
      - group: ""
        hookPhase: Running
        kind: ServiceAccount
        message: serviceaccount/jwt-mysql unchanged
        name: jwt-mysql
        namespace: challenges
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Secret
        message: secret/jwt-mysql unchanged
        name: jwt-mysql
        namespace: challenges
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: ConfigMap
        message: configmap/jwt-mysql unchanged
        name: jwt-mysql
        namespace: challenges
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/jwt-mysql-headless unchanged
        name: jwt-mysql-headless
        namespace: challenges
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/jwt-mysql configured
        name: jwt-mysql
        namespace: challenges
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Running
        kind: StatefulSet
        message: statefulset.apps/jwt-mysql configured
        name: jwt-mysql
        namespace: challenges
        status: Synced
        syncPhase: Sync
        version: v1
      revision: 9.3.1
      source:
        chart: mysql
        repoURL: https://charts.bitnami.com/bitnami
        targetRevision: 9.3.1
  reconciledAt: "2022-08-29T06:10:47Z"
  resources:
  - health:
      status: Missing
    kind: ConfigMap
    name: jwt-mysql
    namespace: challenges
    status: OutOfSync
    version: v1
  - health:
      status: Missing
    kind: Secret
    name: jwt-mysql
    namespace: challenges
    status: OutOfSync
    version: v1
  - health:
      status: Missing
    kind: Service
    name: jwt-mysql
    namespace: challenges
    status: OutOfSync
    version: v1
  - health:
      status: Missing
    kind: Service
    name: jwt-mysql-headless
    namespace: challenges
    status: OutOfSync
    version: v1
  - health:
      status: Missing
    kind: ServiceAccount
    name: jwt-mysql
    namespace: challenges
    status: OutOfSync
    version: v1
  - group: apps
    health:
      status: Missing
    kind: StatefulSet
    name: jwt-mysql
    namespace: challenges
    status: OutOfSync
    version: v1
  sourceType: Helm
  summary: {}
  sync:
    comparedTo:
      destination:
        namespace: challenges
        server: https://kubernetes.default.svc
      source:
        chart: mysql
        repoURL: https://charts.bitnami.com/bitnami
        targetRevision: 9.3.1
    revision: 9.3.1
    status: OutOfSync
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: maplebacoin-redis
spec:
  destination:
    namespace: challenges
    server: https://kubernetes.default.svc
  project: default
  source:
    chart: redis
    helm:
      parameters:
      - name: auth.password
        value: tfdSWdM6BMPD
      - name: architecture
        value: standalone
    repoURL: https://charts.bitnami.com/bitnami
    targetRevision: 17.1.2
status:
  health:
    status: Missing
  history:
  - deployStartedAt: "2022-08-26T07:58:48Z"
    deployedAt: "2022-08-26T07:58:49Z"
    id: 0
    revision: 17.1.2
    source:
      chart: redis
      helm:
        parameters:
        - name: auth.password
          value: tfdSWdM6BMPD
        - name: architecture
          value: standalone
      repoURL: https://charts.bitnami.com/bitnami
      targetRevision: 17.1.2
  operationState:
    finishedAt: "2022-08-26T07:58:49Z"
    message: successfully synced (all tasks run)
    operation:
      initiatedBy:
        username: admin
      retry: {}
      sync:
        revision: 17.1.2
        syncStrategy:
          hook: {}
    phase: Succeeded
    startedAt: "2022-08-26T07:58:48Z"
    syncResult:
      resources:
      - group: ""
        hookPhase: Running
        kind: ServiceAccount
        message: serviceaccount/maplebacoin-redis created
        name: maplebacoin-redis
        namespace: challenges
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Secret
        message: secret/maplebacoin-redis created
        name: maplebacoin-redis
        namespace: challenges
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: ConfigMap
        message: configmap/maplebacoin-redis-configuration created
        name: maplebacoin-redis-configuration
        namespace: challenges
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: ConfigMap
        message: configmap/maplebacoin-redis-health created
        name: maplebacoin-redis-health
        namespace: challenges
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: ConfigMap
        message: configmap/maplebacoin-redis-scripts created
        name: maplebacoin-redis-scripts
        namespace: challenges
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/maplebacoin-redis-master created
        name: maplebacoin-redis-master
        namespace: challenges
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/maplebacoin-redis-headless created
        name: maplebacoin-redis-headless
        namespace: challenges
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Running
        kind: StatefulSet
        message: statefulset.apps/maplebacoin-redis-master created
        name: maplebacoin-redis-master
        namespace: challenges
        status: Synced
        syncPhase: Sync
        version: v1
      revision: 17.1.2
      source:
        chart: redis
        helm:
          parameters:
          - name: auth.password
            value: tfdSWdM6BMPD
          - name: architecture
            value: standalone
        repoURL: https://charts.bitnami.com/bitnami
        targetRevision: 17.1.2
  reconciledAt: "2022-08-29T06:10:47Z"
  resources:
  - health:
      status: Missing
    kind: ConfigMap
    name: maplebacoin-redis-configuration
    namespace: challenges
    status: OutOfSync
    version: v1
  - health:
      status: Missing
    kind: ConfigMap
    name: maplebacoin-redis-health
    namespace: challenges
    status: OutOfSync
    version: v1
  - health:
      status: Missing
    kind: ConfigMap
    name: maplebacoin-redis-scripts
    namespace: challenges
    status: OutOfSync
    version: v1
  - health:
      status: Missing
    kind: Secret
    name: maplebacoin-redis
    namespace: challenges
    status: OutOfSync
    version: v1
  - health:
      status: Missing
    kind: Service
    name: maplebacoin-redis-headless
    namespace: challenges
    status: OutOfSync
    version: v1
  - health:
      status: Missing
    kind: Service
    name: maplebacoin-redis-master
    namespace: challenges
    status: OutOfSync
    version: v1
  - health:
      status: Missing
    kind: ServiceAccount
    name: maplebacoin-redis
    namespace: challenges
    status: OutOfSync
    version: v1
  - group: apps
    health:
      status: Missing
    kind: StatefulSet
    name: maplebacoin-redis-master
    namespace: challenges
    status: OutOfSync
    version: v1
  sourceType: Helm
  summary: {}
  sync:
    comparedTo:
      destination:
        namespace: challenges
        server: https://kubernetes.default.svc
      source:
        chart: redis
        helm:
          parameters:
          - name: auth.password
            value: tfdSWdM6BMPD
          - name: architecture
            value: standalone
        repoURL: https://charts.bitnami.com/bitnami
        targetRevision: 17.1.2
    revision: 17.1.2
    status: OutOfSync
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: mysql
spec:
  destination:
    namespace: mysql
    server: https://kubernetes.default.svc
  project: default
  source:
    chart: mysql
    helm:
      parameters:
      - name: secondary.pdb.create
        value: "true"
      - name: secondary.replicaCount
        value: "3"
      - name: auth.existingSecret
        value: mysql
      - name: architecture
        value: replication
      valueFiles:
      - values.yaml
      values: |-
        architecture: replication
        primary:
          configuration: |-
            [mysqld]
            default_authentication_plugin=mysql_native_password
            skip-name-resolve
            explicit_defaults_for_timestamp
            basedir=/opt/bitnami/mysql
            plugin_dir=/opt/bitnami/mysql/lib/plugin
            port=3306
            socket=/opt/bitnami/mysql/tmp/mysql.sock
            datadir=/bitnami/mysql/data
            tmpdir=/opt/bitnami/mysql/tmp
            max_allowed_packet=16M
            bind-address=0.0.0.0
            pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
            log-error=/opt/bitnami/mysql/logs/mysqld.log
            character-set-server=UTF8
            collation-server=utf8_general_ci
            slow_query_log=0
            slow_query_log_file=/opt/bitnami/mysql/logs/mysqld.log
            long_query_time=10.0
            max_connections=1000

            [client]
            port=3306
            socket=/opt/bitnami/mysql/tmp/mysql.sock
            default-character-set=UTF8
            plugin_dir=/opt/bitnami/mysql/lib/plugin

            [manager]
            port=3306
            socket=/opt/bitnami/mysql/tmp/mysql.sock
            pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
          nodeAffinityPreset:
            type: "hard"
            key: node_pool
            operator: In
            values:
            - ctfd-node-pool
          tolerations:
          - key: "ctfd-node-pool"
            operator: "Equal"
            value: "true"
            effect: "NoSchedule"
        secondary:
          configuration: |-
            [mysqld]
            default_authentication_plugin=mysql_native_password
            skip-name-resolve
            explicit_defaults_for_timestamp
            basedir=/opt/bitnami/mysql
            plugin_dir=/opt/bitnami/mysql/lib/plugin
            port=3306
            socket=/opt/bitnami/mysql/tmp/mysql.sock
            datadir=/bitnami/mysql/data
            tmpdir=/opt/bitnami/mysql/tmp
            max_allowed_packet=16M
            bind-address=0.0.0.0
            pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
            log-error=/opt/bitnami/mysql/logs/mysqld.log
            character-set-server=UTF8
            collation-server=utf8_general_ci
            slow_query_log=0
            slow_query_log_file=/opt/bitnami/mysql/logs/mysqld.log
            long_query_time=10.0
            max_connections=1000

            [client]
            port=3306
            socket=/opt/bitnami/mysql/tmp/mysql.sock
            default-character-set=UTF8
            plugin_dir=/opt/bitnami/mysql/lib/plugin

            [manager]
            port=3306
            socket=/opt/bitnami/mysql/tmp/mysql.sock
            pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
          tolerations:
          - key: "ctfd-node-pool"
            operator: "Equal"
            value: "true"
            effect: "NoSchedule"
          replicaCount: 3
        metrics:
          enabled: true
          serviceMonitor:
            enabled: true
            namespace: monitoring
    repoURL: https://charts.bitnami.com/bitnami
    targetRevision: 9.1.8
  syncPolicy:
    automated: {}
status:
  health:
    status: Healthy
  history:
  - deployStartedAt: "2022-08-24T01:37:08Z"
    deployedAt: "2022-08-24T01:37:09Z"
    id: 19
    revision: 9.1.8
    source:
      chart: mysql
      helm:
        parameters:
        - name: secondary.pdb.create
          value: "true"
        - name: secondary.replicaCount
          value: "3"
        - name: auth.existingSecret
          value: mysql
        valueFiles:
        - values.yaml
        values: |-
          architecture: replication
          primary:
            configuration: |-
              [mysqld]
              default_authentication_plugin=mysql_native_password
              skip-name-resolve
              explicit_defaults_for_timestamp
              basedir=/opt/bitnami/mysql
              plugin_dir=/opt/bitnami/mysql/lib/plugin
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              datadir=/bitnami/mysql/data
              tmpdir=/opt/bitnami/mysql/tmp
              max_allowed_packet=16M
              bind-address=0.0.0.0
              pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
              log-error=/opt/bitnami/mysql/logs/mysqld.log
              character-set-server=UTF8
              collation-server=utf8_general_ci
              slow_query_log=0
              slow_query_log_file=/opt/bitnami/mysql/logs/mysqld.log
              long_query_time=10.0
              max_connections=250

              [client]
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              default-character-set=UTF8
              plugin_dir=/opt/bitnami/mysql/lib/plugin

              [manager]
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
            nodeAffinityPreset:
              type: "hard"
              key: "node_pool=ctfd-node-pool"
            tolerations:
            - key: "ctfd-node-pool"
              operator: "Equal"
              value: "true"
              effect: "NoSchedule"
          secondary:
            configuration: |-
              [mysqld]
              default_authentication_plugin=mysql_native_password
              skip-name-resolve
              explicit_defaults_for_timestamp
              basedir=/opt/bitnami/mysql
              plugin_dir=/opt/bitnami/mysql/lib/plugin
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              datadir=/bitnami/mysql/data
              tmpdir=/opt/bitnami/mysql/tmp
              max_allowed_packet=16M
              bind-address=0.0.0.0
              pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
              log-error=/opt/bitnami/mysql/logs/mysqld.log
              character-set-server=UTF8
              collation-server=utf8_general_ci
              slow_query_log=0
              slow_query_log_file=/opt/bitnami/mysql/logs/mysqld.log
              long_query_time=10.0
              max_connections=250

              [client]
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              default-character-set=UTF8
              plugin_dir=/opt/bitnami/mysql/lib/plugin

              [manager]
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
            tolerations:
            - key: "ctfd-node-pool"
              operator: "Equal"
              value: "true"
              effect: "NoSchedule"
            replicaCount: 3
      repoURL: https://charts.bitnami.com/bitnami
      targetRevision: 9.1.8
  - deployStartedAt: "2022-08-24T01:39:02Z"
    deployedAt: "2022-08-24T01:39:02Z"
    id: 20
    revision: 9.1.8
    source:
      chart: mysql
      helm:
        parameters:
        - name: secondary.pdb.create
          value: "true"
        - name: secondary.replicaCount
          value: "3"
        - name: auth.existingSecret
          value: mysql
        valueFiles:
        - values.yaml
        values: |-
          architecture: replication
          primary:
            configuration: |-
              [mysqld]
              default_authentication_plugin=mysql_native_password
              skip-name-resolve
              explicit_defaults_for_timestamp
              basedir=/opt/bitnami/mysql
              plugin_dir=/opt/bitnami/mysql/lib/plugin
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              datadir=/bitnami/mysql/data
              tmpdir=/opt/bitnami/mysql/tmp
              max_allowed_packet=16M
              bind-address=0.0.0.0
              pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
              log-error=/opt/bitnami/mysql/logs/mysqld.log
              character-set-server=UTF8
              collation-server=utf8_general_ci
              slow_query_log=0
              slow_query_log_file=/opt/bitnami/mysql/logs/mysqld.log
              long_query_time=10.0
              max_connections=250

              [client]
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              default-character-set=UTF8
              plugin_dir=/opt/bitnami/mysql/lib/plugin

              [manager]
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
            nodeAffinityPreset:
              type: "hard"
              key: node_pool
              operator: In
              values:
              - ctfd-node-pool
            tolerations:
            - key: "ctfd-node-pool"
              operator: "Equal"
              value: "true"
              effect: "NoSchedule"
          secondary:
            configuration: |-
              [mysqld]
              default_authentication_plugin=mysql_native_password
              skip-name-resolve
              explicit_defaults_for_timestamp
              basedir=/opt/bitnami/mysql
              plugin_dir=/opt/bitnami/mysql/lib/plugin
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              datadir=/bitnami/mysql/data
              tmpdir=/opt/bitnami/mysql/tmp
              max_allowed_packet=16M
              bind-address=0.0.0.0
              pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
              log-error=/opt/bitnami/mysql/logs/mysqld.log
              character-set-server=UTF8
              collation-server=utf8_general_ci
              slow_query_log=0
              slow_query_log_file=/opt/bitnami/mysql/logs/mysqld.log
              long_query_time=10.0
              max_connections=250

              [client]
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              default-character-set=UTF8
              plugin_dir=/opt/bitnami/mysql/lib/plugin

              [manager]
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
            tolerations:
            - key: "ctfd-node-pool"
              operator: "Equal"
              value: "true"
              effect: "NoSchedule"
            replicaCount: 3
      repoURL: https://charts.bitnami.com/bitnami
      targetRevision: 9.1.8
  - deployStartedAt: "2022-08-24T01:39:05Z"
    deployedAt: "2022-08-24T01:39:06Z"
    id: 21
    revision: 9.1.8
    source:
      chart: mysql
      helm:
        parameters:
        - name: secondary.pdb.create
          value: "true"
        - name: secondary.replicaCount
          value: "3"
        - name: auth.existingSecret
          value: mysql
        valueFiles:
        - values.yaml
        values: |-
          architecture: replication
          primary:
            configuration: |-
              [mysqld]
              default_authentication_plugin=mysql_native_password
              skip-name-resolve
              explicit_defaults_for_timestamp
              basedir=/opt/bitnami/mysql
              plugin_dir=/opt/bitnami/mysql/lib/plugin
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              datadir=/bitnami/mysql/data
              tmpdir=/opt/bitnami/mysql/tmp
              max_allowed_packet=16M
              bind-address=0.0.0.0
              pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
              log-error=/opt/bitnami/mysql/logs/mysqld.log
              character-set-server=UTF8
              collation-server=utf8_general_ci
              slow_query_log=0
              slow_query_log_file=/opt/bitnami/mysql/logs/mysqld.log
              long_query_time=10.0
              max_connections=250

              [client]
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              default-character-set=UTF8
              plugin_dir=/opt/bitnami/mysql/lib/plugin

              [manager]
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
            nodeAffinityPreset:
              type: "hard"
              key: node_pool
              operator: In
              values:
              - ctfd-node-pool
            tolerations:
            - key: "ctfd-node-pool"
              operator: "Equal"
              value: "true"
              effect: "NoSchedule"
          secondary:
            configuration: |-
              [mysqld]
              default_authentication_plugin=mysql_native_password
              skip-name-resolve
              explicit_defaults_for_timestamp
              basedir=/opt/bitnami/mysql
              plugin_dir=/opt/bitnami/mysql/lib/plugin
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              datadir=/bitnami/mysql/data
              tmpdir=/opt/bitnami/mysql/tmp
              max_allowed_packet=16M
              bind-address=0.0.0.0
              pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
              log-error=/opt/bitnami/mysql/logs/mysqld.log
              character-set-server=UTF8
              collation-server=utf8_general_ci
              slow_query_log=0
              slow_query_log_file=/opt/bitnami/mysql/logs/mysqld.log
              long_query_time=10.0
              max_connections=250

              [client]
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              default-character-set=UTF8
              plugin_dir=/opt/bitnami/mysql/lib/plugin

              [manager]
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
            tolerations:
            - key: "ctfd-node-pool"
              operator: "Equal"
              value: "true"
              effect: "NoSchedule"
            replicaCount: 3
      repoURL: https://charts.bitnami.com/bitnami
      targetRevision: 9.1.8
  - deployStartedAt: "2022-08-24T13:18:01Z"
    deployedAt: "2022-08-24T13:18:02Z"
    id: 22
    revision: 9.1.8
    source:
      chart: mysql
      helm:
        parameters:
        - name: secondary.pdb.create
          value: "true"
        - name: secondary.replicaCount
          value: "3"
        - name: auth.existingSecret
          value: mysql
        - name: architecture
          value: replication
        valueFiles:
        - values.yaml
        values: |-
          architecture: replication
          primary:
            configuration: |-
              [mysqld]
              default_authentication_plugin=mysql_native_password
              skip-name-resolve
              explicit_defaults_for_timestamp
              basedir=/opt/bitnami/mysql
              plugin_dir=/opt/bitnami/mysql/lib/plugin
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              datadir=/bitnami/mysql/data
              tmpdir=/opt/bitnami/mysql/tmp
              max_allowed_packet=16M
              bind-address=0.0.0.0
              pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
              log-error=/opt/bitnami/mysql/logs/mysqld.log
              character-set-server=UTF8
              collation-server=utf8_general_ci
              slow_query_log=0
              slow_query_log_file=/opt/bitnami/mysql/logs/mysqld.log
              long_query_time=10.0
              max_connections=250

              [client]
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              default-character-set=UTF8
              plugin_dir=/opt/bitnami/mysql/lib/plugin

              [manager]
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
            nodeAffinityPreset:
              type: "hard"
              key: node_pool
              operator: In
              values:
              - ctfd-node-pool
            tolerations:
            - key: "ctfd-node-pool"
              operator: "Equal"
              value: "true"
              effect: "NoSchedule"
          secondary:
            configuration: |-
              [mysqld]
              default_authentication_plugin=mysql_native_password
              skip-name-resolve
              explicit_defaults_for_timestamp
              basedir=/opt/bitnami/mysql
              plugin_dir=/opt/bitnami/mysql/lib/plugin
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              datadir=/bitnami/mysql/data
              tmpdir=/opt/bitnami/mysql/tmp
              max_allowed_packet=16M
              bind-address=0.0.0.0
              pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
              log-error=/opt/bitnami/mysql/logs/mysqld.log
              character-set-server=UTF8
              collation-server=utf8_general_ci
              slow_query_log=0
              slow_query_log_file=/opt/bitnami/mysql/logs/mysqld.log
              long_query_time=10.0
              max_connections=250

              [client]
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              default-character-set=UTF8
              plugin_dir=/opt/bitnami/mysql/lib/plugin

              [manager]
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
            tolerations:
            - key: "ctfd-node-pool"
              operator: "Equal"
              value: "true"
              effect: "NoSchedule"
            replicaCount: 3
      repoURL: https://charts.bitnami.com/bitnami
      targetRevision: 9.1.8
  - deployStartedAt: "2022-08-27T07:14:01Z"
    deployedAt: "2022-08-27T07:14:02Z"
    id: 23
    revision: 9.1.8
    source:
      chart: mysql
      helm:
        parameters:
        - name: secondary.pdb.create
          value: "true"
        - name: secondary.replicaCount
          value: "3"
        - name: auth.existingSecret
          value: mysql
        - name: architecture
          value: replication
        valueFiles:
        - values.yaml
        values: |-
          architecture: replication
          primary:
            configuration: |-
              [mysqld]
              default_authentication_plugin=mysql_native_password
              skip-name-resolve
              explicit_defaults_for_timestamp
              basedir=/opt/bitnami/mysql
              plugin_dir=/opt/bitnami/mysql/lib/plugin
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              datadir=/bitnami/mysql/data
              tmpdir=/opt/bitnami/mysql/tmp
              max_allowed_packet=16M
              bind-address=0.0.0.0
              pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
              log-error=/opt/bitnami/mysql/logs/mysqld.log
              character-set-server=UTF8
              collation-server=utf8_general_ci
              slow_query_log=0
              slow_query_log_file=/opt/bitnami/mysql/logs/mysqld.log
              long_query_time=10.0
              max_connections=1000

              [client]
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              default-character-set=UTF8
              plugin_dir=/opt/bitnami/mysql/lib/plugin

              [manager]
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
            nodeAffinityPreset:
              type: "hard"
              key: node_pool
              operator: In
              values:
              - ctfd-node-pool
            tolerations:
            - key: "ctfd-node-pool"
              operator: "Equal"
              value: "true"
              effect: "NoSchedule"
          secondary:
            configuration: |-
              [mysqld]
              default_authentication_plugin=mysql_native_password
              skip-name-resolve
              explicit_defaults_for_timestamp
              basedir=/opt/bitnami/mysql
              plugin_dir=/opt/bitnami/mysql/lib/plugin
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              datadir=/bitnami/mysql/data
              tmpdir=/opt/bitnami/mysql/tmp
              max_allowed_packet=16M
              bind-address=0.0.0.0
              pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
              log-error=/opt/bitnami/mysql/logs/mysqld.log
              character-set-server=UTF8
              collation-server=utf8_general_ci
              slow_query_log=0
              slow_query_log_file=/opt/bitnami/mysql/logs/mysqld.log
              long_query_time=10.0
              max_connections=1000

              [client]
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              default-character-set=UTF8
              plugin_dir=/opt/bitnami/mysql/lib/plugin

              [manager]
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
            tolerations:
            - key: "ctfd-node-pool"
              operator: "Equal"
              value: "true"
              effect: "NoSchedule"
            replicaCount: 3
      repoURL: https://charts.bitnami.com/bitnami
      targetRevision: 9.1.8
  - deployStartedAt: "2022-08-27T07:14:09Z"
    deployedAt: "2022-08-27T07:14:10Z"
    id: 24
    revision: 9.1.8
    source:
      chart: mysql
      helm:
        parameters:
        - name: secondary.pdb.create
          value: "true"
        - name: secondary.replicaCount
          value: "3"
        - name: auth.existingSecret
          value: mysql
        - name: architecture
          value: replication
        valueFiles:
        - values.yaml
        values: |-
          architecture: replication
          primary:
            configuration: |-
              [mysqld]
              default_authentication_plugin=mysql_native_password
              skip-name-resolve
              explicit_defaults_for_timestamp
              basedir=/opt/bitnami/mysql
              plugin_dir=/opt/bitnami/mysql/lib/plugin
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              datadir=/bitnami/mysql/data
              tmpdir=/opt/bitnami/mysql/tmp
              max_allowed_packet=16M
              bind-address=0.0.0.0
              pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
              log-error=/opt/bitnami/mysql/logs/mysqld.log
              character-set-server=UTF8
              collation-server=utf8_general_ci
              slow_query_log=0
              slow_query_log_file=/opt/bitnami/mysql/logs/mysqld.log
              long_query_time=10.0
              max_connections=1000

              [client]
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              default-character-set=UTF8
              plugin_dir=/opt/bitnami/mysql/lib/plugin

              [manager]
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
            nodeAffinityPreset:
              type: "hard"
              key: node_pool
              operator: In
              values:
              - ctfd-node-pool
            tolerations:
            - key: "ctfd-node-pool"
              operator: "Equal"
              value: "true"
              effect: "NoSchedule"
          secondary:
            configuration: |-
              [mysqld]
              default_authentication_plugin=mysql_native_password
              skip-name-resolve
              explicit_defaults_for_timestamp
              basedir=/opt/bitnami/mysql
              plugin_dir=/opt/bitnami/mysql/lib/plugin
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              datadir=/bitnami/mysql/data
              tmpdir=/opt/bitnami/mysql/tmp
              max_allowed_packet=16M
              bind-address=0.0.0.0
              pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
              log-error=/opt/bitnami/mysql/logs/mysqld.log
              character-set-server=UTF8
              collation-server=utf8_general_ci
              slow_query_log=0
              slow_query_log_file=/opt/bitnami/mysql/logs/mysqld.log
              long_query_time=10.0
              max_connections=1000

              [client]
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              default-character-set=UTF8
              plugin_dir=/opt/bitnami/mysql/lib/plugin

              [manager]
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
            tolerations:
            - key: "ctfd-node-pool"
              operator: "Equal"
              value: "true"
              effect: "NoSchedule"
            replicaCount: 3
      repoURL: https://charts.bitnami.com/bitnami
      targetRevision: 9.1.8
  - deployStartedAt: "2022-08-27T07:22:22Z"
    deployedAt: "2022-08-27T07:22:23Z"
    id: 25
    revision: 9.1.8
    source:
      chart: mysql
      helm:
        parameters:
        - name: secondary.pdb.create
          value: "true"
        - name: secondary.replicaCount
          value: "3"
        - name: auth.existingSecret
          value: mysql
        - name: architecture
          value: replication
        valueFiles:
        - values.yaml
        values: |-
          architecture: replication
          primary:
            configuration: |-
              [mysqld]
              default_authentication_plugin=mysql_native_password
              skip-name-resolve
              explicit_defaults_for_timestamp
              basedir=/opt/bitnami/mysql
              plugin_dir=/opt/bitnami/mysql/lib/plugin
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              datadir=/bitnami/mysql/data
              tmpdir=/opt/bitnami/mysql/tmp
              max_allowed_packet=16M
              bind-address=0.0.0.0
              pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
              log-error=/opt/bitnami/mysql/logs/mysqld.log
              character-set-server=UTF8
              collation-server=utf8_general_ci
              slow_query_log=0
              slow_query_log_file=/opt/bitnami/mysql/logs/mysqld.log
              long_query_time=10.0
              max_connections=1000

              [client]
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              default-character-set=UTF8
              plugin_dir=/opt/bitnami/mysql/lib/plugin

              [manager]
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
            nodeAffinityPreset:
              type: "hard"
              key: node_pool
              operator: In
              values:
              - ctfd-node-pool
            tolerations:
            - key: "ctfd-node-pool"
              operator: "Equal"
              value: "true"
              effect: "NoSchedule"
          secondary:
            configuration: |-
              [mysqld]
              default_authentication_plugin=mysql_native_password
              skip-name-resolve
              explicit_defaults_for_timestamp
              basedir=/opt/bitnami/mysql
              plugin_dir=/opt/bitnami/mysql/lib/plugin
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              datadir=/bitnami/mysql/data
              tmpdir=/opt/bitnami/mysql/tmp
              max_allowed_packet=16M
              bind-address=0.0.0.0
              pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
              log-error=/opt/bitnami/mysql/logs/mysqld.log
              character-set-server=UTF8
              collation-server=utf8_general_ci
              slow_query_log=0
              slow_query_log_file=/opt/bitnami/mysql/logs/mysqld.log
              long_query_time=10.0
              max_connections=1000

              [client]
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              default-character-set=UTF8
              plugin_dir=/opt/bitnami/mysql/lib/plugin

              [manager]
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
            tolerations:
            - key: "ctfd-node-pool"
              operator: "Equal"
              value: "true"
              effect: "NoSchedule"
            replicaCount: 3
          metrics:
            enabled: true
      repoURL: https://charts.bitnami.com/bitnami
      targetRevision: 9.1.8
  - deployStartedAt: "2022-08-27T07:22:37Z"
    deployedAt: "2022-08-27T07:22:37Z"
    id: 26
    revision: 9.1.8
    source:
      chart: mysql
      helm:
        parameters:
        - name: secondary.pdb.create
          value: "true"
        - name: secondary.replicaCount
          value: "3"
        - name: auth.existingSecret
          value: mysql
        - name: architecture
          value: replication
        valueFiles:
        - values.yaml
        values: |-
          architecture: replication
          primary:
            configuration: |-
              [mysqld]
              default_authentication_plugin=mysql_native_password
              skip-name-resolve
              explicit_defaults_for_timestamp
              basedir=/opt/bitnami/mysql
              plugin_dir=/opt/bitnami/mysql/lib/plugin
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              datadir=/bitnami/mysql/data
              tmpdir=/opt/bitnami/mysql/tmp
              max_allowed_packet=16M
              bind-address=0.0.0.0
              pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
              log-error=/opt/bitnami/mysql/logs/mysqld.log
              character-set-server=UTF8
              collation-server=utf8_general_ci
              slow_query_log=0
              slow_query_log_file=/opt/bitnami/mysql/logs/mysqld.log
              long_query_time=10.0
              max_connections=1000

              [client]
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              default-character-set=UTF8
              plugin_dir=/opt/bitnami/mysql/lib/plugin

              [manager]
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
            nodeAffinityPreset:
              type: "hard"
              key: node_pool
              operator: In
              values:
              - ctfd-node-pool
            tolerations:
            - key: "ctfd-node-pool"
              operator: "Equal"
              value: "true"
              effect: "NoSchedule"
          secondary:
            configuration: |-
              [mysqld]
              default_authentication_plugin=mysql_native_password
              skip-name-resolve
              explicit_defaults_for_timestamp
              basedir=/opt/bitnami/mysql
              plugin_dir=/opt/bitnami/mysql/lib/plugin
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              datadir=/bitnami/mysql/data
              tmpdir=/opt/bitnami/mysql/tmp
              max_allowed_packet=16M
              bind-address=0.0.0.0
              pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
              log-error=/opt/bitnami/mysql/logs/mysqld.log
              character-set-server=UTF8
              collation-server=utf8_general_ci
              slow_query_log=0
              slow_query_log_file=/opt/bitnami/mysql/logs/mysqld.log
              long_query_time=10.0
              max_connections=1000

              [client]
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              default-character-set=UTF8
              plugin_dir=/opt/bitnami/mysql/lib/plugin

              [manager]
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
            tolerations:
            - key: "ctfd-node-pool"
              operator: "Equal"
              value: "true"
              effect: "NoSchedule"
            replicaCount: 3
          metrics:
            enabled: true
      repoURL: https://charts.bitnami.com/bitnami
      targetRevision: 9.1.8
  - deployStartedAt: "2022-08-27T07:40:38Z"
    deployedAt: "2022-08-27T07:40:38Z"
    id: 27
    revision: 9.1.8
    source:
      chart: mysql
      helm:
        parameters:
        - name: secondary.pdb.create
          value: "true"
        - name: secondary.replicaCount
          value: "3"
        - name: auth.existingSecret
          value: mysql
        - name: architecture
          value: replication
        valueFiles:
        - values.yaml
        values: |-
          architecture: replication
          primary:
            configuration: |-
              [mysqld]
              default_authentication_plugin=mysql_native_password
              skip-name-resolve
              explicit_defaults_for_timestamp
              basedir=/opt/bitnami/mysql
              plugin_dir=/opt/bitnami/mysql/lib/plugin
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              datadir=/bitnami/mysql/data
              tmpdir=/opt/bitnami/mysql/tmp
              max_allowed_packet=16M
              bind-address=0.0.0.0
              pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
              log-error=/opt/bitnami/mysql/logs/mysqld.log
              character-set-server=UTF8
              collation-server=utf8_general_ci
              slow_query_log=0
              slow_query_log_file=/opt/bitnami/mysql/logs/mysqld.log
              long_query_time=10.0
              max_connections=1000

              [client]
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              default-character-set=UTF8
              plugin_dir=/opt/bitnami/mysql/lib/plugin

              [manager]
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
            nodeAffinityPreset:
              type: "hard"
              key: node_pool
              operator: In
              values:
              - ctfd-node-pool
            tolerations:
            - key: "ctfd-node-pool"
              operator: "Equal"
              value: "true"
              effect: "NoSchedule"
          secondary:
            configuration: |-
              [mysqld]
              default_authentication_plugin=mysql_native_password
              skip-name-resolve
              explicit_defaults_for_timestamp
              basedir=/opt/bitnami/mysql
              plugin_dir=/opt/bitnami/mysql/lib/plugin
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              datadir=/bitnami/mysql/data
              tmpdir=/opt/bitnami/mysql/tmp
              max_allowed_packet=16M
              bind-address=0.0.0.0
              pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
              log-error=/opt/bitnami/mysql/logs/mysqld.log
              character-set-server=UTF8
              collation-server=utf8_general_ci
              slow_query_log=0
              slow_query_log_file=/opt/bitnami/mysql/logs/mysqld.log
              long_query_time=10.0
              max_connections=1000

              [client]
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              default-character-set=UTF8
              plugin_dir=/opt/bitnami/mysql/lib/plugin

              [manager]
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
            tolerations:
            - key: "ctfd-node-pool"
              operator: "Equal"
              value: "true"
              effect: "NoSchedule"
            replicaCount: 3
          metrics:
            enabled: true
            serviceMonitor:
              enabled: true
              namespace: monitoring
      repoURL: https://charts.bitnami.com/bitnami
      targetRevision: 9.1.8
  - deployStartedAt: "2022-08-27T07:40:42Z"
    deployedAt: "2022-08-27T07:40:42Z"
    id: 28
    revision: 9.1.8
    source:
      chart: mysql
      helm:
        parameters:
        - name: secondary.pdb.create
          value: "true"
        - name: secondary.replicaCount
          value: "3"
        - name: auth.existingSecret
          value: mysql
        - name: architecture
          value: replication
        valueFiles:
        - values.yaml
        values: |-
          architecture: replication
          primary:
            configuration: |-
              [mysqld]
              default_authentication_plugin=mysql_native_password
              skip-name-resolve
              explicit_defaults_for_timestamp
              basedir=/opt/bitnami/mysql
              plugin_dir=/opt/bitnami/mysql/lib/plugin
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              datadir=/bitnami/mysql/data
              tmpdir=/opt/bitnami/mysql/tmp
              max_allowed_packet=16M
              bind-address=0.0.0.0
              pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
              log-error=/opt/bitnami/mysql/logs/mysqld.log
              character-set-server=UTF8
              collation-server=utf8_general_ci
              slow_query_log=0
              slow_query_log_file=/opt/bitnami/mysql/logs/mysqld.log
              long_query_time=10.0
              max_connections=1000

              [client]
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              default-character-set=UTF8
              plugin_dir=/opt/bitnami/mysql/lib/plugin

              [manager]
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
            nodeAffinityPreset:
              type: "hard"
              key: node_pool
              operator: In
              values:
              - ctfd-node-pool
            tolerations:
            - key: "ctfd-node-pool"
              operator: "Equal"
              value: "true"
              effect: "NoSchedule"
          secondary:
            configuration: |-
              [mysqld]
              default_authentication_plugin=mysql_native_password
              skip-name-resolve
              explicit_defaults_for_timestamp
              basedir=/opt/bitnami/mysql
              plugin_dir=/opt/bitnami/mysql/lib/plugin
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              datadir=/bitnami/mysql/data
              tmpdir=/opt/bitnami/mysql/tmp
              max_allowed_packet=16M
              bind-address=0.0.0.0
              pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
              log-error=/opt/bitnami/mysql/logs/mysqld.log
              character-set-server=UTF8
              collation-server=utf8_general_ci
              slow_query_log=0
              slow_query_log_file=/opt/bitnami/mysql/logs/mysqld.log
              long_query_time=10.0
              max_connections=1000

              [client]
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              default-character-set=UTF8
              plugin_dir=/opt/bitnami/mysql/lib/plugin

              [manager]
              port=3306
              socket=/opt/bitnami/mysql/tmp/mysql.sock
              pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
            tolerations:
            - key: "ctfd-node-pool"
              operator: "Equal"
              value: "true"
              effect: "NoSchedule"
            replicaCount: 3
          metrics:
            enabled: true
            serviceMonitor:
              enabled: true
              namespace: monitoring
      repoURL: https://charts.bitnami.com/bitnami
      targetRevision: 9.1.8
  operationState:
    finishedAt: "2022-08-27T07:40:42Z"
    message: successfully synced (all tasks run)
    operation:
      initiatedBy:
        username: admin
      retry: {}
      sync:
        revision: 9.1.8
        syncStrategy:
          hook: {}
    phase: Succeeded
    startedAt: "2022-08-27T07:40:42Z"
    syncResult:
      resources:
      - group: ""
        hookPhase: Succeeded
        kind: Secret
        message: ignored (requires pruning)
        name: mysql
        namespace: mysql
        status: PruneSkipped
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ConfigMap
        message: ignored (requires pruning)
        name: mysql
        namespace: mysql
        status: PruneSkipped
        syncPhase: Sync
        version: v1
      - group: cilium.io
        hookPhase: Succeeded
        kind: CiliumIdentity
        message: ignored (requires pruning)
        name: "9695"
        namespace: ""
        status: PruneSkipped
        syncPhase: Sync
        version: v2
      - group: ""
        hookPhase: Succeeded
        kind: Service
        message: ignored (requires pruning)
        name: mysql-headless
        namespace: mysql
        status: PruneSkipped
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: PersistentVolumeClaim
        message: ignored (requires pruning)
        name: data-mysql-0
        namespace: mysql
        status: PruneSkipped
        syncPhase: Sync
        version: v1
      - group: cilium.io
        hookPhase: Succeeded
        kind: CiliumIdentity
        message: ignored (requires pruning)
        name: "16177"
        namespace: ""
        status: PruneSkipped
        syncPhase: Sync
        version: v2
      - group: cilium.io
        hookPhase: Succeeded
        kind: CiliumIdentity
        message: ignored (requires pruning)
        name: "6139"
        namespace: ""
        status: PruneSkipped
        syncPhase: Sync
        version: v2
      - group: cilium.io
        hookPhase: Succeeded
        kind: CiliumIdentity
        message: ignored (requires pruning)
        name: "8135"
        namespace: ""
        status: PruneSkipped
        syncPhase: Sync
        version: v2
      - group: ""
        hookPhase: Succeeded
        kind: Service
        message: ignored (requires pruning)
        name: mysql
        namespace: mysql
        status: PruneSkipped
        syncPhase: Sync
        version: v1
      - group: policy
        hookPhase: Running
        kind: PodDisruptionBudget
        message: poddisruptionbudget.policy/mysql-secondary configured
        name: mysql-secondary
        namespace: mysql
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: ServiceAccount
        message: serviceaccount/mysql unchanged
        name: mysql
        namespace: mysql
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: ConfigMap
        message: configmap/mysql-primary unchanged
        name: mysql-primary
        namespace: mysql
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: ConfigMap
        message: configmap/mysql-secondary unchanged
        name: mysql-secondary
        namespace: mysql
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/mysql-metrics unchanged
        name: mysql-metrics
        namespace: mysql
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/mysql-secondary-headless unchanged
        name: mysql-secondary-headless
        namespace: mysql
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/mysql-primary-headless unchanged
        name: mysql-primary-headless
        namespace: mysql
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/mysql-primary configured
        name: mysql-primary
        namespace: mysql
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/mysql-secondary configured
        name: mysql-secondary
        namespace: mysql
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Running
        kind: StatefulSet
        message: statefulset.apps/mysql-primary configured
        name: mysql-primary
        namespace: mysql
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Running
        kind: StatefulSet
        message: statefulset.apps/mysql-secondary configured
        name: mysql-secondary
        namespace: mysql
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Running
        kind: ServiceMonitor
        message: servicemonitor.monitoring.coreos.com/mysql unchanged
        name: mysql
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      revision: 9.1.8
      source:
        chart: mysql
        helm:
          parameters:
          - name: secondary.pdb.create
            value: "true"
          - name: secondary.replicaCount
            value: "3"
          - name: auth.existingSecret
            value: mysql
          - name: architecture
            value: replication
          valueFiles:
          - values.yaml
          values: |-
            architecture: replication
            primary:
              configuration: |-
                [mysqld]
                default_authentication_plugin=mysql_native_password
                skip-name-resolve
                explicit_defaults_for_timestamp
                basedir=/opt/bitnami/mysql
                plugin_dir=/opt/bitnami/mysql/lib/plugin
                port=3306
                socket=/opt/bitnami/mysql/tmp/mysql.sock
                datadir=/bitnami/mysql/data
                tmpdir=/opt/bitnami/mysql/tmp
                max_allowed_packet=16M
                bind-address=0.0.0.0
                pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
                log-error=/opt/bitnami/mysql/logs/mysqld.log
                character-set-server=UTF8
                collation-server=utf8_general_ci
                slow_query_log=0
                slow_query_log_file=/opt/bitnami/mysql/logs/mysqld.log
                long_query_time=10.0
                max_connections=1000

                [client]
                port=3306
                socket=/opt/bitnami/mysql/tmp/mysql.sock
                default-character-set=UTF8
                plugin_dir=/opt/bitnami/mysql/lib/plugin

                [manager]
                port=3306
                socket=/opt/bitnami/mysql/tmp/mysql.sock
                pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
              nodeAffinityPreset:
                type: "hard"
                key: node_pool
                operator: In
                values:
                - ctfd-node-pool
              tolerations:
              - key: "ctfd-node-pool"
                operator: "Equal"
                value: "true"
                effect: "NoSchedule"
            secondary:
              configuration: |-
                [mysqld]
                default_authentication_plugin=mysql_native_password
                skip-name-resolve
                explicit_defaults_for_timestamp
                basedir=/opt/bitnami/mysql
                plugin_dir=/opt/bitnami/mysql/lib/plugin
                port=3306
                socket=/opt/bitnami/mysql/tmp/mysql.sock
                datadir=/bitnami/mysql/data
                tmpdir=/opt/bitnami/mysql/tmp
                max_allowed_packet=16M
                bind-address=0.0.0.0
                pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
                log-error=/opt/bitnami/mysql/logs/mysqld.log
                character-set-server=UTF8
                collation-server=utf8_general_ci
                slow_query_log=0
                slow_query_log_file=/opt/bitnami/mysql/logs/mysqld.log
                long_query_time=10.0
                max_connections=1000

                [client]
                port=3306
                socket=/opt/bitnami/mysql/tmp/mysql.sock
                default-character-set=UTF8
                plugin_dir=/opt/bitnami/mysql/lib/plugin

                [manager]
                port=3306
                socket=/opt/bitnami/mysql/tmp/mysql.sock
                pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
              tolerations:
              - key: "ctfd-node-pool"
                operator: "Equal"
                value: "true"
                effect: "NoSchedule"
              replicaCount: 3
            metrics:
              enabled: true
              serviceMonitor:
                enabled: true
                namespace: monitoring
        repoURL: https://charts.bitnami.com/bitnami
        targetRevision: 9.1.8
  reconciledAt: "2022-08-29T06:10:47Z"
  resources:
  - kind: ConfigMap
    name: mysql
    namespace: mysql
    requiresPruning: true
    status: OutOfSync
    version: v1
  - kind: ConfigMap
    name: mysql-primary
    namespace: mysql
    status: Synced
    version: v1
  - kind: ConfigMap
    name: mysql-secondary
    namespace: mysql
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: PersistentVolumeClaim
    name: data-mysql-0
    namespace: mysql
    requiresPruning: true
    status: OutOfSync
    version: v1
  - kind: Secret
    name: mysql
    namespace: mysql
    requiresPruning: true
    status: OutOfSync
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: mysql
    namespace: mysql
    requiresPruning: true
    status: OutOfSync
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: mysql-headless
    namespace: mysql
    requiresPruning: true
    status: OutOfSync
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: mysql-metrics
    namespace: mysql
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: mysql-primary
    namespace: mysql
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: mysql-primary-headless
    namespace: mysql
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: mysql-secondary
    namespace: mysql
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: mysql-secondary-headless
    namespace: mysql
    status: Synced
    version: v1
  - kind: ServiceAccount
    name: mysql
    namespace: mysql
    status: Synced
    version: v1
  - group: apps
    health:
      message: statefulset rolling update complete 1 pods at revision mysql-primary-6ffc578fc7...
      status: Healthy
    kind: StatefulSet
    name: mysql-primary
    namespace: mysql
    status: Synced
    version: v1
  - group: apps
    health:
      message: statefulset rolling update complete 3 pods at revision mysql-secondary-66bff78c67...
      status: Healthy
    kind: StatefulSet
    name: mysql-secondary
    namespace: mysql
    status: Synced
    version: v1
  - group: cilium.io
    kind: CiliumIdentity
    name: "16177"
    requiresPruning: true
    status: OutOfSync
    version: v2
  - group: cilium.io
    kind: CiliumIdentity
    name: "6139"
    requiresPruning: true
    status: OutOfSync
    version: v2
  - group: cilium.io
    kind: CiliumIdentity
    name: "8135"
    requiresPruning: true
    status: OutOfSync
    version: v2
  - group: cilium.io
    kind: CiliumIdentity
    name: "9695"
    requiresPruning: true
    status: OutOfSync
    version: v2
  - group: monitoring.coreos.com
    kind: ServiceMonitor
    name: mysql
    namespace: monitoring
    status: Synced
    version: v1
  - group: policy
    kind: PodDisruptionBudget
    name: mysql-secondary
    namespace: mysql
    status: Synced
    version: v1
  sourceType: Helm
  summary:
    images:
    - docker.io/bitnami/mysql:8.0.29-debian-11-r3
    - docker.io/bitnami/mysqld-exporter:0.14.0-debian-11-r3
  sync:
    comparedTo:
      destination:
        namespace: mysql
        server: https://kubernetes.default.svc
      source:
        chart: mysql
        helm:
          parameters:
          - name: secondary.pdb.create
            value: "true"
          - name: secondary.replicaCount
            value: "3"
          - name: auth.existingSecret
            value: mysql
          - name: architecture
            value: replication
          valueFiles:
          - values.yaml
          values: |-
            architecture: replication
            primary:
              configuration: |-
                [mysqld]
                default_authentication_plugin=mysql_native_password
                skip-name-resolve
                explicit_defaults_for_timestamp
                basedir=/opt/bitnami/mysql
                plugin_dir=/opt/bitnami/mysql/lib/plugin
                port=3306
                socket=/opt/bitnami/mysql/tmp/mysql.sock
                datadir=/bitnami/mysql/data
                tmpdir=/opt/bitnami/mysql/tmp
                max_allowed_packet=16M
                bind-address=0.0.0.0
                pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
                log-error=/opt/bitnami/mysql/logs/mysqld.log
                character-set-server=UTF8
                collation-server=utf8_general_ci
                slow_query_log=0
                slow_query_log_file=/opt/bitnami/mysql/logs/mysqld.log
                long_query_time=10.0
                max_connections=1000

                [client]
                port=3306
                socket=/opt/bitnami/mysql/tmp/mysql.sock
                default-character-set=UTF8
                plugin_dir=/opt/bitnami/mysql/lib/plugin

                [manager]
                port=3306
                socket=/opt/bitnami/mysql/tmp/mysql.sock
                pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
              nodeAffinityPreset:
                type: "hard"
                key: node_pool
                operator: In
                values:
                - ctfd-node-pool
              tolerations:
              - key: "ctfd-node-pool"
                operator: "Equal"
                value: "true"
                effect: "NoSchedule"
            secondary:
              configuration: |-
                [mysqld]
                default_authentication_plugin=mysql_native_password
                skip-name-resolve
                explicit_defaults_for_timestamp
                basedir=/opt/bitnami/mysql
                plugin_dir=/opt/bitnami/mysql/lib/plugin
                port=3306
                socket=/opt/bitnami/mysql/tmp/mysql.sock
                datadir=/bitnami/mysql/data
                tmpdir=/opt/bitnami/mysql/tmp
                max_allowed_packet=16M
                bind-address=0.0.0.0
                pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
                log-error=/opt/bitnami/mysql/logs/mysqld.log
                character-set-server=UTF8
                collation-server=utf8_general_ci
                slow_query_log=0
                slow_query_log_file=/opt/bitnami/mysql/logs/mysqld.log
                long_query_time=10.0
                max_connections=1000

                [client]
                port=3306
                socket=/opt/bitnami/mysql/tmp/mysql.sock
                default-character-set=UTF8
                plugin_dir=/opt/bitnami/mysql/lib/plugin

                [manager]
                port=3306
                socket=/opt/bitnami/mysql/tmp/mysql.sock
                pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
              tolerations:
              - key: "ctfd-node-pool"
                operator: "Equal"
                value: "true"
                effect: "NoSchedule"
              replicaCount: 3
            metrics:
              enabled: true
              serviceMonitor:
                enabled: true
                namespace: monitoring
        repoURL: https://charts.bitnami.com/bitnami
        targetRevision: 9.1.8
    revision: 9.1.8
    status: OutOfSync
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: prometheus
spec:
  destination:
    namespace: monitoring
    server: https://kubernetes.default.svc
  project: default
  source:
    chart: kube-prometheus
    helm:
      valueFiles:
      - values.yaml
      values: |-
        prometheus:
          persistence:
            enabled: true
            size: 50Gi
        node-exporter:
          tolerations:
            - key: "ctfd-node-pool"
              operator: "Equal"
              value: "true"
              effect: "NoSchedule"
    repoURL: https://charts.bitnami.com/bitnami
    targetRevision: 8.1.2
  syncPolicy:
    syncOptions:
    - Replace=true
status:
  health:
    status: Healthy
  history:
  - deployStartedAt: "2022-08-26T07:14:08Z"
    deployedAt: "2022-08-26T07:14:12Z"
    id: 0
    revision: 8.1.2
    source:
      chart: kube-prometheus
      helm:
        valueFiles:
        - values.yaml
        values: |-
          prometheus:
            persistence:
              enabled: true
              size: 50Gi
      repoURL: https://charts.bitnami.com/bitnami
      targetRevision: 8.1.2
  - deployStartedAt: "2022-08-26T07:45:07Z"
    deployedAt: "2022-08-26T07:45:09Z"
    id: 1
    revision: 8.1.2
    source:
      chart: kube-prometheus
      helm:
        valueFiles:
        - values.yaml
        values: |-
          prometheus:
            persistence:
              enabled: true
              size: 50Gi
            tolerations:
              - key: "ctfd-node-pool"
                operator: "Equal"
                value: "true"
                effect: "NoSchedule"
      repoURL: https://charts.bitnami.com/bitnami
      targetRevision: 8.1.2
  - deployStartedAt: "2022-08-26T07:46:10Z"
    deployedAt: "2022-08-26T07:46:12Z"
    id: 2
    revision: 8.1.2
    source:
      chart: kube-prometheus
      helm:
        valueFiles:
        - values.yaml
        values: |-
          prometheus:
            persistence:
              enabled: true
              size: 50Gi
          node-exporter:
            tolerations:
              - key: "ctfd-node-pool"
                operator: "Equal"
                value: "true"
                effect: "NoSchedule"
      repoURL: https://charts.bitnami.com/bitnami
      targetRevision: 8.1.2
  operationState:
    finishedAt: "2022-08-26T07:46:12Z"
    message: successfully synced (all tasks run)
    operation:
      initiatedBy:
        username: admin
      retry: {}
      sync:
        revision: 8.1.2
        syncOptions:
        - Replace=true
        syncStrategy:
          hook: {}
    phase: Succeeded
    startedAt: "2022-08-26T07:46:10Z"
    syncResult:
      resources:
      - group: cilium.io
        hookPhase: Succeeded
        kind: CiliumIdentity
        message: ignored (requires pruning)
        name: "10248"
        namespace: ""
        status: PruneSkipped
        syncPhase: Sync
        version: v2
      - group: cilium.io
        hookPhase: Succeeded
        kind: CiliumIdentity
        message: ignored (requires pruning)
        name: "37874"
        namespace: ""
        status: PruneSkipped
        syncPhase: Sync
        version: v2
      - group: cilium.io
        hookPhase: Succeeded
        kind: CiliumIdentity
        message: ignored (requires pruning)
        name: "4943"
        namespace: ""
        status: PruneSkipped
        syncPhase: Sync
        version: v2
      - group: policy
        hookPhase: Running
        kind: PodSecurityPolicy
        message: podsecuritypolicy.policy/prometheus-kube-state-metrics-monitoring
          replaced
        name: prometheus-kube-state-metrics-monitoring
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1beta1
      - group: policy
        hookPhase: Running
        kind: PodSecurityPolicy
        message: podsecuritypolicy.policy/prometheus-kube-prometheus-operator replaced
        name: prometheus-kube-prometheus-operator
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1beta1
      - group: policy
        hookPhase: Running
        kind: PodSecurityPolicy
        message: podsecuritypolicy.policy/prometheus-kube-prometheus-alertmanager
          replaced
        name: prometheus-kube-prometheus-alertmanager
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1beta1
      - group: policy
        hookPhase: Running
        kind: PodSecurityPolicy
        message: podsecuritypolicy.policy/prometheus-node-exporter replaced
        name: prometheus-node-exporter
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1beta1
      - group: policy
        hookPhase: Running
        kind: PodSecurityPolicy
        message: podsecuritypolicy.policy/prometheus-kube-prometheus-prometheus replaced
        name: prometheus-kube-prometheus-prometheus
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1beta1
      - group: ""
        hookPhase: Running
        kind: ServiceAccount
        message: serviceaccount/prometheus-kube-state-metrics replaced
        name: prometheus-kube-state-metrics
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: ServiceAccount
        message: serviceaccount/prometheus-kube-prometheus-alertmanager replaced
        name: prometheus-kube-prometheus-alertmanager
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: ServiceAccount
        message: serviceaccount/prometheus-kube-prometheus-operator replaced
        name: prometheus-kube-prometheus-operator
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: ServiceAccount
        message: serviceaccount/prometheus-kube-prometheus-blackbox-exporter replaced
        name: prometheus-kube-prometheus-blackbox-exporter
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: ServiceAccount
        message: serviceaccount/prometheus-kube-prometheus-prometheus replaced
        name: prometheus-kube-prometheus-prometheus
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: ServiceAccount
        message: serviceaccount/prometheus-node-exporter replaced
        name: prometheus-node-exporter
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Secret
        message: secret/alertmanager-prometheus-kube-prometheus-alertmanager replaced
        name: alertmanager-prometheus-kube-prometheus-alertmanager
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: ConfigMap
        message: configmap/prometheus-kube-prometheus-operator replaced
        name: prometheus-kube-prometheus-operator
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: ConfigMap
        message: configmap/prometheus-kube-prometheus-blackbox-exporter replaced
        name: prometheus-kube-prometheus-blackbox-exporter
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apiextensions.k8s.io
        hookPhase: Running
        kind: CustomResourceDefinition
        message: CustomResourceDefinition/podmonitors.monitoring.coreos.com updated
        name: podmonitors.monitoring.coreos.com
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apiextensions.k8s.io
        hookPhase: Running
        kind: CustomResourceDefinition
        message: CustomResourceDefinition/prometheusrules.monitoring.coreos.com updated
        name: prometheusrules.monitoring.coreos.com
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apiextensions.k8s.io
        hookPhase: Running
        kind: CustomResourceDefinition
        message: CustomResourceDefinition/servicemonitors.monitoring.coreos.com updated
        name: servicemonitors.monitoring.coreos.com
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apiextensions.k8s.io
        hookPhase: Running
        kind: CustomResourceDefinition
        message: CustomResourceDefinition/probes.monitoring.coreos.com updated
        name: probes.monitoring.coreos.com
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apiextensions.k8s.io
        hookPhase: Running
        kind: CustomResourceDefinition
        message: CustomResourceDefinition/alertmanagerconfigs.monitoring.coreos.com
          updated
        name: alertmanagerconfigs.monitoring.coreos.com
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apiextensions.k8s.io
        hookPhase: Running
        kind: CustomResourceDefinition
        message: CustomResourceDefinition/thanosrulers.monitoring.coreos.com updated
        name: thanosrulers.monitoring.coreos.com
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apiextensions.k8s.io
        hookPhase: Running
        kind: CustomResourceDefinition
        message: CustomResourceDefinition/alertmanagers.monitoring.coreos.com updated
        name: alertmanagers.monitoring.coreos.com
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apiextensions.k8s.io
        hookPhase: Running
        kind: CustomResourceDefinition
        message: CustomResourceDefinition/prometheuses.monitoring.coreos.com updated
        name: prometheuses.monitoring.coreos.com
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: ClusterRole
        message: clusterrole.rbac.authorization.k8s.io/prometheus-kube-prometheus-alertmanager-psp
          reconciled. clusterrole.rbac.authorization.k8s.io/prometheus-kube-prometheus-alertmanager-psp
          replaced
        name: prometheus-kube-prometheus-alertmanager-psp
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: ClusterRole
        message: clusterrole.rbac.authorization.k8s.io/prometheus-kube-prometheus-prometheus
          reconciled. clusterrole.rbac.authorization.k8s.io/prometheus-kube-prometheus-prometheus
          replaced
        name: prometheus-kube-prometheus-prometheus
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: ClusterRole
        message: clusterrole.rbac.authorization.k8s.io/prometheus-kube-state-metrics-monitoring-psp
          reconciled. clusterrole.rbac.authorization.k8s.io/prometheus-kube-state-metrics-monitoring-psp
          replaced
        name: prometheus-kube-state-metrics-monitoring-psp
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: ClusterRole
        message: clusterrole.rbac.authorization.k8s.io/prometheus-kube-state-metrics-monitoring
          reconciled. clusterrole.rbac.authorization.k8s.io/prometheus-kube-state-metrics-monitoring
          replaced
        name: prometheus-kube-state-metrics-monitoring
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: ClusterRole
        message: clusterrole.rbac.authorization.k8s.io/prometheus-kube-prometheus-operator-psp
          reconciled. clusterrole.rbac.authorization.k8s.io/prometheus-kube-prometheus-operator-psp
          replaced
        name: prometheus-kube-prometheus-operator-psp
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: ClusterRole
        message: clusterrole.rbac.authorization.k8s.io/prometheus-node-exporter-psp
          reconciled. clusterrole.rbac.authorization.k8s.io/prometheus-node-exporter-psp
          replaced
        name: prometheus-node-exporter-psp
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: ClusterRole
        message: clusterrole.rbac.authorization.k8s.io/prometheus-kube-prometheus-prometheus-psp
          reconciled. clusterrole.rbac.authorization.k8s.io/prometheus-kube-prometheus-prometheus-psp
          replaced
        name: prometheus-kube-prometheus-prometheus-psp
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: ClusterRole
        message: clusterrole.rbac.authorization.k8s.io/prometheus-kube-prometheus-operator
          reconciled. clusterrole.rbac.authorization.k8s.io/prometheus-kube-prometheus-operator
          replaced
        name: prometheus-kube-prometheus-operator
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: ClusterRoleBinding
        message: clusterrolebinding.rbac.authorization.k8s.io/prometheus-kube-prometheus-operator
          reconciled. clusterrolebinding.rbac.authorization.k8s.io/prometheus-kube-prometheus-operator
          replaced
        name: prometheus-kube-prometheus-operator
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: ClusterRoleBinding
        message: clusterrolebinding.rbac.authorization.k8s.io/prometheus-kube-prometheus-prometheus-psp
          reconciled. clusterrolebinding.rbac.authorization.k8s.io/prometheus-kube-prometheus-prometheus-psp
          replaced
        name: prometheus-kube-prometheus-prometheus-psp
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: ClusterRoleBinding
        message: clusterrolebinding.rbac.authorization.k8s.io/prometheus-kube-prometheus-operator-psp
          reconciled. clusterrolebinding.rbac.authorization.k8s.io/prometheus-kube-prometheus-operator-psp
          replaced
        name: prometheus-kube-prometheus-operator-psp
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: ClusterRoleBinding
        message: clusterrolebinding.rbac.authorization.k8s.io/prometheus-node-exporter-psp
          reconciled. clusterrolebinding.rbac.authorization.k8s.io/prometheus-node-exporter-psp
          replaced
        name: prometheus-node-exporter-psp
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: ClusterRoleBinding
        message: clusterrolebinding.rbac.authorization.k8s.io/prometheus-kube-prometheus-alertmanager-psp
          reconciled. clusterrolebinding.rbac.authorization.k8s.io/prometheus-kube-prometheus-alertmanager-psp
          replaced
        name: prometheus-kube-prometheus-alertmanager-psp
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: ClusterRoleBinding
        message: clusterrolebinding.rbac.authorization.k8s.io/prometheus-kube-state-metrics-monitoring
          reconciled. clusterrolebinding.rbac.authorization.k8s.io/prometheus-kube-state-metrics-monitoring
          replaced
        name: prometheus-kube-state-metrics-monitoring
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: ClusterRoleBinding
        message: clusterrolebinding.rbac.authorization.k8s.io/prometheus-kube-state-metrics-monitoring-psp
          reconciled. clusterrolebinding.rbac.authorization.k8s.io/prometheus-kube-state-metrics-monitoring-psp
          replaced
        name: prometheus-kube-state-metrics-monitoring-psp
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: ClusterRoleBinding
        message: clusterrolebinding.rbac.authorization.k8s.io/prometheus-kube-prometheus-prometheus
          reconciled. clusterrolebinding.rbac.authorization.k8s.io/prometheus-kube-prometheus-prometheus
          replaced
        name: prometheus-kube-prometheus-prometheus
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/prometheus-kube-prometheus-coredns replaced
        name: prometheus-kube-prometheus-coredns
        namespace: kube-system
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/prometheus-kube-prometheus-kube-scheduler replaced
        name: prometheus-kube-prometheus-kube-scheduler
        namespace: kube-system
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/prometheus-kube-prometheus-kube-controller-manager replaced
        name: prometheus-kube-prometheus-kube-controller-manager
        namespace: kube-system
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/prometheus-kube-prometheus-kube-proxy replaced
        name: prometheus-kube-prometheus-kube-proxy
        namespace: kube-system
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/prometheus-kube-prometheus-alertmanager replaced
        name: prometheus-kube-prometheus-alertmanager
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/prometheus-kube-prometheus-prometheus replaced
        name: prometheus-kube-prometheus-prometheus
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/prometheus-kube-prometheus-blackbox-exporter replaced
        name: prometheus-kube-prometheus-blackbox-exporter
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/prometheus-kube-prometheus-operator replaced
        name: prometheus-kube-prometheus-operator
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/prometheus-node-exporter replaced
        name: prometheus-node-exporter
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/prometheus-kube-state-metrics replaced
        name: prometheus-kube-state-metrics
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Running
        kind: DaemonSet
        message: daemonset.apps/prometheus-node-exporter replaced
        name: prometheus-node-exporter
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Running
        kind: Deployment
        message: deployment.apps/prometheus-kube-state-metrics replaced
        name: prometheus-kube-state-metrics
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Running
        kind: Deployment
        message: deployment.apps/prometheus-kube-prometheus-blackbox-exporter replaced
        name: prometheus-kube-prometheus-blackbox-exporter
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Running
        kind: Deployment
        message: deployment.apps/prometheus-kube-prometheus-operator replaced
        name: prometheus-kube-prometheus-operator
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Running
        kind: Alertmanager
        message: alertmanager.monitoring.coreos.com/prometheus-kube-prometheus-alertmanager
          replaced
        name: prometheus-kube-prometheus-alertmanager
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Running
        kind: ServiceMonitor
        message: servicemonitor.monitoring.coreos.com/prometheus-kube-prometheus-kube-controller-manager
          replaced
        name: prometheus-kube-prometheus-kube-controller-manager
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Running
        kind: ServiceMonitor
        message: servicemonitor.monitoring.coreos.com/prometheus-kube-prometheus-coredns
          replaced
        name: prometheus-kube-prometheus-coredns
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Running
        kind: ServiceMonitor
        message: servicemonitor.monitoring.coreos.com/prometheus-kube-prometheus-kube-proxy
          replaced
        name: prometheus-kube-prometheus-kube-proxy
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Running
        kind: ServiceMonitor
        message: servicemonitor.monitoring.coreos.com/prometheus-kube-prometheus-prometheus
          replaced
        name: prometheus-kube-prometheus-prometheus
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Running
        kind: ServiceMonitor
        message: servicemonitor.monitoring.coreos.com/prometheus-kube-prometheus-alertmanager
          replaced
        name: prometheus-kube-prometheus-alertmanager
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Running
        kind: ServiceMonitor
        message: servicemonitor.monitoring.coreos.com/prometheus-kube-prometheus-kube-scheduler
          replaced
        name: prometheus-kube-prometheus-kube-scheduler
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Running
        kind: ServiceMonitor
        message: servicemonitor.monitoring.coreos.com/prometheus-kube-prometheus-kubelet
          replaced
        name: prometheus-kube-prometheus-kubelet
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Running
        kind: ServiceMonitor
        message: servicemonitor.monitoring.coreos.com/prometheus-kube-prometheus-apiserver
          replaced
        name: prometheus-kube-prometheus-apiserver
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Running
        kind: ServiceMonitor
        message: servicemonitor.monitoring.coreos.com/prometheus-kube-prometheus-operator
          replaced
        name: prometheus-kube-prometheus-operator
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Running
        kind: Prometheus
        message: prometheus.monitoring.coreos.com/prometheus-kube-prometheus-prometheus
          replaced
        name: prometheus-kube-prometheus-prometheus
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Running
        kind: ServiceMonitor
        message: servicemonitor.monitoring.coreos.com/prometheus-kube-state-metrics
          replaced
        name: prometheus-kube-state-metrics
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Running
        kind: ServiceMonitor
        message: servicemonitor.monitoring.coreos.com/prometheus-node-exporter replaced
        name: prometheus-node-exporter
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      revision: 8.1.2
      source:
        chart: kube-prometheus
        helm:
          valueFiles:
          - values.yaml
          values: |-
            prometheus:
              persistence:
                enabled: true
                size: 50Gi
            node-exporter:
              tolerations:
                - key: "ctfd-node-pool"
                  operator: "Equal"
                  value: "true"
                  effect: "NoSchedule"
        repoURL: https://charts.bitnami.com/bitnami
        targetRevision: 8.1.2
  reconciledAt: "2022-08-29T06:10:47Z"
  resources:
  - kind: ConfigMap
    name: prometheus-kube-prometheus-blackbox-exporter
    namespace: monitoring
    status: Synced
    version: v1
  - kind: ConfigMap
    name: prometheus-kube-prometheus-operator
    namespace: monitoring
    status: Synced
    version: v1
  - kind: Secret
    name: alertmanager-prometheus-kube-prometheus-alertmanager
    namespace: monitoring
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: prometheus-kube-prometheus-coredns
    namespace: kube-system
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: prometheus-kube-prometheus-kube-controller-manager
    namespace: kube-system
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: prometheus-kube-prometheus-kube-proxy
    namespace: kube-system
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: prometheus-kube-prometheus-kube-scheduler
    namespace: kube-system
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: prometheus-kube-prometheus-alertmanager
    namespace: monitoring
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: prometheus-kube-prometheus-blackbox-exporter
    namespace: monitoring
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: prometheus-kube-prometheus-operator
    namespace: monitoring
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: prometheus-kube-prometheus-prometheus
    namespace: monitoring
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: prometheus-kube-state-metrics
    namespace: monitoring
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: prometheus-node-exporter
    namespace: monitoring
    status: Synced
    version: v1
  - kind: ServiceAccount
    name: prometheus-kube-prometheus-alertmanager
    namespace: monitoring
    status: Synced
    version: v1
  - kind: ServiceAccount
    name: prometheus-kube-prometheus-blackbox-exporter
    namespace: monitoring
    status: Synced
    version: v1
  - kind: ServiceAccount
    name: prometheus-kube-prometheus-operator
    namespace: monitoring
    status: Synced
    version: v1
  - kind: ServiceAccount
    name: prometheus-kube-prometheus-prometheus
    namespace: monitoring
    status: Synced
    version: v1
  - kind: ServiceAccount
    name: prometheus-kube-state-metrics
    namespace: monitoring
    status: Synced
    version: v1
  - kind: ServiceAccount
    name: prometheus-node-exporter
    namespace: monitoring
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: alertmanagerconfigs.monitoring.coreos.com
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: alertmanagers.monitoring.coreos.com
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: podmonitors.monitoring.coreos.com
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: probes.monitoring.coreos.com
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: prometheuses.monitoring.coreos.com
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: prometheusrules.monitoring.coreos.com
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: servicemonitors.monitoring.coreos.com
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: thanosrulers.monitoring.coreos.com
    status: Synced
    version: v1
  - group: apps
    health:
      status: Healthy
    kind: DaemonSet
    name: prometheus-node-exporter
    namespace: monitoring
    status: Synced
    version: v1
  - group: apps
    health:
      status: Healthy
    kind: Deployment
    name: prometheus-kube-prometheus-blackbox-exporter
    namespace: monitoring
    status: Synced
    version: v1
  - group: apps
    health:
      status: Healthy
    kind: Deployment
    name: prometheus-kube-prometheus-operator
    namespace: monitoring
    status: Synced
    version: v1
  - group: apps
    health:
      status: Healthy
    kind: Deployment
    name: prometheus-kube-state-metrics
    namespace: monitoring
    status: Synced
    version: v1
  - group: cilium.io
    kind: CiliumIdentity
    name: "10248"
    requiresPruning: true
    status: OutOfSync
    version: v2
  - group: cilium.io
    kind: CiliumIdentity
    name: "37874"
    requiresPruning: true
    status: OutOfSync
    version: v2
  - group: cilium.io
    kind: CiliumIdentity
    name: "4943"
    requiresPruning: true
    status: OutOfSync
    version: v2
  - group: monitoring.coreos.com
    kind: Alertmanager
    name: prometheus-kube-prometheus-alertmanager
    namespace: monitoring
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: Prometheus
    name: prometheus-kube-prometheus-prometheus
    namespace: monitoring
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: ServiceMonitor
    name: prometheus-kube-prometheus-alertmanager
    namespace: monitoring
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: ServiceMonitor
    name: prometheus-kube-prometheus-apiserver
    namespace: monitoring
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: ServiceMonitor
    name: prometheus-kube-prometheus-coredns
    namespace: monitoring
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: ServiceMonitor
    name: prometheus-kube-prometheus-kube-controller-manager
    namespace: monitoring
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: ServiceMonitor
    name: prometheus-kube-prometheus-kube-proxy
    namespace: monitoring
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: ServiceMonitor
    name: prometheus-kube-prometheus-kube-scheduler
    namespace: monitoring
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: ServiceMonitor
    name: prometheus-kube-prometheus-kubelet
    namespace: monitoring
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: ServiceMonitor
    name: prometheus-kube-prometheus-operator
    namespace: monitoring
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: ServiceMonitor
    name: prometheus-kube-prometheus-prometheus
    namespace: monitoring
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: ServiceMonitor
    name: prometheus-kube-state-metrics
    namespace: monitoring
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: ServiceMonitor
    name: prometheus-node-exporter
    namespace: monitoring
    status: Synced
    version: v1
  - group: policy
    kind: PodSecurityPolicy
    name: prometheus-kube-prometheus-alertmanager
    status: Synced
    version: v1beta1
  - group: policy
    kind: PodSecurityPolicy
    name: prometheus-kube-prometheus-operator
    status: Synced
    version: v1beta1
  - group: policy
    kind: PodSecurityPolicy
    name: prometheus-kube-prometheus-prometheus
    status: Synced
    version: v1beta1
  - group: policy
    kind: PodSecurityPolicy
    name: prometheus-kube-state-metrics-monitoring
    status: Synced
    version: v1beta1
  - group: policy
    kind: PodSecurityPolicy
    name: prometheus-node-exporter
    status: Synced
    version: v1beta1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: prometheus-kube-prometheus-alertmanager-psp
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: prometheus-kube-prometheus-operator
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: prometheus-kube-prometheus-operator-psp
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: prometheus-kube-prometheus-prometheus
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: prometheus-kube-prometheus-prometheus-psp
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: prometheus-kube-state-metrics-monitoring
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: prometheus-kube-state-metrics-monitoring-psp
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: prometheus-node-exporter-psp
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
    name: prometheus-kube-prometheus-alertmanager-psp
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
    name: prometheus-kube-prometheus-operator
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
    name: prometheus-kube-prometheus-operator-psp
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
    name: prometheus-kube-prometheus-prometheus
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
    name: prometheus-kube-prometheus-prometheus-psp
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
    name: prometheus-kube-state-metrics-monitoring
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
    name: prometheus-kube-state-metrics-monitoring-psp
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
    name: prometheus-node-exporter-psp
    status: Synced
    version: v1
  sourceType: Helm
  summary:
    images:
    - docker.io/bitnami/alertmanager:0.24.0-debian-11-r22
    - docker.io/bitnami/blackbox-exporter:0.22.0-debian-11-r0
    - docker.io/bitnami/kube-state-metrics:2.5.0-debian-11-r23
    - docker.io/bitnami/node-exporter:1.3.1-debian-11-r23
    - docker.io/bitnami/prometheus-operator:0.58.0-debian-11-r8
    - docker.io/bitnami/prometheus:2.37.0-debian-11-r9
  sync:
    comparedTo:
      destination:
        namespace: monitoring
        server: https://kubernetes.default.svc
      source:
        chart: kube-prometheus
        helm:
          valueFiles:
          - values.yaml
          values: |-
            prometheus:
              persistence:
                enabled: true
                size: 50Gi
            node-exporter:
              tolerations:
                - key: "ctfd-node-pool"
                  operator: "Equal"
                  value: "true"
                  effect: "NoSchedule"
        repoURL: https://charts.bitnami.com/bitnami
        targetRevision: 8.1.2
    revision: 8.1.2
    status: OutOfSync
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: redis
spec:
  destination:
    namespace: redis
    server: https://kubernetes.default.svc
  project: default
  source:
    chart: redis
    helm:
      valueFiles:
      - values.yaml
      values: |-
        auth:
          existingSecret: redis
        master:
          disableCommands: []
          nodeAffinityPreset:
            type: "hard"
            key: node_pool
            operator: In
            values:
            - ctfd-node-pool
          tolerations:
          - key: "ctfd-node-pool"
            operator: "Equal"
            value: "true"
            effect: "NoSchedule"
        replica:
          tolerations:
          - key: "ctfd-node-pool"
            operator: "Equal"
            value: "true"
            effect: "NoSchedule"
        metrics:
          enabled: true
          serviceMonitor:
            enabled: true
            namespace: monitoring
    repoURL: https://charts.bitnami.com/bitnami
    targetRevision: 17.0.10
status:
  health:
    status: Healthy
  history:
  - deployStartedAt: "2022-08-14T05:40:01Z"
    deployedAt: "2022-08-14T05:40:02Z"
    id: 0
    revision: 17.0.10
    source:
      chart: redis
      helm:
        valueFiles:
        - values.yaml
        values: 'disableCommands: []'
      repoURL: https://charts.bitnami.com/bitnami
      targetRevision: 17.0.10
  - deployStartedAt: "2022-08-14T05:48:25Z"
    deployedAt: "2022-08-14T05:48:26Z"
    id: 1
    revision: 17.0.10
    source:
      chart: redis
      helm:
        valueFiles:
        - values.yaml
        values: |-
          master:
            disableCommands: []
      repoURL: https://charts.bitnami.com/bitnami
      targetRevision: 17.0.10
  - deployStartedAt: "2022-08-14T05:50:08Z"
    deployedAt: "2022-08-14T05:50:09Z"
    id: 2
    revision: 17.0.10
    source:
      chart: redis
      helm:
        parameters:
        - name: auth.password
          value: b2e4Cx2xdq
        valueFiles:
        - values.yaml
        values: |-
          master:
            disableCommands: []
      repoURL: https://charts.bitnami.com/bitnami
      targetRevision: 17.0.10
  - deployStartedAt: "2022-08-14T05:51:49Z"
    deployedAt: "2022-08-14T05:51:50Z"
    id: 3
    revision: 17.0.10
    source:
      chart: redis
      helm:
        valueFiles:
        - values.yaml
        values: |-
          master:
            disableCommands: []
      repoURL: https://charts.bitnami.com/bitnami
      targetRevision: 17.0.10
  - deployStartedAt: "2022-08-26T02:59:34Z"
    deployedAt: "2022-08-26T02:59:35Z"
    id: 4
    revision: 17.0.10
    source:
      chart: redis
      helm:
        valueFiles:
        - values.yaml
        values: |-
          auth:
            existingSecret: redis
          master:
            disableCommands: []
      repoURL: https://charts.bitnami.com/bitnami
      targetRevision: 17.0.10
  - deployStartedAt: "2022-08-26T03:00:40Z"
    deployedAt: "2022-08-26T03:00:40Z"
    id: 5
    revision: 17.0.10
    source:
      chart: redis
      helm:
        valueFiles:
        - values.yaml
        values: |-
          auth:
            existingSecret: redis
          master:
            disableCommands: []
            nodeAffinityPreset:
              type: "hard"
              key: node_pool
              operator: In
              values:
              - ctfd-node-pool
            tolerations:
            - key: "ctfd-node-pool"
              operator: "Equal"
              value: "true"
              effect: "NoSchedule"
      repoURL: https://charts.bitnami.com/bitnami
      targetRevision: 17.0.10
  - deployStartedAt: "2022-08-26T03:24:08Z"
    deployedAt: "2022-08-26T03:24:08Z"
    id: 6
    revision: 17.0.10
    source:
      chart: redis
      helm:
        valueFiles:
        - values.yaml
        values: |-
          auth:
            existingSecret: redis
          master:
            disableCommands: []
            nodeAffinityPreset:
              type: "hard"
              key: node_pool
              operator: In
              values:
              - ctfd-node-pool
            tolerations:
            - key: "ctfd-node-pool"
              operator: "Equal"
              value: "true"
              effect: "NoSchedule"
          replica:
            tolerations:
            - key: "ctfd-node-pool"
              operator: "Equal"
              value: "true"
              effect: "NoSchedule"
      repoURL: https://charts.bitnami.com/bitnami
      targetRevision: 17.0.10
  - deployStartedAt: "2022-08-27T07:23:49Z"
    deployedAt: "2022-08-27T07:23:49Z"
    id: 7
    revision: 17.0.10
    source:
      chart: redis
      helm:
        valueFiles:
        - values.yaml
        values: |-
          auth:
            existingSecret: redis
          master:
            disableCommands: []
            nodeAffinityPreset:
              type: "hard"
              key: node_pool
              operator: In
              values:
              - ctfd-node-pool
            tolerations:
            - key: "ctfd-node-pool"
              operator: "Equal"
              value: "true"
              effect: "NoSchedule"
          replica:
            tolerations:
            - key: "ctfd-node-pool"
              operator: "Equal"
              value: "true"
              effect: "NoSchedule"
          metrics:
            enabled: true
      repoURL: https://charts.bitnami.com/bitnami
      targetRevision: 17.0.10
  - deployStartedAt: "2022-08-27T07:35:56Z"
    deployedAt: "2022-08-27T07:35:56Z"
    id: 8
    revision: 17.0.10
    source:
      chart: redis
      helm:
        valueFiles:
        - values.yaml
        values: |-
          auth:
            existingSecret: redis
          master:
            disableCommands: []
            nodeAffinityPreset:
              type: "hard"
              key: node_pool
              operator: In
              values:
              - ctfd-node-pool
            tolerations:
            - key: "ctfd-node-pool"
              operator: "Equal"
              value: "true"
              effect: "NoSchedule"
          replica:
            tolerations:
            - key: "ctfd-node-pool"
              operator: "Equal"
              value: "true"
              effect: "NoSchedule"
          metrics:
            enabled: true
            serviceMonitor:
              enabled: true
              namespace: monitoring
      repoURL: https://charts.bitnami.com/bitnami
      targetRevision: 17.0.10
  operationState:
    finishedAt: "2022-08-27T07:35:56Z"
    message: successfully synced (all tasks run)
    operation:
      initiatedBy:
        username: admin
      retry: {}
      sync:
        revision: 17.0.10
        syncStrategy:
          hook: {}
    phase: Succeeded
    startedAt: "2022-08-27T07:35:56Z"
    syncResult:
      resources:
      - group: cilium.io
        hookPhase: Succeeded
        kind: CiliumIdentity
        message: ignored (requires pruning)
        name: "15422"
        namespace: ""
        status: PruneSkipped
        syncPhase: Sync
        version: v2
      - group: ""
        hookPhase: Succeeded
        kind: Secret
        message: ignored (requires pruning)
        name: redis
        namespace: redis
        status: PruneSkipped
        syncPhase: Sync
        version: v1
      - group: cilium.io
        hookPhase: Succeeded
        kind: CiliumIdentity
        message: ignored (requires pruning)
        name: "6244"
        namespace: ""
        status: PruneSkipped
        syncPhase: Sync
        version: v2
      - group: cilium.io
        hookPhase: Succeeded
        kind: CiliumIdentity
        message: ignored (requires pruning)
        name: "5491"
        namespace: ""
        status: PruneSkipped
        syncPhase: Sync
        version: v2
      - group: cilium.io
        hookPhase: Succeeded
        kind: CiliumIdentity
        message: ignored (requires pruning)
        name: "8318"
        namespace: ""
        status: PruneSkipped
        syncPhase: Sync
        version: v2
      - group: ""
        hookPhase: Running
        kind: ServiceAccount
        message: serviceaccount/redis unchanged
        name: redis
        namespace: redis
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: ConfigMap
        message: configmap/redis-configuration unchanged
        name: redis-configuration
        namespace: redis
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: ConfigMap
        message: configmap/redis-health unchanged
        name: redis-health
        namespace: redis
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: ConfigMap
        message: configmap/redis-scripts unchanged
        name: redis-scripts
        namespace: redis
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/redis-headless unchanged
        name: redis-headless
        namespace: redis
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/redis-metrics unchanged
        name: redis-metrics
        namespace: redis
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/redis-master configured
        name: redis-master
        namespace: redis
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/redis-replicas configured
        name: redis-replicas
        namespace: redis
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Running
        kind: StatefulSet
        message: statefulset.apps/redis-master configured
        name: redis-master
        namespace: redis
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Running
        kind: StatefulSet
        message: statefulset.apps/redis-replicas configured
        name: redis-replicas
        namespace: redis
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Running
        kind: ServiceMonitor
        message: servicemonitor.monitoring.coreos.com/redis created
        name: redis
        namespace: monitoring
        status: Synced
        syncPhase: Sync
        version: v1
      revision: 17.0.10
      source:
        chart: redis
        helm:
          valueFiles:
          - values.yaml
          values: |-
            auth:
              existingSecret: redis
            master:
              disableCommands: []
              nodeAffinityPreset:
                type: "hard"
                key: node_pool
                operator: In
                values:
                - ctfd-node-pool
              tolerations:
              - key: "ctfd-node-pool"
                operator: "Equal"
                value: "true"
                effect: "NoSchedule"
            replica:
              tolerations:
              - key: "ctfd-node-pool"
                operator: "Equal"
                value: "true"
                effect: "NoSchedule"
            metrics:
              enabled: true
              serviceMonitor:
                enabled: true
                namespace: monitoring
        repoURL: https://charts.bitnami.com/bitnami
        targetRevision: 17.0.10
  reconciledAt: "2022-08-29T06:10:47Z"
  resources:
  - kind: ConfigMap
    name: redis-configuration
    namespace: redis
    status: Synced
    version: v1
  - kind: ConfigMap
    name: redis-health
    namespace: redis
    status: Synced
    version: v1
  - kind: ConfigMap
    name: redis-scripts
    namespace: redis
    status: Synced
    version: v1
  - kind: Secret
    name: redis
    namespace: redis
    requiresPruning: true
    status: OutOfSync
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: redis-headless
    namespace: redis
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: redis-master
    namespace: redis
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: redis-metrics
    namespace: redis
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: redis-replicas
    namespace: redis
    status: Synced
    version: v1
  - kind: ServiceAccount
    name: redis
    namespace: redis
    status: Synced
    version: v1
  - group: apps
    health:
      message: 'partitioned roll out complete: 1 new pods have been updated...'
      status: Healthy
    kind: StatefulSet
    name: redis-master
    namespace: redis
    status: Synced
    version: v1
  - group: apps
    health:
      message: 'partitioned roll out complete: 3 new pods have been updated...'
      status: Healthy
    kind: StatefulSet
    name: redis-replicas
    namespace: redis
    status: Synced
    version: v1
  - group: cilium.io
    kind: CiliumIdentity
    name: "15422"
    requiresPruning: true
    status: OutOfSync
    version: v2
  - group: cilium.io
    kind: CiliumIdentity
    name: "5491"
    requiresPruning: true
    status: OutOfSync
    version: v2
  - group: cilium.io
    kind: CiliumIdentity
    name: "6244"
    requiresPruning: true
    status: OutOfSync
    version: v2
  - group: cilium.io
    kind: CiliumIdentity
    name: "8318"
    requiresPruning: true
    status: OutOfSync
    version: v2
  - group: monitoring.coreos.com
    kind: ServiceMonitor
    name: redis
    namespace: monitoring
    status: Synced
    version: v1
  sourceType: Helm
  summary:
    images:
    - docker.io/bitnami/redis-exporter:1.43.0-debian-11-r18
    - docker.io/bitnami/redis:7.0.4-debian-11-r11
  sync:
    comparedTo:
      destination:
        namespace: redis
        server: https://kubernetes.default.svc
      source:
        chart: redis
        helm:
          valueFiles:
          - values.yaml
          values: |-
            auth:
              existingSecret: redis
            master:
              disableCommands: []
              nodeAffinityPreset:
                type: "hard"
                key: node_pool
                operator: In
                values:
                - ctfd-node-pool
              tolerations:
              - key: "ctfd-node-pool"
                operator: "Equal"
                value: "true"
                effect: "NoSchedule"
            replica:
              tolerations:
              - key: "ctfd-node-pool"
                operator: "Equal"
                value: "true"
                effect: "NoSchedule"
            metrics:
              enabled: true
              serviceMonitor:
                enabled: true
                namespace: monitoring
        repoURL: https://charts.bitnami.com/bitnami
        targetRevision: 17.0.10
    revision: 17.0.10
    status: OutOfSync
---
